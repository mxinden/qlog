{
  "magic": "E!vIA5L86J2I",
  "timestamp": "2022-02-27T00:45:37.623377+00:00",
  "repo": "quicwg/qlog",
  "labels": [
    {
      "name": "design",
      "description": "",
      "color": "1d76db"
    },
    {
      "name": "editorial",
      "description": "",
      "color": "0e8a16"
    },
    {
      "name": "high-level-schema",
      "description": "",
      "color": "7fd836"
    },
    {
      "name": "quic-http3-fields",
      "description": "",
      "color": "d6354a"
    },
    {
      "name": "future-versions",
      "description": "issue will be tackled but not for the current iteration",
      "color": "ea049d"
    },
    {
      "name": "current-version",
      "description": "",
      "color": "08497a"
    },
    {
      "name": "privacy",
      "description": "",
      "color": "C17C17"
    },
    {
      "name": "discuss",
      "description": "needs further discussion",
      "color": "CA53CA"
    }
  ],
  "issues": [
    {
      "number": 1,
      "id": "MDU6SXNzdWU0MjkyODkxNjc=",
      "title": "Allow flexible fields definitions",
      "url": "https://github.com/quicwg/qlog/issues/1",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "high-level-schema"
      ],
      "body": "The fields that are logged for each individual event depend on the context of usage of the format.\r\n\r\nE.g., if you split your logs per connection-id yourself, you do not need to log the connection-id for each event.\r\nHowever, if you do not log only QUIC data, but also ICMP/TCP info (e.g., the in-network measurement use-case), you need an additional field \"protocol-type\".\r\n\r\nProposal:\r\nAllow common fields to be set in each \"trace\" header.\r\n\r\n```\r\n{\r\n     \"common_fields\": [ \"connection_id\": \"0xdeadbeef\", \"protocol-type\": \"QUIC\" ],  \r\n     \"field_headers: [\"timestamp\", \"category\", \"type\", \"trigger\", \"data\"],  \r\n     \"events\": [ ... ]  \r\n}\r\n```\r\n\r\nIf you do not log a field, you just leave it out of both common_fields and field_headers. \r\n",
      "createdAt": "2019-04-04T13:46:52Z",
      "updatedAt": "2019-10-14T09:31:32Z",
      "closedAt": "2019-10-14T09:31:32Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Present in draft-01 by allowing fields in either common_fields or in event_fields.",
          "createdAt": "2019-10-14T09:31:32Z",
          "updatedAt": "2019-10-14T09:31:32Z"
        }
      ]
    },
    {
      "number": 2,
      "id": "MDU6SXNzdWU0MjkzNTQzMDY=",
      "title": "Streaming format",
      "url": "https://github.com/quicwg/qlog/issues/2",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "high-level-schema"
      ],
      "body": "Plain JSON is not entirely streamable... it requires its fields to be closed properly (by ] and }) at the end.\r\n\r\ne.g.,\r\n```\r\n\"events\": [\r\n           { \"key\": \"val\" }\r\n```\r\nWill fail, but \r\n```\r\n\"events\": [\r\n           { \"key\": \"val\" }\r\n]\r\n```\r\nwill succeed. \r\n\r\nHowever, one could employ a streaming JSON parser (e.g., http://oboejs.com/) and ignore unclosed fields at the end that way. \r\nFor the way the format is currently defined, an implementation would then write the \"header\" of the qlog file, and then it could stream individual events that are just appended to the file. \r\nIf the file isn't properly closed, that's not a problem: the streaming parser user just ignores those errors.\r\nHowever, this breaks compatibility with the built-in parsers in many stdlibs and the browsers themselves.\r\nIt would also be possible to write a simple postprocessing tool that simply appends the necessary \"closing\" characters to a qlog file if it isn't complete, though that adds another step in a pipeline... \r\n\r\nThere are also various JSON-subformats that address this problem (see https://en.wikipedia.org/wiki/JSON_streaming), but they also do not seem to be supported in the standard JSON parsers for many platforms...\r\n\r\n**Given all this, my personal preference is to stay with just the normal JSON format and tools are recommended to use a streaming parser.** \r\n\r\n\r\nExample of how the browser's built-in JSON parser does not support special JSON:\r\n![2019-04-04 17_02_41](https://user-images.githubusercontent.com/2240689/55566226-8df5ff80-56fb-11e9-9a60-ab0fe703cf27.png)\r\n\r\nExample of how a streaming parser (oboe) does handle this properly:\r\n![proof](https://user-images.githubusercontent.com/2240689/55569216-77eb3d80-5701-11e9-86af-2b1a5b79ea2f.png)\r\n\r\n\r\n\r\n",
      "createdAt": "2019-04-04T15:47:41Z",
      "updatedAt": "2020-09-05T16:15:36Z",
      "closedAt": "2020-09-05T16:15:36Z",
      "comments": []
    },
    {
      "number": 3,
      "id": "MDU6SXNzdWU0Mjk3MTAwNDc=",
      "title": "Aggregated metrics",
      "url": "https://github.com/quicwg/qlog/issues/3",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design"
      ],
      "body": "Example: in-network logger aggregates over a period of time and sends back summarized data in 1 go (e.g., average RTT in past 10s, measured over 10k packets).\r\n\r\nThis can be supported in a variety of ways.\r\n\r\nThe easiest would probably be a new EVENT type that just contains the aggregated metrics.\r\nHowever, this depends on which types of aggregated data you want to pass. \r\n\r\ne.g., saying: median RTT was 50ms over the past 5s and we saw 1k packets in that time is fine\r\n\r\ne.g., saying: median RTT was 50ms across these 5 connections identified by these 4-tuples, is not really adhering to the semantics of the original setup.\r\n\r\nWe need more input from the people doing aggregated use cases to see how this data would be used and which types of metadata is needed to make an informed decision. ",
      "createdAt": "2019-04-05T11:30:41Z",
      "updatedAt": "2020-09-07T13:18:00Z",
      "closedAt": "2020-09-07T13:18:00Z",
      "comments": []
    },
    {
      "number": 4,
      "id": "MDU6SXNzdWU0Mjk3MjQzNzc=",
      "title": "Readability vs file size",
      "url": "https://github.com/quicwg/qlog/issues/4",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design"
      ],
      "body": "We would like to keep the file (semi-) human readable.\r\nThis means more advanced techniques like listing all fields in an ENUM up-front and then referencing to them by index is not optimal.\r\n\r\nHowever, when repeating strings, we might want to limit the length of individual fields. \r\ne.g., TRANS instead of TRANSPORT, APP instead of APPLICATION, RX instead of RECEIVE, etc. \r\n\r\nCurrent numbers (with readable strings):\r\n- qlog version without whitespace is about 4x the size of the binary .qtr file for the quic-trace example file (3.5MB to 823KB)\r\n- qlog version with whitespace is 10.6MB. However, this should matter little, since if manually reviewing large logs, you'll probably use a text editor that can auto-format the json from the version without whitespace\r\n\r\n4x size difference is a lot, but better than the direct .json protobuf transform, which clocks in at 14MB. ",
      "createdAt": "2019-04-05T12:11:32Z",
      "updatedAt": "2020-09-05T16:19:14Z",
      "closedAt": "2020-09-05T16:19:14Z",
      "comments": []
    },
    {
      "number": 5,
      "id": "MDU6SXNzdWU0Mjk3MzAwOTY=",
      "title": "Decide upon a language to define the schema definition",
      "url": "https://github.com/quicwg/qlog/issues/5",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "editorial"
      ],
      "body": "We need to indicate various things, such as field types (int, string, ...), whether fields are required or optional, give example values for fields, etc.\r\n\r\nWe could use normal JSON-schema for this, but this is quite verbose...\r\nWe could also use TypeScript, though this is non-standard...\r\nOther RFCs are known to use their own specific languages for this (i.e., see TLS 1.3's type definitions), but maybe there is something workable already out there. \r\n\r\nCurrently, we use TypeScript format, since this is used in the Quicker prototype qlog implementation directly + is easy enough to parse for newcomers. ",
      "createdAt": "2019-04-05T12:26:48Z",
      "updatedAt": "2020-09-05T16:19:46Z",
      "closedAt": "2020-09-05T16:19:46Z",
      "comments": []
    },
    {
      "number": 6,
      "id": "MDU6SXNzdWU0Mjk3NzczOTI=",
      "title": "Define the semantics of RX and TX for NETWORK vantage point",
      "url": "https://github.com/quicwg/qlog/issues/6",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "high-level-schema"
      ],
      "body": "For CLIENT and SERVER, the difference between RECEIVE (RX) and TRANSMIT (TX) is obvious. Not so for an in-network observer (or, e.g., a proxy server), where these terms make less sense...\r\n\r\nSome options:\r\n- Type is NETWORK_CLIENT and NETWORK_SERVER (instead of NETWORK)\r\n- add separate \"flow\" field indicating if we use CLIENT or SERVER semantics (currently in the draft)\r\n- add separate metadata field indicating which 5-tuple is the conceptual \"client\" and which is the \"server\" and use RX/TX based on that\r\n- Don't fix this and let the tooling layer figure it out (if packet nr 6 is a client TX and a RX in the NETWORK trace, the network is from the viewpoint of the SERVER)\r\n\r\nBroader discussion: does it make sense to log packets as PACKET_TX and _RX here? how about instead a PACKET event (similar to how wireshark does it). However: this doesn't make sense for (stateful) proxies that do act as both client+server when ~transforming the traffic (e.g., Facebook's load balancer). \r\n",
      "createdAt": "2019-04-05T14:15:11Z",
      "updatedAt": "2019-10-14T09:30:47Z",
      "closedAt": "2019-10-14T09:30:47Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Solved in draft-01 by using separate _sent and _received (or equivalent) events for clarity + using vantage_point and their \"flow\" field.",
          "createdAt": "2019-10-14T09:30:47Z",
          "updatedAt": "2019-10-14T09:30:47Z"
        }
      ]
    },
    {
      "number": 7,
      "id": "MDU6SXNzdWU0Mjk4MjIyODc=",
      "title": "Use cases for the TRIGGER field ",
      "url": "https://github.com/quicwg/qlog/issues/7",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "high-level-schema"
      ],
      "body": "To have the TRIGGER as a top-level field, there need to be good use-cases and people willing to use this in their tools. \r\n\r\nSince the TRIGGER will only be useful for specific events (e.g., PACKET_RETRANSMIT can be due to several loss-detection related situations) and it's value might in some cases also just be deduced from the context of surrounding log messages, it is debatable it will have much use in practice. \r\n\r\nAn alternate approach could be to log it as part of the DATA field of specific events, instead of as a top-level field. ",
      "createdAt": "2019-04-05T15:48:06Z",
      "updatedAt": "2019-10-14T09:36:11Z",
      "closedAt": "2019-10-14T09:36:11Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Feedback from among others @nibanks indicates that adding the TRIGGER as an optional member of the DATA is probably the better option down the road.\r\n\r\nWe could think about extending that: any event_field could conceptually be added to data. This would be useful for other event_fields as well, that are not the same for all events (which would be in common_fields) but also don't need to be logged for each event (event_fields). Maybe something like dynamic_fields? and then you do data.dynamic to fetch them? (e.g., data.dynamic.trigger). This is nice an flexible, but a potential nightmare to support properly in tooling...",
          "createdAt": "2019-07-31T13:47:10Z",
          "updatedAt": "2019-07-31T13:47:10Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Fixed in #23. Triggers are now properties of the data field with hints in the draft as to their values in separate contexts. \r\n\r\nDecided not to do the \"dynamic_fields\" approach for now to keep complexity manageable. ",
          "createdAt": "2019-10-14T09:36:11Z",
          "updatedAt": "2019-10-14T09:36:11Z"
        }
      ]
    },
    {
      "number": 8,
      "id": "MDU6SXNzdWU0Mjk4Mzg0ODU=",
      "title": "Allow index-based referencing for all event field names",
      "url": "https://github.com/quicwg/qlog/issues/8",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "high-level-schema"
      ],
      "body": "Currently, we have a concept that you can have a \"groups_id\" object in \"common_fields\". \r\nIf you then have a \"group_id\" in your \"events_field\", the value for that with each event is an index into the \"groups_id\" field, to prevent replication of complex fields.\r\n\r\nWe could make this more general, applicable to each field name.\r\nE.g., if you know up-front which CATEGORY values you support, you could do something like:\r\n\r\n```\r\n{\r\n    \"common_fields\": {\r\n        \"group_id\": \"127ecc830d98f9d54a42c4f0842aa87e181a\",\r\n        \"ODCID\": \"127ecc830d98f9d54a42c4f0842aa87e181a\",\r\n        \"CATEGORY\": [\"PACKET_RX\", \"DATA_FRAME_NEW\"]\r\n        \"protocol_type\":  \"QUIC_HTTP3\",\r\n        \"reference_time\": \"1553986553572\"\r\n    },\r\n    \"event_fields\": [\r\n        \"delta_time\",\r\n        \"CATEGORY\",\r\n        \"EVENT_TYPE\",\r\n        \"TRIGGER\",\r\n        \"DATA\"\r\n    ],\r\n    \"events\": [[\r\n            2,\r\n            \"TRANSPORT\",\r\n            0,\r\n            \"LINE\",\r\n            [...]\r\n        ],[\r\n            7,\r\n            \"APPLICATION\",\r\n            1,\r\n            \"GET\",\r\n            [...]\r\n        ],\r\n        ...\r\n    ]\r\n}\r\n```\r\n\r\nWe would then have a general rule:\r\n\r\n> If the field is present as a value of type array in \"common_fields\" AND the field-name is present in \"event_fields\", the value per-event MUST be treated as an index into the \"common_fields\" entry, rather than taken as a direct value. \r\n\r\n(\"groups_id\" would then also be renamed to \"group_id\" in \"common_fields\")\r\n\r\nThis would allow smaller file sizes (and less string writing overhead) for applications that have a static list of e.g., CATEGORY or EVENT_TYPE up front.\r\nDownside 1 is that it complicates the tools reading the file (but only a bit imo).\r\nDownside 2 is that is complicates humans reading the file (so it depends on the use case).\r\n   (either way, it's easy to go from 1 to the other with a simple script)\r\n\r\n-----------------------------------------------------------------------------------\r\n\r\nThis concept could be extended to make it a fully self-describing format.\r\nIn other words, we could also describe the fields in the DATA for known events up-front and replace those entries with in-order arrays of the values instead of key-value object definitions.\r\n\r\nVery high-level concept (probably needs proper description of the fields etc.):\r\n```\r\n\"data_fields\" : {\r\n      \"TRANSPORT+PACKET_SENT\" : [\r\n         \"frame_type\",\r\n         \"packet_number\",\r\n         \"frames\"\r\n     ]\r\n}\r\n...\r\n[ 57, \"TRANSPORT\", \"PACKET_SENT\", \"TRIGGER\", [\"STREAM\", 15, [...]]]\r\n```\r\nTaking this all to the extreme, you could have a fully self-describing format that lists all known events (and potentially some values, similar to QPack's static table) up-top and then each entry just uses indexes + potentially a few raw values. However, I'm personally not of the opinion this added complexity is worth it. \r\n\r\n",
      "createdAt": "2019-04-05T16:27:53Z",
      "updatedAt": "2019-10-14T09:29:52Z",
      "closedAt": "2019-10-14T09:29:52Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "In the interest of keeping things simple and because there are few situations where this has turned up in the meantime, I've decided for now to only allow this for \"group_id\". Further fields that benefit from this can be added per-instance. \r\n\r\nNote that Chrome's netlog format does this, and it severely compromises the user's ability to understand and grep those files, despite them using .json as a substrate as well.",
          "createdAt": "2019-10-14T09:29:52Z",
          "updatedAt": "2019-10-14T09:29:52Z"
        }
      ]
    },
    {
      "number": 9,
      "id": "MDU6SXNzdWU0MzA1MDE2ODM=",
      "title": "How descriptive should EVENT_TYPE names be?",
      "url": "https://github.com/quicwg/qlog/issues/9",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "quic-http3-fields"
      ],
      "body": "For example:\r\nPACKET_RECEIVED        vs       1RTT_PACKET_RECEIVED\r\nFRAME_NEW                vs        ACK_FRAME_NEW\r\n\r\nFor the leftmost entries, one would add a \"type\" field to the \"DATA\" value, e.g., \r\n```\r\n{\r\n     \"type\": \"1RTT\"\r\n}\r\n```\r\n\r\nThe shorter form makes that we have a much less large amount of different EVENT_TYPEs, but also makes it a bit harder to parse for human readers + harder to quickly filter for tools. \r\nThe longer form is much more explicit, but requires much more definition up-front and a proliferation of different EVENT_TYPEs.\r\n\r\nWe could also break consistency. i.e., the original qlog used PACKET_RECEIVED with an explicit type in the DATA, but used ACK_FRAME_NEW for individual frames.\r\n\r\nCurrently, we use the short-form, since this is most similar to quic-trace and keeps it consistent if we want to log frames both in their own events and again when sending a packet. \r\n\r\nExtra edge-case: Errors\r\nIf you go for extreme short-form, you would just have a single ERROR EVENT_TYPE for each CATEGORY, and define the error type in the DATA.\r\nHowever, for easier manual debugging, tracking the specific type of error directly in the EVENT_TYPE is arguably easier. Maybe an exception should be made for errors? ",
      "createdAt": "2019-04-08T15:01:36Z",
      "updatedAt": "2019-10-07T19:46:27Z",
      "closedAt": "2019-10-07T19:46:26Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "In draft-01, we made the conscious choice to limit the number of events as much as possible and make most event data based on the Frame definitions that already existed for packet_sent and packet_received. Combined with proper naming of properties (e.g., packet_type instead of type) this enables fast parsing while removing the need for separate events for each possible signal.",
          "createdAt": "2019-10-07T19:46:26Z",
          "updatedAt": "2019-10-07T19:46:26Z"
        }
      ]
    },
    {
      "number": 10,
      "id": "MDU6SXNzdWU0MzA5NTQyMzE=",
      "title": "Numbers in JSON",
      "url": "https://github.com/quicwg/qlog/issues/10",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "editorial",
        "quic-http3-fields"
      ],
      "body": "Typically, integers in JavaScript and most JSON implementations are limited to 2^53-1.\r\nThis gives problems, as the VLIE values in the QUIC/H3 specs are 2^62-1.\r\n\r\nTwo options:\r\n- Allow bigger values in the JSON. Tools MUST use a JSON parser that can deal with this and a JavaScript engine that supports BigInt (currently limited to Chromium: https://caniuse.com/#search=bigint)\r\n- Encode all VLIE fields as strings. Tools have to deal with this themselves (most will probably just take the shortcut of assuming actual values will be < 2^53 and just use the JavaScript \"Number\" type). This is best for a wide tooling implementation area in browsers. \r\n\r\nCurrently, the draft uses option 2. \r\n\r\n",
      "createdAt": "2019-04-09T13:00:45Z",
      "updatedAt": "2020-09-05T16:19:32Z",
      "closedAt": "2020-09-05T16:19:32Z",
      "comments": [
        {
          "author": "jlaine",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Firefox and Edge (obviously) also suport BigInt according to caniuse. The only significant outlier is Safari.\r\n\r\nHowever you're right, JSON serialization / parsing isn't there yet:\r\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt#Use_within_JSON",
          "createdAt": "2019-08-23T10:57:13Z",
          "updatedAt": "2019-08-23T10:59:25Z"
        },
        {
          "author": "martinthomson",
          "authorAssociation": "MEMBER",
          "body": "An alternative would be to define a completely different interface.\r\n\r\nJSON is an odd choice because what generally happens here is that you have a stream of events.  Constructing that as a JSON array is awkward as it interacts poorly with typical JSON processing pipelines.  You might use JSON text sequences, but that is an odd line.\r\n\r\nCSV has some nice properties: you define the first column as the event type and remaining fields dependent on the type.  Then each record is delineated by something easy to produce (CRLF) and fields are easily recoverable.  Everything is a string then and you can define processing for number fields.",
          "createdAt": "2019-11-19T04:00:59Z",
          "updatedAt": "2019-11-19T04:00:59Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "As pointed out by @marten-seemann, the JSON spec itself does not limit the numbers to 2^53-1, it is just the implementations.\r\n\r\nAs such, for the purposes of the qlog spec, and if we stay with JSON, we can simply require clients to be able to deal with larger numbers in one of several ways (e.g., either detect and discard, detect and notify user, ignore, use parser that can handle up to 64 bit).\r\n\r\nI am thinking of switching to option 1 (from the first post in this issue) for draft-02. \r\n\r\n\r\n",
          "createdAt": "2020-01-19T10:45:33Z",
          "updatedAt": "2020-01-19T10:45:33Z"
        }
      ]
    },
    {
      "number": 11,
      "id": "MDU6SXNzdWU0MzQ2NzkxMTA=",
      "title": "Allow raw logging of packets and/or frames",
      "url": "https://github.com/quicwg/qlog/issues/11",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "quic-http3-fields"
      ],
      "body": "As mentioned by @kazuho on the mailing list, it would be useful to (re-)introduce the ability to log raw packet and/or frame contents, probably has a hex-encoded string. \r\n\r\nProbably easiest to add an additional field like this:\r\n```\r\n{\r\n    \"stream_type\": \"ACK\",\r\n    \"raw_hex\": \"0892e340dbaa354f800239dddc7be78406fe3726bea050bb8c56ab36\",\r\n    ...\r\n}\r\n```",
      "createdAt": "2019-04-18T09:37:52Z",
      "updatedAt": "2019-10-14T09:27:43Z",
      "closedAt": "2019-10-14T09:27:43Z",
      "comments": [
        {
          "author": "kazuho",
          "authorAssociation": "MEMBER",
          "body": "Thank you for opening the issue.\r\n\r\nCan we also omit the \"stream_type\" attribute, because that would be obvious from the first byte of the binary? So something like just `{\"raw_hex\":\"...\"}` or just the hex string itself.",
          "createdAt": "2019-04-18T23:58:00Z",
          "updatedAt": "2019-04-18T23:58:00Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Omitting the stream_type is indeed possible.\r\nDropping the \"raw_hex\" would require a move to an array (i.e., [ ]) rather than an object (i.e., { }) literal.\r\nThis is something we might want to allow for issue #8 as well, so that might fit. \r\n\r\nJust to be sure what we're talking about:\r\nWe would have a mixed JSON file format with some events (e.g., recovery-related stuff) being logged in full, and the packet/frame level events being logged as binary hex strings for post-processing, right? See the example below.\r\n\r\n```\r\n\"events\": {\r\n    [48, \"TRANSPORT\", \"PACKET_RECEIVED\", \"DEFAULT\", [\"08277abefc43c25eca0892e340dbaa354f800239dddc7be78406fe3726bea050bb8c56ab36\"] ],\r\n    [49, \"TRANSPORT\", \"FRAME_RECEIVED\", \"DEFAULT\", [\"0892e340dbaa354f800239dddc7be78406fe3726bea050bb8c56ab36\"] ],\r\n    [50, \"RECOVERY\", \"METRIC_UPDATE\", \"ACK_RECEIVED\", {\"min_rtt\": 50, \"smoothed_rtt\": 62} ],\r\n}\r\n```\r\nDoes that fit with what you had in mind? (I have now included both full packet and separate frame logs, obviously we could also just do the packet only)\r\n",
          "createdAt": "2019-04-19T09:57:21Z",
          "updatedAt": "2019-04-19T09:58:45Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Lacking further follow-up on this, I've added \"raw\" or \"raw_encrypted\"/\"raw_decrypted\" fields where appropriate to draft-01. I do not want to require tools to deal with situations where only the \"raw\" fields are present (i.e., having to include a full compliant QUIC and H3 parser in each tool), so you'd have to write a separate transformer that takes the raw stuff and transforms it into \"proper qlog\" before putting it in a tool, but I feel it's a good compromise personally.",
          "createdAt": "2019-10-14T09:27:43Z",
          "updatedAt": "2019-10-14T09:27:43Z"
        }
      ]
    },
    {
      "number": 13,
      "id": "MDU6SXNzdWU0NzE3NzQ4MDQ=",
      "title": "Invalid Assumptions in packet_sent triggers",
      "url": "https://github.com/quicwg/qlog/issues/13",
      "state": "CLOSED",
      "author": "nibanks",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "The `packet_sent`'s `triggers` field makes the assumptions that a packet is sent because a previous packet is being retransmitted. For instance, in winquic a connection has a queue/set of what data needs to be sent. When data is (suspected) lost, the data in the packet is added back to the queue. Similarly for PTO, we mark an outstanding packet as lost, and if we don't have any, queue a PING frame.\r\n\r\nThe send logic just grabs data from the queue/set and builds up packets to be sent. There is no direction relationship between different packets.\r\n\r\nSo, IMO, triggers are the reason data is queued to be sent, not actually sent. What is actually sent will depend on the entire state of the send queue at the time the send logic actually executes.\r\n\r\nFor example, assume you have two outstanding packets that end up getting marked as lost:\r\n\r\n```\r\n  PktNum=1 { STREAM ID=1, Offset=0, Length=100 }\r\n  PktNum=2 { STREAM ID=1, Offset=100, Length=100 }\r\n```\r\n\r\nBoth are marked as lost. Around the same time, the app queues another 100 bytes on stream 1 to be sent. Then another packet ends up getting sent:\r\n\r\n```\r\n  PktNum=55 { STREAM ID=1, Offset=0, Length=300 }\r\n```",
      "createdAt": "2019-07-23T15:45:02Z",
      "updatedAt": "2019-10-07T17:03:31Z",
      "closedAt": "2019-10-07T17:03:31Z",
      "comments": [
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "As a follow up, I believe the packet_lost and packet_acknowledged events should be in the transport section. Also, the packet_retransmit should be removed.",
          "createdAt": "2019-07-23T15:48:54Z",
          "updatedAt": "2019-07-23T15:48:54Z"
        }
      ]
    },
    {
      "number": 14,
      "id": "MDU6SXNzdWU0NzE3Nzk5MTc=",
      "title": "Payload for packet_dropped",
      "url": "https://github.com/quicwg/qlog/issues/14",
      "state": "CLOSED",
      "author": "nibanks",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "First, it looks like there is no payload for this event. Is that expected? It's a hard problem. Practically, there is only one case in which you drop a packet, post decryption success, and that is because it's a duplicate packet number. Other than that, all other drop events would occur before a packet is decrypted. If it can't be decrypted you don't know the packet number, which would likely be the most interesting payload of this event. So, therefor it likely isn't too useful in having the packet number as payload.\r\n\r\nSo, in absence of including the packet number as payload, it might just be worth having a \"reason\" which is a string. That's what winquic has already at least.",
      "createdAt": "2019-07-23T15:54:46Z",
      "updatedAt": "2019-10-07T17:03:30Z",
      "closedAt": "2019-10-07T17:03:30Z",
      "comments": []
    },
    {
      "number": 15,
      "id": "MDU6SXNzdWU0NzI4MTg2NjI=",
      "title": "Specify time units used for ack_delay",
      "url": "https://github.com/quicwg/qlog/issues/15",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "And probably for other non-timestamp time values (like RTT)\r\n\r\nOptions:\r\n- Force people to use the resolution set in the \"configuration\"\r\n- Choose a fixed resolution (always milli or always micro)\r\n- Allow people to indicate resolution inside .data of each event \r\n- Combination: default is milli, add config parameter to specify, allow overrides in the .data, etc.\r\n\r\nThanks @jlaine for reporting.",
      "createdAt": "2019-07-25T11:43:19Z",
      "updatedAt": "2019-10-14T09:24:55Z",
      "closedAt": "2019-10-14T09:24:55Z",
      "comments": [
        {
          "author": "jlaine",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I'd say the first option \"force people to use the resolution set in configuration\".",
          "createdAt": "2019-08-23T10:54:57Z",
          "updatedAt": "2019-08-23T10:54:57Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Fixed by 3c09877 through the \"first option\"",
          "createdAt": "2019-10-14T09:24:55Z",
          "updatedAt": "2019-10-14T09:24:55Z"
        }
      ]
    },
    {
      "number": 16,
      "id": "MDU6SXNzdWU0NzMwNTQ1NDU=",
      "title": "Support partial logs",
      "url": "https://github.com/quicwg/qlog/issues/16",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "@nibanks mentioned that the winquic implementation does logging in a circular buffer. If this runs out of space, the earliest logs (e.g., the ip addresses, initial connection ids, etc. might have been dropped).\r\n\r\nWe can't really force tools to support this, but potentially we can add text in the draft so people know they should take this into account.",
      "createdAt": "2019-07-25T20:26:05Z",
      "updatedAt": "2019-10-14T09:24:28Z",
      "closedAt": "2019-10-14T09:24:28Z",
      "comments": []
    },
    {
      "number": 17,
      "id": "MDU6SXNzdWU0NzMwNTg0NzU=",
      "title": "Simplify / fix group_id usage",
      "url": "https://github.com/quicwg/qlog/issues/17",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Right now, the group_id concept is -very- flexible. It can be in common_fields (e.g., 1 trace per connection) but it can also be in event_fields (combining several connections into 1 trace). That already puts quite a burden on tools to support this different approaches.\r\n\r\nThen, another problem comes up if you would have the same group_id across multiple traces (e.g., trace 1 has some events for group_id x, but trace 2 has some group_id x events as well.)\r\n\r\nNote: This concept was mainly added to support the spindump use case (https://github.com/EricssonResearch/spindump), CC @jariarkko. There, a network intermediary logs (aggregated) data on many connections and even protocols. It would be tedious for that setup to split everything out into separate traces. \r\n\r\nPossible solutions I currently see:\r\n- Only allow 1 of the options (e.g., group_id only in common_fields or only in event_fields). I'm not a big fan of this (common only is inflexible, event_fields only has much overhead)(also: common can be seen as a special case of event_fields, so that could be the implementation target)\r\n- Disallow the same group_id across different traces: I think this makes a lot of sense, my preference\r\n- Discard the whole group_id concept alltogether (in practice, this would lead to many different approaches in different tools. basically the same as event_fields only, only no standard way of calling the thing)\r\n\r\nAdditional suggestion: rename group_id to \"luid\" (locally unique identifier)\r\n\r\nThanks to @nibanks for reporting this",
      "createdAt": "2019-07-25T20:35:32Z",
      "updatedAt": "2020-09-05T16:21:06Z",
      "closedAt": "2020-09-05T16:21:06Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thinking about this some more and having implemented splitting traces on group_id in quicvis, I feel allowing group_ids across traces is still the best way to go. \r\n\r\nIf you're logging on multiple network intermediaries (so multiple vantage points) at once and then merge those logs, you will always have the same group_id split over multiple traces. However, each of those traces SHOULD then represent a different vantage_point. So the real restriction should be: cannot spread events from the same vantage point across different traces within the same qlog file. Put differently: each trace should contain only events from a single vantage point. \r\n\r\nAs such, we might rename group_id to flow_id instead, since that makes the semantics a bit clearer. That would say \"this event belongs to flow with flow_id x, as observed from entity y\".\r\n\r\nI am trying to think of a reason why you would want to combine events from different vantage points into the same trace, but can't seem to find a use case. Either way, that would require changing up how we define vantage_point now, since it's per-trace and not part of common_fields or event_fields. \r\n\r\nAny thoughts @nibanks? ",
          "createdAt": "2019-10-02T12:01:53Z",
          "updatedAt": "2019-10-02T12:01:53Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "Are there really people signed up to trace multiple different vantage points and put them all in the same file? I don't know about other companies, but getting logs from more than one machine all into the same file is practically impossible for the Windows scenario. Would it be so bad that the tools need to parse a file per vantage point?\r\n\r\nI want qlog to succeed, but the more complicated it it, the less the chance I see that of becoming a reality. IMO, this is a place where simplicity should win.",
          "createdAt": "2019-10-02T14:05:51Z",
          "updatedAt": "2019-10-02T14:09:23Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "1) About the use case of having multiple traces in 1 file, I'm not directly thinking of the Windows scenario or using this in production, but more about use cases such as research, education and case studies. There, it's handy to be able to group everything needed for a single \"context\" in a single file to be shared and interpreted easily. For production, automated gathering or aggregation in separate datastores is certainly also possible. The current setup does not prevent you loading separate files, 1 per vantage point, either.  \r\n\r\n2) I'm not sure how only allowing a single trace from a single vantage point per file would help the original problem that it's difficult for tool developers to deal with group_ids occurring across traces... client and server will still have events with the same group_id (e.g., ODCID)\r\n\r\n As such, I'm not 100% sure what you're proposing? Do you want to do away with the \"traces\" array and replace it with a single \"trace\" per qlog file? Or do you want to do away with group_id at the \"event_fields\" level, requiring each individual trace to only contain events from a single connection?\r\n\r\nIn the latter case, I think that would actually be an obstacle to adoption, since currently several implementers are simply logging all events on the server in a single trace, tagged with ODCID for later splitting. This is generally much simpler than generating a single file (or trace) per connection on the server. \r\n\r\nIf you want to do away with group_id completely, that would leave out a whole bunch of other use cases, e.g., in-network observers like spindump (https://github.com/EricssonResearch/spindump, CC @jariarkko, @ihlar). This might be good enough for the QUIC use case (though barely), but not if qlog would grow to a more flexible format. \r\n\r\nFor draft-01, I've decided to keep the setup as-is, since there are users employing group_ids already (e.g., quant). I did specify the intended uses a bit more and am certainly open to more discussion on this design. Will you be in Singapore, @nibanks?",
          "createdAt": "2019-10-14T08:58:25Z",
          "updatedAt": "2019-10-14T08:58:25Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "the `group_id` field was not seeing much use in practice and as discussed above had some issues.\r\n\r\nIt has been considerably simplified for draft02, from f5db7cdc8cd0cf37bfe5f1b0b4c54fc56ffc5f28 onward. ",
          "createdAt": "2020-09-05T16:21:06Z",
          "updatedAt": "2020-09-05T16:21:06Z"
        }
      ]
    },
    {
      "number": 19,
      "id": "MDU6SXNzdWU0OTAxODExOTk=",
      "title": "Make it possible to tie push_id to stream",
      "url": "https://github.com/quicwg/qlog/issues/19",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Thanks to @jlaine for reporting",
      "createdAt": "2019-09-06T07:46:24Z",
      "updatedAt": "2019-10-09T19:24:59Z",
      "closedAt": "2019-10-09T19:24:58Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Was added as \"associated_push_id\" to http.stream_type_set in dda4374878d6fa3aabe9406bd1f7f8706ac59c80",
          "createdAt": "2019-10-09T19:24:58Z",
          "updatedAt": "2019-10-09T19:24:58Z"
        }
      ]
    },
    {
      "number": 20,
      "id": "MDU6SXNzdWU0OTMyNjg4Njg=",
      "title": "Better qpack support",
      "url": "https://github.com/quicwg/qlog/issues/20",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Some comments from @lpardue on qpack support:\r\n\r\n> but how do you correlate a qpack header block event (or whatever you want to call it) to the header frame that it was carried in? maybe simply that header block event contains a stream_id for correlation\r\n\r\n> other option is add raw_header_block to the HeaderFrame event data\r\n\r\nThough that would still require additional events for encoder/decoder instructions, no?\r\n\r\n> a qpack event that can consist of encoder instructions, decoder instructions and/or header block\r\n\r\nSo this seems the better option then, combined with the stream_id and expectation that the qpack events are logged in the same order as HeaderFrame's... (though not sure how important the ordering is personally).\r\n\r\nOpen questions:\r\n- What about seeing what's in the dynamic table (or initial static table? or is that always the same?)? specific dynamic_table_updated event or... ?\r\n\r\n\r\n",
      "createdAt": "2019-09-13T11:12:21Z",
      "updatedAt": "2019-10-08T14:50:35Z",
      "closedAt": "2019-10-08T14:50:35Z",
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "> What about seeing what's in the dynamic table (or initial static table? or is that always the same?)? specific dynamic_table_updated event or... ?\r\n\r\nSome of this comes around to qlog design ethos - are you logging the message exchange objects or their effects or both (or some, depending on event types and deployment preference)?\r\n",
          "createdAt": "2019-09-13T11:18:25Z",
          "updatedAt": "2019-09-13T11:18:25Z"
        }
      ]
    },
    {
      "number": 21,
      "id": "MDU6SXNzdWU1MDE0NDY2MDA=",
      "title": "Make event names more consistent",
      "url": "https://github.com/quicwg/qlog/issues/21",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Change event names to the trend of \"metrics_updated\" instead of \"metric_update\".\r\nThis is what we use for \"packet_sent\" and \"packet_received\" etc. and it's nicer to have this everywhere. ",
      "createdAt": "2019-10-02T12:03:27Z",
      "updatedAt": "2019-10-04T10:41:15Z",
      "closedAt": "2019-10-04T10:41:15Z",
      "comments": []
    },
    {
      "number": 22,
      "id": "MDU6SXNzdWU1MDIxMzAxNzQ=",
      "title": "Mark events by their importance",
      "url": "https://github.com/quicwg/qlog/issues/22",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Not all events are equally useful in a debugging/tooling scenario.\r\nMark events according to order of usefulness/expectedness.\r\n\r\nFor example:\r\n- Core\r\n- Base\r\n- Extra",
      "createdAt": "2019-10-03T15:15:45Z",
      "updatedAt": "2019-10-04T10:41:15Z",
      "closedAt": "2019-10-04T10:41:15Z",
      "comments": []
    },
    {
      "number": 23,
      "id": "MDU6SXNzdWU1MDI1MjU5NTE=",
      "title": "Make triggers behave like mixins",
      "url": "https://github.com/quicwg/qlog/issues/23",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Since no-one is implementing triggers as top-level fields and it was always unclear how to best approach them, we should punt them to optional properties of the \"data\" field instead. This allows their flexibility without their overhead. \r\n\r\nSee also issue #7 ",
      "createdAt": "2019-10-04T09:20:09Z",
      "updatedAt": "2019-10-04T10:41:15Z",
      "closedAt": "2019-10-04T10:41:15Z",
      "comments": []
    },
    {
      "number": 24,
      "id": "MDU6SXNzdWU1MDM1NTYyMTM=",
      "title": "Replace specific events with a single encompassing event",
      "url": "https://github.com/quicwg/qlog/issues/24",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "We want to reduce the total amount of events as much as possible.\r\n\r\nEspecially specific events for things happening in reaction to the receipt of a specific frame in a packet (e.g., ACK, MAX_DATA, etc.) can be removed, since they can usually be inferred from that frame. Initially we had separate events for these (e.g., \"packet_acknowledged\" or \"flow_control_updated\" but those were rarely used in addition to packet_received events + many implementations do not defer frame handling from reception.\r\n\r\nOne notable exception is @nibank's msquic, which does not log all frames in a received packet, but rather does log only specific events (e.g., packet_acknowledged). One of the reasons is because he feels logging each packet in full does not scale. Another reason for this pattern might be that an implementation does not wish to log all types of frames OR conversely, does not want to log packet-level information at all but only very select frames. \r\n\r\nTo support this use case and still keep a low amount of event types, I will add a \"frame_parsed\" encompassing event. This will log the frame with its associated data, but without the encompassing packet-level data. This prevents re-defining semantics for many events. The downside is that you sometimes might want to log e.g., \"packet_acknowledged\" a long time after frame receipt. In that case, you would pretend you're parsing the frame only then. I feel this is a good trade-off to make here though. ",
      "createdAt": "2019-10-07T16:20:47Z",
      "updatedAt": "2019-10-07T17:03:31Z",
      "closedAt": "2019-10-07T17:03:31Z",
      "comments": []
    },
    {
      "number": 25,
      "id": "MDU6SXNzdWU1MDQ1MjcwNDA=",
      "title": "Additional triggers and info for dropped packets",
      "url": "https://github.com/quicwg/qlog/issues/25",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "The current text lists about 8 reasons for dropping packets.\r\nMicrosoft's implementation lists 60+ individual reasons (via @nibanks)\r\n\r\nSome of those:\r\n\r\n> LogDrop(\"Retry sent to server\");\r\nLogDrop(\"Already received server response\");\r\nLogDrop(\"No room for ODCID\");\r\nLogDrop(\"Invalid ODCID\");\r\nLogDrop(\"InitialToken alloc failed\");\r\nLogDrop(\"OrigCID alloc failed\");\r\nLogDrop(\"Max deferred datagram count reached\");\r\nLogDrop(\"Key no longer accepted\");\r\nLogDrop(\"SH packet during version negotiation\");\r\nLogDrop(\"Too short for HP\");\r\nLogDrop(\"Packet number too big\");\r\nLogDrop(\"Payload length less than encryption tag\");\r\nLogDrop(\"Generate new packet keys\");\r\nLogDrop(\"Decryption failure\");\r\nLogDrop(\"Invalid SH Reserved bits values\");\r\nLogDrop(\"Invalid LH Reserved bits values\");\r\nLogDrop(\"Duplicate packet number\");\r\nLogDrop(\"Key no longer accepted (batch)\");\r\nLogDrop(\"Failed to compute HP mask\");\r\nLogDrop(\"Different remote address\");\r\nLogDrop(\"Too small for Packet->Invariant\");\r\nLogDrop(\"LH no room for DestCID\");\r\nLogDrop(\"Zero length DestCID\");\r\nLogDrop(\"LH no room for SourceCID\");\r\nLogDrop(\"SH no room for DestCID\");\r\nLogDrop(\"DestCID don't match\");\r\nLogDrop(\"SourceCID don't match\");\r\nLogDrop(\"Greater than allowed max CID length\");\r\nLogDropWithValue(\"Invalid client/server packet type\", Packet->LH->Type);\r\nLogDrop(\"Invalid LH FixedBit bits values\");\r\nLogDrop(\"Long header has invalid token length\");\r\nLogDropWithValue(\"Long header has token length larger than buffer length\", TokenLengthVarInt);\r\nLogDrop(\"Long header has invalid payload length\");\r\nLogDropWithValue(\"Long header has length larger than buffer length\", LengthVarInt);\r\nLogDropWithValue(\"Long Header doesn't have enough room for packet number\",\r\nLogDrop(\"Invalid SH FixedBit bits values\");\r\nLogDrop(\"Non-initial packet not matched with a Connection\");\r\nLogDrop(\"Retry received after initial\");\r\n\r\nI feel that we don't need to list things in this level of detail in the qlog spec (the \"trigger\" field allows any text anyway). However, maybe some guidance text on this would be helpful and maybe a few more suggested triggers would be interesting. \r\n\r\n\r\n",
      "createdAt": "2019-10-09T09:29:23Z",
      "updatedAt": "2020-09-08T15:39:02Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 26,
      "id": "MDU6SXNzdWU1MDcwOTMyMTQ=",
      "title": "well-known URI might include an extension",
      "url": "https://github.com/quicwg/qlog/issues/26",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, we just use the ODCID directly as an identifier, without a \".qlog\" extension. \r\nIt might be interesting to include the extension, but I don't really have a good view on the pros and cons. ",
      "createdAt": "2019-10-15T08:38:34Z",
      "updatedAt": "2020-09-01T19:13:48Z",
      "closedAt": "2020-09-01T19:13:48Z",
      "comments": []
    },
    {
      "number": 27,
      "id": "MDU6SXNzdWU1MDcxMDcwNzU=",
      "title": "0-RTT is a bit ambiguous in -01",
      "url": "https://github.com/quicwg/qlog/issues/27",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "using transport.parameters_set there are two parameters to signal 0-RTT:\r\n- resumption_allowed\r\n- early_data_enabled\r\n\r\nAs pointed out by @jlaine, these are a bit ambiguous, as 0-RTT can either be used for the current connection or enabled for a future connection.\r\n\r\nSolution 1:\r\n- Rename parameters to resumption_accepted and early_data_accepted\r\n- Add new events: session_ticket_sent/received (with early_data_enabled?:boolean member)\r\n\r\nSolution 2:\r\n- Rename parameters to resumption_accepted and early_data_accepted\r\n- Add new parameters: resumption_offered and early_data_offered",
      "createdAt": "2019-10-15T09:03:47Z",
      "updatedAt": "2021-10-04T14:27:01Z",
      "closedAt": null,
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm not sure I agree that there's an ambiguity here, as TLS 1.3 clearly defines how the `early_data` extension is used. However, we currently can't log when 0-RTT is accepted / rejected (although you _could_ infer that by observing what values TLS sends).\r\nMaybe we should have separate events that indicate if resumption (with or without 0-RTT) was offered (on the client side), and on the server side, if it was accepted or rejected (for rejections, the reason might be interesting to log).",
          "createdAt": "2021-10-04T14:27:01Z",
          "updatedAt": "2021-10-04T14:27:01Z"
        }
      ]
    },
    {
      "number": 28,
      "id": "MDU6SXNzdWU1MDkwNTI3Mzg=",
      "title": "Lacking a way to indicate ALPN list for client",
      "url": "https://github.com/quicwg/qlog/issues/28",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Currently, we can log a list of supported ALPN values for the server in \"server_listening\" and log the finally selected ALPN in \"parameters_set\". However, we lack a way to log the list of ALPN values the client supports (and offers the server).\r\n\r\nOptions:\r\n- add `alpn_values?: Array<string> // ALPN values offered by the client / received by the server. Use parameters_set to log the actually selected alp` to \"connection_started\"\r\n- make \"alpn\" in \"parameters_set\" an array instead of a string\r\n\r\nI personally prefer the 1st option, since the second doesn't match the semantics of \"set\" (since it would be emitted twice) and logging the negotiation options should be optional in a \"Base\" (while the final value is in a \"Core\" event).\r\n\r\nCC @jlaine ",
      "createdAt": "2019-10-18T12:35:44Z",
      "updatedAt": "2020-11-03T11:51:22Z",
      "closedAt": "2020-11-03T11:51:21Z",
      "comments": [
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "The first option is fine. It is nice to distinguish between proposal and results.\r\nI could see for example:\r\n```\r\n\"alpn_values\": [ \"h3-27\", \"hq-27\", \"h3-25\", \"hq-25\" ],\r\n```\r\nAnd later:\r\n```\r\n\"alpn\": \"h3-27\",\r\n```\r\nBut there a few issues. For example, what happens if the qlog entry contains both `alpn_values` and `alpn`?",
          "createdAt": "2020-03-08T04:31:02Z",
          "updatedAt": "2020-03-08T04:33:46Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "I would prefer something like `proposed_alpn` instead of `alpn_values`, to emphasize that this is a proposal. This also has a nice way to solve the `proposed_alpn` vs `alpn` issues. For example, if a server logs:\r\n```\r\n\"proposed_alpn\": [ \"h3-27\", \"hq-27\", \"h3-25\", \"hq-25\" ],\r\n\"alpn\": \"h3-27\",\r\n```\r\nThat can be clear understood as \"the client proposed these 4 values, and the server selected the 1sr one\"\r\n",
          "createdAt": "2020-03-08T04:34:50Z",
          "updatedAt": "2020-03-08T04:35:24Z"
        },
        {
          "author": "jlaine",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I like the idea of strictly distinguishing offer values and the negotiated one. Alternative possible names (no strong feelings about this):\r\n\r\n```\r\n\"alpn_offer\": [\"a\", \"b\", \"c\"]\r\n\"alpn_answer\": \"a\"\r\n```",
          "createdAt": "2020-03-08T11:13:13Z",
          "updatedAt": "2020-03-08T11:13:28Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Added a separate `alpn_information` event for this. Not sure this is the best approach overall, but will see. Discussion on this continues in #85. ",
          "createdAt": "2020-11-03T11:51:21Z",
          "updatedAt": "2020-11-03T11:51:21Z"
        }
      ]
    },
    {
      "number": 29,
      "id": "MDU6SXNzdWU1MjAzNTE4MjY=",
      "title": "Utf-8",
      "url": "https://github.com/quicwg/qlog/issues/29",
      "state": "CLOSED",
      "author": "mocsy",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Draft 01 doesn't specify character encoding, but the ts files work with utf-8, don't they?\r\nI propose to standardize that choice as well.",
      "createdAt": "2019-11-09T07:35:27Z",
      "updatedAt": "2020-09-05T16:12:20Z",
      "closedAt": "2020-09-05T16:12:20Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Excellent point, I agree the encoding should be defined. ",
          "createdAt": "2019-11-09T07:38:34Z",
          "updatedAt": "2019-11-09T07:38:34Z"
        }
      ]
    },
    {
      "number": 30,
      "id": "MDU6SXNzdWU1MjQ4MjY3Nzg=",
      "title": "consider moving to a binary format",
      "url": "https://github.com/quicwg/qlog/issues/30",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "I just started working on implementing qlog in quic-go. Maybe it's because I'm still fairly unfamiliar with qlog, but I feel like encoding things in JSON leads to some awkward hacks. Examples of these are:\r\n* A lot of numbers are encoded as strings, e.g. stream offset or packet numbers. I assume this is because JSON doesn't properly handle uint64s (or does it?).\r\n* IP addresses are encoded as strings. If that means they're supposed to be encoded in the human-readable encoding (with . and :), that's ambiguous for IPv6 addresses. Really, IP addresses should be a byte array.\r\n* (Raw) packet data is supposed to be hex encoded, which greatly increases the log size.\r\n* Some fields are defined as enums, whereas other fields that just have a few options are encoded as strings. Examples are the `stream_side` (\"sending\" or \"receiving\") and `stream_type` (\"unidirectional\" or \"bidirectional\"), which are both string fields.\r\n\r\nI'm not sure if I like trick to save bytes on the `events` by first defining the `event_fields` and then using a list instead of an object to encode the `events`. To me, this feels more like a hack to work around the shortcomings of JSON, namely the repetition of the field labels when using objects.\r\nAs far as I can see, a binary encoding scheme would be able to provide a type-safe representation here without repeating the field labels (and blowing up the file size), as long as it's possible to define some `common_fields` for a connection.\r\n\r\nA protobuf-based logging format (This is just a suggestion. Protobufs are the thing I'm most familiar with, maybe there are better choices out there.) would resolve the encoding ambiguities I listed above, because we'd be able to make use of a strong typing system, which would allow us to completely eliminate the use of `string`s (except for places where things actually are strings, e.g. CONNECTION_CLOSE reason phrases). Furthermore, it would greatly simplify implementing qlog: Just fill in the corresponding fields in the Protobuf messages, call `Marshal()`, and you're done. No need to manually define dozens of logging structs and make sure they're correctly serialized into qlog's flavor of JSON.",
      "createdAt": "2019-11-19T07:30:57Z",
      "updatedAt": "2020-09-05T16:22:44Z",
      "closedAt": "2020-09-05T16:22:44Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Talking about this with @nibanks, he would primarily like this for larger traces (he has logs of several 100s of megabytes) and for integration with other tools (like https://docs.microsoft.com/en-us/windows-hardware/test/wpt/windows-performance-analyzer).\r\n\r\nHe suggests https://diamon.org/ctf/ as one possible format (though, at first glance, this doesn't have a JavaScript parser somewhere). ",
          "createdAt": "2020-01-07T16:05:08Z",
          "updatedAt": "2020-01-07T16:05:08Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "There is related experience with DNS log formats. In particular, look at the CBOR encoding of DNS logs proposed in RFC 8618, https://datatracker.ietf.org/doc/rfc8618/. They started from PCAP, but there was a practical issue with managing huge PCAP files. The first attempt was to just try compress the binary, but they ended up with a more structured approach. The logical syntax follows the \"natural\" repetitions in the data, managing to get for example DNS names encoded just once, and then represented by indices in the tables of names. Then they encode the \"syntactically organized\" data in CBOR (binary JSON), and they apply compression on top of that.\r\n\r\nThe main value of the logical syntax comes when processing logs. For example, I observed a factor 50 performance gain between doing DNS statistics directly on the PCAP and doing the same statistics on the logical CBOR data, due to both reduced IO with shorter data, and more compact code following logical references.\r\n\r\nI suspect there is something similar hiding in the Quic traces.",
          "createdAt": "2020-02-26T01:05:34Z",
          "updatedAt": "2020-02-26T01:05:34Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "@huitema that's some very interesting stuff that I wasn't aware of yet, thanks!",
          "createdAt": "2020-02-26T09:51:43Z",
          "updatedAt": "2020-02-26T09:51:43Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Talking about it some more with @nibanks, he states:\r\n\r\n> I'd prefer something that is light-weight and doesn't depend on yet another thing (protobuf). Or something that exists and is light weight to implement a parser for from scratch\r\n\r\n@LPardue did some initial tests with CBOR and found the file size gains not to really outweigh compressed JSON. \r\n\r\nI am currently experimenting with a few binary scheme options to get a first feel for potential file size and (de)serialization gains. That should give us some additional data to work from. ",
          "createdAt": "2020-03-17T15:24:30Z",
          "updatedAt": "2020-03-17T15:24:30Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "To be clear I am no CBOR expert. All I did for my serializing code was substitute out serde_json for serde_cbor and compare the resulting output. CBOR shaved off 10% of identity encoding, gzipped-json shaved off about 40%.\r\n\r\nAFAIK It is possible to profile CBOR to be more efficient (e.g. https://tools.ietf.org/html/draft-raza-ace-cbor-certificates-04) but that is beyond my skillset.\r\n",
          "createdAt": "2020-03-17T23:06:52Z",
          "updatedAt": "2020-03-17T23:06:52Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "I am quite familiar with the work on using CBOR to record DNS traces in RFC 8618. The captures were originally in PCAP, but PCAP gets very large files. They looked at a set of variations:\r\n\r\n|  Format      | File size | Comp. | Comp. size |   RSS | User time |\r\n| --------- | --------- | ----- | ---------- | ----- | --------- |\r\n| PCAP        |    661.87 | snzip |     212.48 |  2696 |      1.26 |\r\n|             |           | lz4   |     181.58 |  6336 |      1.35 |\r\n|             |           | gzip  |     153.46 |  1428 |     18.20 |\r\n|             |           | zstd  |      87.07 |  3544 |      4.27 |\r\n|             |           | xz    |      49.09 | 97416 |    160.79 |\r\n|             |           |       |            |       |           |\r\n| JSON simple |   4113.92 | snzip |     603.78 |  2656 |      5.72 |\r\n|             |           | lz4   |     386.42 |  5636 |      5.25 |\r\n|             |           | gzip  |     271.11 |  1492 |     73.00 |\r\n|             |           | zstd  |     133.43 |  3284 |      8.68 |\r\n|             |           | xz    |      51.98 | 97412 |    600.74 |\r\n|             |           |       |            |       |           |\r\n| Avro simple |    640.45 | snzip |     148.98 |  2656 |      0.90 |\r\n|             |           | lz4   |     111.92 |  5828 |      0.99 |\r\n|             |           | gzip  |     103.07 |  1540 |     11.52 |\r\n|             |           | zstd  |      49.08 |  3524 |      2.50 |\r\n|             |           | xz    |      22.87 | 97308 |     90.34 |\r\n|             |           |       |            |       |           |\r\n| CBOR simple |    764.82 | snzip |     164.57 |  2664 |      1.11 |\r\n|             |           | lz4   |     120.98 |  5892 |      1.13 |\r\n|             |           | gzip  |     110.61 |  1428 |     12.88 |\r\n|             |           | zstd  |      54.14 |  3224 |      2.77 |\r\n|             |           | xz    |      23.43 | 97276 |    111.48 |\r\n|             |           |       |            |       |           |\r\n| PBuf simple |    749.51 | snzip |     167.16 |  2660 |      1.08 |\r\n|             |           | lz4   |     123.09 |  5824 |      1.14 |\r\n|             |           | gzip  |     112.05 |  1424 |     12.75 |\r\n|             |           | zstd  |      53.39 |  3388 |      2.76 |\r\n|             |           | xz    |      23.99 | 97348 |    106.47 |\r\n|             |           |       |            |       |           |\r\n| JSON block  |    519.77 | snzip |     106.12 |  2812 |      0.93 |\r\n|             |           | lz4   |     104.34 |  6080 |      0.97 |\r\n|             |           | gzip  |      57.97 |  1604 |     12.70 |\r\n|             |           | zstd  |      61.51 |  3396 |      3.45 |\r\n|             |           | xz    |      27.67 | 97524 |    169.10 |\r\n|             |           |       |            |       |           |\r\n| Avro block  |     60.45 | snzip |      48.38 |  2688 |      0.20 |\r\n|             |           | lz4   |      48.78 |  8540 |      0.22 |\r\n|             |           | gzip  |      39.62 |  1576 |      2.92 |\r\n|             |           | zstd  |      29.63 |  3612 |      1.25 |\r\n|             |           | xz    |      18.28 | 97564 |     25.81 |\r\n|             |           |       |            |       |           |\r\n| CBOR block  |     75.25 | snzip |      53.27 |  2684 |      0.24 |\r\n|             |           | lz4   |      51.88 |  8008 |      0.28 |\r\n|             |           | gzip  |      41.17 |  1548 |      4.36 |\r\n|             |           | zstd  |      30.61 |  3476 |      1.48 |\r\n|             |           | xz    |      18.15 | 97556 |     38.78 |\r\n|             |           |       |            |       |           |\r\n| PBuf block  |     67.98 | snzip |      51.10 |  2636 |      0.24 |\r\n|             |           | lz4   |      52.39 |  8304 |      0.24 |\r\n|             |           | gzip  |      40.19 |  1520 |      3.63 |\r\n|             |           | zstd  |      31.61 |  3576 |      1.40 |\r\n|             |           | xz    |      17.94 | 97440 |     33.99 |\r\n\r\nYou can see that there are some differences between various algorithms. JSON clearly gets bigger sizes there than the binary alternatives, even after compression. But the biggest differences come from switching from what they call \"simple\" to what they call \"block\".\r\n\r\nThe simple alternative is pretty similar to the current Qlog. Each DNS transaction is represented by a corresponding record in JSON, CBOR, Avro or protobuf. In contrast, the \"block\" format starts by building tables of objects seen in multiple records: table of DNS names, table to record values, etc. Then the individual PCAP records are represented by \"block records\" which instead of listing DNS names simply list the index of the name in the table of names. You can think of that as a \"logical compression\", and it does reduces the size of the recording by a factor 10x. After that, they can still apply compression.\r\n\r\nThe real beauty of the block format comes when processing the data in back end programs. Compare:\r\n```\r\nuncompress < pcap.xz | process-pcap\r\n```\r\nTo:\r\n```\r\nuncompress < cbor.xz | process-cbor\r\n```\r\nIn the cbor alternative, there are about 10 times fewer data piped into the analysis program than in the pcap alternative. That's a much lower IO load. On top of that, since the cbor data is structured in blocks, parsing and processing is much easier, resulting in a much lower CPU load. In a project that I was involved with, replacing process-pcap by process-cbor made us run 40 times faster!\r\n\r\nAlso note that there are no practical differences between the various binary alternatives. yes, +- 10% here or there, but compared to a factor 40 that's really in the noise.",
          "createdAt": "2020-03-18T00:58:46Z",
          "updatedAt": "2020-03-18T00:58:46Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thanks a lot for that @huitema. Doing something similar to the \"block format\" would be trivial for qlog as well. However, it mismatches with how I thought general purpose compression works in my head... don't those algorithms also build that type of lookup-table on the fly? I will test with manual block formats as well and see what that gives.\r\n\r\nAnother interesting ref from @martinthomson https://tools.ietf.org/html/draft-mattsson-tls-cbor-cert-compress-00",
          "createdAt": "2020-03-18T11:10:58Z",
          "updatedAt": "2020-03-18T11:10:58Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So I've been doing some tests of my own to figure out the best approach to this for qlog.\r\n\r\nI've created converter scripts (see https://github.com/quiclog/pcap2qlog/tree/binary/src/converters) that use a lookup table/dictionary instead of repeating values, one that cbor encodes the files and a (rudimentary) protobuf schema. The dictionary is currently fully dynamic and stored inside the resulting file, but this can obviously be improved by having a static shared dictionary with a dynamic part for just the field values (much like QPACK and Chrome's NetLog). \r\n\r\nI've then also looked at various compression schemes (https://github.com/quiclog/pcap2qlog/blob/binary/src/scripts/comparisons/compare.sh) (xz, gzip, brotli, zstd, lz4), focusing mainly on the schemes most often seen on the web for on-the-fly compression (gzip 6 and brotli 4).\r\n\r\nFull results can be found at https://gist.github.com/rmarx/49bb14f83157d9fe59fb40e7c05b1f3f, a bit nicer representation in the following image (sizes for traces in which a 500MB or 100MB file were downloaded from the lsquic public endpoint). The blue value is the reference point for the percentages, green is the \"best in class\" for that row:\r\n\r\n![2020-04-22 11_27_11-results xlsx - Excel](https://user-images.githubusercontent.com/2240689/79965403-410ed380-848c-11ea-9d66-b1a90bd4bc72.png)\r\n\r\n\r\nMain takeaways for me:\r\n1. protobuf is the smallest, but not by a huge margin compared to dictionary+cbor, especially not when compression is used.\r\n2. compression alone saves massively, even on the original JSON file or direct CBOR version of that\r\n3. protobuf without compression is still quite large (23% of original), so I'd reckon you'd always use compression for storage/transmission anyway? \r\n\r\nNext to these tests, we also ran a survey among QUIC experts (implementers and researchers), on which we got replies from 28 participants (thanks everyone!). Part of the survey was to ask how important they felt features like \"fast (de)serialization, small file size, flexibility (e.g., easily add new event types), grep-ability\" were. The full results will be posted soon (are part of a publication we're preparing), but the gist of it is:\r\n\r\n![2020-04-22 11_37_40-QUIC and HTTP_3 Debugging Survey - March 2020 - Google Forms](https://user-images.githubusercontent.com/2240689/79966456-c050d700-848d-11ea-9113-d9c2a230d8ab.png)\r\n\r\nMy interpretation:\r\n1. Flexibility is the major selling point across the board. I personally believe moving to something like protobuf sort of robs us from that (much more difficult to add new event types as you have to update the schema)\r\n2. Most don't care too much about (de)serialization performance\r\n3. Small file size was regarded as important, but again not as much as flexibility. \r\n4. grep-ability was also considered an important feature by many\r\n5. easy integration is also a major point and this would be easier with something like protobuf\r\n\r\nFinally, we also talked to Facebook (cc @mjoras), who have been deploying qlog at scale, logging over 30 billion qlog events per day. Compared to their earlier binary format, qlog is about 2-3x larger and takes 50% longer to serialize. Yet, this is quite manageable on the server side, where they log full-string JSON events to a centralized service. On the client, they do find the file-size to be prohibitive to upload granular full qlogs (containing all events they'd like). Yet, Matt was also adamant that they'd rather keep the flexibility of the JSON format than move to a more inflexible binary one. They were considering utilizing compression and writing a custom JSON (de)serializer, optimized for qlog, to help deal with some of the overhead. \r\n\r\n----------------------------------\r\n\r\nSo, presented with those results, my standpoint today is still to keep using JSON as the basis for qlog. I would propose to add the \"dictionary\" setup to the spec though, as an optional optimized mode and also recommend tools to support that (not sure about a default static dictionary at this point though). Furthermore, I'd recommend using cbor if file size is important. \r\n\r\nCompanies that do need more optimizations can write their own protobuf (or equivalent) schema (which I've shown is possible) and then write a post-processor to go to proper JSON qlog for shared tooling. \r\n\r\nStill, feedback on all this is more than welcome of course! @marten-seemann, @martinthomson, @huitema, @LPardue, @nibanks, @mjoras\r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2020-04-22T09:50:22Z",
          "updatedAt": "2020-04-22T09:50:22Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "If we use cbor, does that mean that we can get rid of the `event_fields`? Having implemented a both an encoder as well as a parsing tool, this complicated things quite a bit for me (over just encoding an event as a normal JSON object).",
          "createdAt": "2020-04-22T09:56:02Z",
          "updatedAt": "2020-04-22T09:56:02Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "With the latest commit linked above (https://github.com/quiclog/internet-drafts/commit/eb59e69aa0f92031d8a2377575b7328429440061), I feel this issue has been resolved.\r\n\r\nqlog has not moved to a binary format by default, but is now much easier to serialize as one/to define a binary schema for. Some of the reasoning behind that has also been included in the qlog document. ",
          "createdAt": "2020-09-05T16:22:44Z",
          "updatedAt": "2020-09-05T16:22:44Z"
        }
      ]
    },
    {
      "number": 31,
      "id": "MDU6SXNzdWU1MzA1NzkzNjI=",
      "title": "Typo in path response frame definition",
      "url": "https://github.com/quicwg/qlog/issues/31",
      "state": "CLOSED",
      "author": "mpiraux",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "```\r\n### PathResponseFrame\r\n\r\n~~~\r\nclass PathResponseFrame{\r\n  frame_type:string = \"patch_response\";\r\n\r\n  data?:string;\r\n}\r\n~~~\r\n```\r\n\r\n`patch_response` should be `path_response`.",
      "createdAt": "2019-11-30T13:30:20Z",
      "updatedAt": "2020-09-07T13:29:02Z",
      "closedAt": "2020-09-07T13:29:02Z",
      "comments": []
    },
    {
      "number": 32,
      "id": "MDU6SXNzdWU1NDYzMzIyODQ=",
      "title": "Mention JSON earlier",
      "url": "https://github.com/quicwg/qlog/issues/32",
      "state": "CLOSED",
      "author": "dtikhonov",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "The fact that qlog is in JSON format is not mentioned until section 3.3.4 of the main logging schema draft.  This should be stated earlier: before any JSON examples are given.",
      "createdAt": "2020-01-07T15:02:10Z",
      "updatedAt": "2020-09-05T16:04:17Z",
      "closedAt": "2020-09-05T16:04:17Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Fixed in f5db7cdc8cd0cf37bfe5f1b0b4c54fc56ffc5f28",
          "createdAt": "2020-09-05T16:04:17Z",
          "updatedAt": "2020-09-05T16:04:17Z"
        }
      ]
    },
    {
      "number": 33,
      "id": "MDU6SXNzdWU1NDYzMzM5OTQ=",
      "title": "Well-known URI: uppercase or lowercase",
      "url": "https://github.com/quicwg/qlog/issues/33",
      "state": "CLOSED",
      "author": "dtikhonov",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Whether ODCID in the well-known URI is uppercase or lowercase should be specified.",
      "createdAt": "2020-01-07T15:05:21Z",
      "updatedAt": "2020-09-01T19:13:38Z",
      "closedAt": "2020-09-01T19:13:38Z",
      "comments": []
    },
    {
      "number": 34,
      "id": "MDU6SXNzdWU1NDk5MDA3MzI=",
      "title": "Consolidate repeated padding frames?",
      "url": "https://github.com/quicwg/qlog/issues/34",
      "state": "CLOSED",
      "author": "agrover",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Padding frames contain no information, but when eyeballing a qlog for the start of a connection, they swamp more interesting things.\r\n\r\nIt's a bit of a cheat, given that qlog otherwise is 1:1 between packet contents and logging, but I was wondering if a more compact representation of repeated padding frames might be nice.\r\n\r\nThis is less about qlog file size -- I'm assuming repeated padding entries in json would compress amazingly -- more about human readability.\r\n\r\nI see pros and cons, but wanted to raise it as an issue. Cheers.",
      "createdAt": "2020-01-15T00:45:26Z",
      "updatedAt": "2020-09-07T13:28:39Z",
      "closedAt": "2020-09-07T13:28:39Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I'm very confused at the moment, because I was sure I had already added this to the editor's draft for version -02, but... apparently not? \r\n\r\nSo yes, I definitely think this is a good idea. At one point, Facebook was logging 1 padding frame for each byte of padding and that was horrendous. \r\n\r\nI thought about just adding a \"length\" field to the padding frame, indicating the amount of bytes padded. Would you agree that's the correct approach? \r\n\r\n",
          "createdAt": "2020-01-15T07:29:55Z",
          "updatedAt": "2020-01-15T07:29:55Z"
        },
        {
          "author": "hawkinsw",
          "authorAssociation": "NONE",
          "body": "> I'm very confused at the moment, because I was sure I had already added this to the editor's draft for version -02, but... apparently not?\r\n> \r\n> So yes, I definitely think this is a good idea. At one point, Facebook was logging 1 padding frame for each byte of padding and that was horrendous.\r\n> \r\n> I thought about just adding a \"length\" field to the padding frame, indicating the amount of bytes padded. Would you agree that's the correct approach?\r\n\r\nThat sounds like a pretty good idea to me. It also seems to \"mirror\" the approach that Wireshark takes?\r\n![Screenshot from 2020-01-15 03-52-38](https://user-images.githubusercontent.com/8715530/72419310-911e2180-374a-11ea-8520-1b8f99a34a12.png)\r\n",
          "createdAt": "2020-01-15T08:53:33Z",
          "updatedAt": "2020-01-15T08:53:33Z"
        },
        {
          "author": "agrover",
          "authorAssociation": "NONE",
          "body": "> I thought about just adding a \"length\" field to the padding frame, indicating the amount of bytes padded. Would you agree that's the correct approach?\r\n\r\nSounds good to me!",
          "createdAt": "2020-01-16T18:48:52Z",
          "updatedAt": "2020-01-16T18:48:52Z"
        }
      ]
    },
    {
      "number": 35,
      "id": "MDU6SXNzdWU1NTE3NTE3NjI=",
      "title": "Add guidance to server developers",
      "url": "https://github.com/quicwg/qlog/issues/35",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "@marten-seemann asked how to best approach logging from a server's perspective, given that things like version negotiation and stateless retry are not inherently tied to a single connection. We should add some informative guidance on how to best approach this to the spec, depending on how much state you're willing to keep around \r\n\r\nSome options:\r\n\r\n1. low state: keep a separate qlog file for the entire server. This logs vneg, retry, etc.. Then, when a connection is truly accepted, start a new .qlog for the individual connection, containing all events thereafter. The server.qlog can then also contain an event signalling the acceptance of a new connection for later cross-linking between the files.\r\n2. low state: keep a single huge qlog file for everything, using the \"group_id\" field to allow later de-multiplexing into separate connections (I believe quant does this atm)\r\n3. stateful: if you already track vneg/retry and link them up with the final connection, you can output them in the per-connection qlog file as well\r\n\r\nMaybe also shortly talk about some of the trade-offs in each option. Also talk about how to approach server-level events like server_listening and packet_dropped in separate scenarios. ",
      "createdAt": "2020-01-18T10:33:53Z",
      "updatedAt": "2020-11-01T13:04:40Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 36,
      "id": "MDU6SXNzdWU1NTE3NTUxNTg=",
      "title": "Require specific encoding for string fields",
      "url": "https://github.com/quicwg/qlog/issues/36",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "For example, NewTokenFrame doesn't really need a length field if the encoding of the token is specified (e.g., if it is hex-encoded, byte-length is 2x token.length).\r\n\r\nWe already indicate hex-encoding at other places in the text (e.g., for version), maybe it's a good idea to enforce this across the board (then also specificy whether it should have 0x prefix or not etc. + examples).\r\n\r\nThanks to @marten-seemann for reporting",
      "createdAt": "2020-01-18T11:08:45Z",
      "updatedAt": "2020-09-05T16:23:16Z",
      "closedAt": "2020-09-05T16:23:16Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "This also applies to the NEW_CONNECTION_ID frame.",
          "createdAt": "2020-01-18T14:43:29Z",
          "updatedAt": "2020-01-18T14:43:29Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Could this be as easy as saying that all byte-values are hex-encoding (omitting the 0x) somewhere in the introduction? Then this would apply to connection IDs, Retry tokens, NEW_TOKEN tokens, stateless reset tokens, etc.",
          "createdAt": "2020-07-08T09:01:57Z",
          "updatedAt": "2020-07-08T09:01:57Z"
        }
      ]
    },
    {
      "number": 37,
      "id": "MDU6SXNzdWU1NTE3NTc4MjA=",
      "title": "missing HANDSHAKE_DONE frame",
      "url": "https://github.com/quicwg/qlog/issues/37",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2020-01-18T11:35:17Z",
      "updatedAt": "2020-01-18T15:31:42Z",
      "closedAt": "2020-01-18T15:31:42Z",
      "comments": []
    },
    {
      "number": 39,
      "id": "MDU6SXNzdWU1NTE3ODA4OTQ=",
      "title": "Be more consistent in numbers vs strings for (potentially) large numbers (varints)",
      "url": "https://github.com/quicwg/qlog/issues/39",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Now, we only make varints strings if it's likely they will go over 2^53 (JSON's / JavaScript's number limit). \r\n\r\nFor example, this means error codes are just numbers, even though they are varints, as it's unlikely to see a very large error code. However, for fields that are greased (e.g., see https://github.com/quicwg/base-drafts/pull/3360) they could be larger and a number no longer suffices.\r\n\r\nSee also dcil and scil in PacketHeader, which could be numbers but are now strings.\r\n\r\nMore in general: maybe it's best to simply allow both for all number fields and have the tools figure it out? ",
      "createdAt": "2020-01-18T15:07:33Z",
      "updatedAt": "2020-09-07T13:19:00Z",
      "closedAt": "2020-09-07T13:19:00Z",
      "comments": [
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "For me it would be very unnatural to treat Quic integers (varint encoded) as strings instead of numbers. Not impossible of course, one could always add quotes. But very unnatural.\r\n",
          "createdAt": "2020-02-26T00:54:29Z",
          "updatedAt": "2020-02-26T00:54:29Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "An approach some people are using for extension experimentation IS to pick large values for frame type, settings, stream types, etc. ",
          "createdAt": "2020-05-25T13:03:08Z",
          "updatedAt": "2020-05-25T13:03:08Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "@LPardue people do pick large numbers for experimentation, but the numbers are typically 2 bytes:\r\n```\r\nFrame types:\r\n    ack_frequency = 0xAF,\r\n    time_stamp = 757\r\nTP:\r\n    test_large_chello = 3127,\r\n    enable_loss_bit_old = 0x1055,\r\n    enable_loss_bit = 0x1057,\r\n    min_ack_delay = 0xDE1A,\r\n    enable_time_stamp = 0x7157\r\n```\r\nEven if we add another byte for versioning, traditional JSON will work just fine.",
          "createdAt": "2020-05-25T14:39:55Z",
          "updatedAt": "2020-05-25T14:39:55Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "The plan is to switch away from JSON/TypeScript notation in the draft and use explicit type annotations (e.g., uint32, uint64, etc.).\r\n\r\nThen I'd add something stating that, if using a JSON format, you should decide yourself between a) encoding 64-bit values as strings or b) hope they won't be larger than 2^53 and log them as numbers. Tools would be strongly advised to support both string and number variants of these fields. ",
          "createdAt": "2020-05-25T15:02:24Z",
          "updatedAt": "2020-05-25T15:03:02Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "and PRIORITY_UPDATE is using `0x1CCB8BBF1F0700` :)\r\n\r\nIt will be more difficult to make a general purpose library that can do what Robin suggests on the serialization side. It might also make it hard on the deserialization side in my specific implementation. \r\n\r\nThat said, I really dislike the arbitrary schema inconstencies that exist today. So on balance I look forward to the proposed approach.",
          "createdAt": "2020-05-25T15:19:41Z",
          "updatedAt": "2020-05-25T15:19:41Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "If only we knew someone from the H3 Priorities team that could help mitigate that weirdly large Frame identifier... ",
          "createdAt": "2020-05-25T15:25:30Z",
          "updatedAt": "2020-05-25T15:25:30Z"
        }
      ]
    },
    {
      "number": 40,
      "id": "MDU6SXNzdWU1NTE4Njk2MDE=",
      "title": "packet_size doesn't belong in the PacketHeader, but PacketType does",
      "url": "https://github.com/quicwg/qlog/issues/40",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "In my interpretation, the `PacketHeader` is a QUIC packet header. Therefore, it should contain the QUIC packet type.\r\nHowever, the `packet_size` (as opposed to the `payload_length`, which is the length of the QUIC payload e.g. in a coalesced packet), is a property of the UDP packet, and therefore should a property of the `packet_sent` / `packet_received` event.",
      "createdAt": "2020-01-19T05:27:36Z",
      "updatedAt": "2020-11-02T16:57:19Z",
      "closedAt": "2020-11-02T16:57:19Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "While I -think- I agree with the general sentiment, this is a major departure from the current setup as implemented in most qlog setups. Additionally, many qvis visualizations actively use these fields.\r\n\r\nI propose to keep the issue and PR open until when I can update qvis to deal with this change, so that I don't forget to do just that. Definitely before draft-02 lands of course.\r\n\r\nAdditionally, `packet_size` is intended to mean the entire size of the QUIC packet (header + payload), not the UDP datagram size (which can span multiple coalesced QUIC packets as you indicate). I felt the separate packet_size was needed to get an estimate of the header size, since that can differ quite a bit depending on the chosen encodings, pn-length etc. That does bring up the question if we need a `datagram_size/length` outside of the `datagram_*` events as well (though I personally would say not).",
          "createdAt": "2020-01-19T10:31:18Z",
          "updatedAt": "2020-01-19T10:31:18Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I initially moved `packet_size` to `packet_sent` and `packet_received`, which was the simplest solution. \r\n\r\nHowever, when considering other issues around indicating packet and frame sizing, I ended up deciding to go for a generalized solution by using a shared RawInfo struct. This means that packet lengths are now logged as `packet_sent:raw.length` instead of `packet_sent:packet_size`. This isn't as clear, I agree, but it is consistent with how we log lengths for other things in qlog, which was more important for me at this time. Given that implementers have to move the packet_size field out of PacketHeader anyway, it shouldn't matter too much if they move it to `raw.length` I'd expect. ",
          "createdAt": "2020-11-02T16:57:19Z",
          "updatedAt": "2020-11-02T16:57:19Z"
        }
      ]
    },
    {
      "number": 42,
      "id": "MDU6SXNzdWU1NTE5MDYyODU=",
      "title": "Think about usage in proxies",
      "url": "https://github.com/quicwg/qlog/issues/42",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "If qlog is used on a proxy, the question becomes what vantage_point it should use for its traces, since it's now simultaneously accepting and opening connections, and thus behaves as both a client and a server.\r\n\r\nOne approach would be to have (two) separate traces with separate vantage_points, but if there is a 1-to-1 mapping between client -> proxy -> origin connections, it -might- make sense to log everything into one trace (though I would need to reflect more on this). \r\n\r\nIn this latter case, it might make sense to add a \"role\" or \"vantage_point\" indication to events like `connection_started`.\r\n\r\nThanks to @hawkinsw for reporting.\r\nMaybe @LPardue has some comments, given his experience with the proxy-ing use case? ",
      "createdAt": "2020-01-19T11:08:11Z",
      "updatedAt": "2020-09-08T15:40:36Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 43,
      "id": "MDU6SXNzdWU1NTI3ODIwOTc=",
      "title": "Add connection_closed or connection_dropped event",
      "url": "https://github.com/quicwg/qlog/issues/43",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Currently, we rely on packet_* with a CONNECTION_CLOSE frame, but that's not always enough. E.g., the server can decide to drop a connection after a long timeout without sending a CONNECTION_CLOSE. Or, we might want additional information of when a connection is effectively dropped completely (according to @marten-seemann: is supposed to happen 3 PTOs after it is retired)\r\n\r\nMaybe a connection_closed event with a trigger field suffices? Should this be importance Base or Extra?",
      "createdAt": "2020-01-21T10:23:18Z",
      "updatedAt": "2020-11-02T20:14:21Z",
      "closedAt": "2020-11-02T20:14:21Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So I'm currently breaking my head on this one as there are a lot of aspects to closing connections in QUIC:\r\n\r\n1. there are three different states: closing, draining, actually closed\r\n2. there are many different reasons for \"closing\": idle timeout/handshake timeout, \"immediate close\", stateless reset, no overlapping versions, ...\r\n3. within immediate close, there are different error spaces: connection errors, application errors (which don't always reflect the actual internal error properly)\r\n\r\nCurrently (see draft02 branch), these things are kind of spread out across three different events:\r\n- connectivity:connection_state_updated\r\n- generic:connection_error\r\n- generic:application_error\r\n\r\nCombining this into a single `connection_closed` event with all that flexibility would thus lead to some serious duplication across the board..., not to mention a very complex event\r\n\r\nHowever, looking at https://github.com/lucas-clemente/quic-go/pull/2501/files, which seems the main use case for @marten-seemann at least, all he really cares about is logging a free-form string \"reason\" for a connection_closed event, as well as having a separate event type so it's easy to query just the `connection_closed`, instead of having to sift through `connection_state_updated`. \r\n\r\nSo, my proposal would be to add `connection_closed` as a quite high-level event, mainly useful for manual interpretation, referring to the other existing events if the need arises to log more fine-grained info. \r\n\r\nThus, the proposed design of `connection_closed` for draft-02:\r\n\r\n```\r\n{\r\n        owner?:\"local\"|\"remote\",\r\n\r\n        connection_error_code?:uint32,\r\n        application_error_code?:uint32,\r\n     \r\n        reason?:string\r\n}\r\n\r\nTriggers:\r\n* clean\r\n* handshake_timeout\r\n* idle_timeout\r\n* error // basically the \"immediate close\" case\r\n* stateless_reset\r\n* version_mismatch\r\n```\r\n(reminder, in qlog, each event has an implicit trigger field, which can contain any string value, so other triggers would be valid here as well)\r\n\r\nI'm not particularly happy with this design, but it's better than others I could come up with.\r\n\r\nDoes this suit your use case @marten-seemann? Can you let me know by tomorrow evening (2nd November)? Thanks! \r\n\r\n",
          "createdAt": "2020-11-01T15:39:58Z",
          "updatedAt": "2020-11-01T15:39:58Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Why do we need `generic:connection_error` and a `generic:application_error`?",
          "createdAt": "2020-11-02T08:07:26Z",
          "updatedAt": "2020-11-02T08:07:26Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Merged connection_error and application_error with connection_closed, as that indeed makes more sense here. \r\n\r\nClosing for now, open to revisiting this for draft-03. ",
          "createdAt": "2020-11-02T20:14:21Z",
          "updatedAt": "2020-11-02T20:14:21Z"
        }
      ]
    },
    {
      "number": 44,
      "id": "MDU6SXNzdWU1NTI3ODM1MDc=",
      "title": "Revise design of dual-endpoint events",
      "url": "https://github.com/quicwg/qlog/issues/44",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "current-version"
      ],
      "body": "Currently, we have some events that are used both for indicating changes in the local as well as the remote endpoint. An example is parameters_set, which logs both connection params we set locally, as the ones we get from the other side. parameters_set uses an \"owner\" field to disambiguate between these two cases. \r\n\r\nHowever, other events with similar purpose, like connection_id_updated, use another approach (src_ vs dst_ prefixes). We should decide on a singular consistent approach (currently leaning towards \"owner\" field myself, as it is the most flexible)",
      "createdAt": "2020-01-21T10:25:48Z",
      "updatedAt": "2021-08-18T10:02:53Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 45,
      "id": "MDU6SXNzdWU1NTI3ODQ2MDM=",
      "title": "Reduce importance of connection_id_updated",
      "url": "https://github.com/quicwg/qlog/issues/45",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, it is a Core event.\r\nHowever, as pointed out by @marten-seemann, not all implementations track when the remote endpoint changes their CID (e.g., looks when they first receive a packet with a new CID). In those cases, they might decide to take the log filesize hit by just logging the CID for each incoming PacketHeader.\r\n\r\nAs such, the connection_id_updated should probably be a Base event, with guidance on when to use which option.",
      "createdAt": "2020-01-21T10:27:41Z",
      "updatedAt": "2020-09-07T13:24:26Z",
      "closedAt": "2020-09-07T13:24:26Z",
      "comments": []
    },
    {
      "number": 46,
      "id": "MDU6SXNzdWU1NTM2MzIzNjY=",
      "title": "Updates for draft-25",
      "url": "https://github.com/quicwg/qlog/issues/46",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "For now, there's just one I'm aware of:\r\n\r\nparameters_set.idle_timeout was renamed to .max_idle_timeout",
      "createdAt": "2020-01-22T15:54:15Z",
      "updatedAt": "2021-08-18T09:53:14Z",
      "closedAt": "2021-08-18T09:53:14Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "There was also HANDSHAKE_DONE, but we added that already.",
          "createdAt": "2020-01-22T17:44:02Z",
          "updatedAt": "2020-01-22T17:44:02Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "maybe this was flagged a while back but `HTTP3EventType:dependency_update`, since it looks like there will be no dpendency-based prioritization in HTTP/3 core probably want to remove it",
          "createdAt": "2020-01-24T12:06:38Z",
          "updatedAt": "2020-01-24T12:07:26Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "@LPardue I think that's a specific issue for the TypeScript definitions that's not in the qlog draft itself? I've fixed it for ts here: https://github.com/quiclog/qlog/commit/cf4af5b227289fb32cde9dc9e39ee6a963a08384",
          "createdAt": "2020-01-24T12:38:25Z",
          "updatedAt": "2020-01-24T12:38:33Z"
        }
      ]
    },
    {
      "number": 47,
      "id": "MDU6SXNzdWU1NTQ3MTk0ODQ=",
      "title": "Revisit the category for generic events",
      "url": "https://github.com/quicwg/qlog/issues/47",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "We have a number of \"generic\" events in the draft (section 7, General error, warning and debugging definitions). These currently have their own categories: error, warning, info, debug, verbose, simulation. This is a bit awkward, since most of these only have a single event type. \r\n\r\nIt might be a good idea to group these under a single category, e.g., \"generic\" or \"general\" or \"textual\" or... (or maybe 2: generic and simulation). Another option would be to define a new event field called `log_level` next to category (but that would increase overhead, as now we're essentially squatting on the category to provide that). \r\n\r\nThe purpose of these events (sans simulation) is to allow one to replace the default textual logging with qlog completely (e.g., everything you now send to stdout/stderr with printf() would go into these kinds of events).\r\n\r\nThanks to @LPardue for reporting.",
      "createdAt": "2020-01-24T12:52:37Z",
      "updatedAt": "2020-11-01T13:04:11Z",
      "closedAt": "2020-11-01T13:04:11Z",
      "comments": [
        {
          "author": "kazu-yamamoto",
          "authorAssociation": "NONE",
          "body": "I would vote for \"generic\" or \"general\".",
          "createdAt": "2020-08-06T00:27:00Z",
          "updatedAt": "2020-08-06T00:27:00Z"
        }
      ]
    },
    {
      "number": 48,
      "id": "MDU6SXNzdWU1NTYxMDAyMzI=",
      "title": "Reference the JSON specification",
      "url": "https://github.com/quicwg/qlog/issues/48",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Currently JSON is mentioned, but not officially referenced.\r\nMake it clear that formats unspecified in the qlog draft should be taken from JSON spec (e.g., that booleans should be spelled `true` and `false`)\r\n\r\nthanks @hawkinsw for reporting",
      "createdAt": "2020-01-28T10:01:15Z",
      "updatedAt": "2020-09-05T16:23:51Z",
      "closedAt": "2020-09-05T16:23:51Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Was fixed in f5db7cdc8cd0cf37bfe5f1b0b4c54fc56ffc5f28",
          "createdAt": "2020-09-05T16:23:51Z",
          "updatedAt": "2020-09-05T16:23:51Z"
        }
      ]
    },
    {
      "number": 49,
      "id": "MDU6SXNzdWU1NTk2NjMwNTQ=",
      "title": "More fine-grained connection states",
      "url": "https://github.com/quicwg/qlog/issues/49",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Per @huitema:\r\n\r\n` I would split the active state between \"start\" and \"confirmed\", and the handshake start on the server side between \"received a request\" and \"address validated\".`\r\n\r\n```\r\nThe server will go through the \"anti dos mitigation\" phase until the client's address is validated. That's important, because the server behavior in that state is restricted. Once it has sent all the handshake packets, the server goes to a \"false start\" phase in which it can send 1-RTT packets but (should) not receive. And then once it receives the client finished and sends the \"handshake done\", it moves to a confirmed state, at which point it can deal with migration and key update.\r\n\r\nClient is kind of the same. It goes from initiating to handshake, then to an \"almost ready\" phase after sending the \"client finished\" and getting the 1rtt keys. But it will only become really active once it receives the \"handshake done\" or an equivalent.\r\n```",
      "createdAt": "2020-02-04T11:40:06Z",
      "updatedAt": "2020-11-03T11:50:32Z",
      "closedAt": "2020-11-03T11:50:32Z",
      "comments": [
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "Defining connection states is hard, but here is what I would suggest:\r\n\r\n1) Client side, up to the \"ready\" state:\r\n* attempted (Initial sent, no handshake keys received yet)\r\n* handshake (handshake keys received)\r\n* almost ready (1RTT keys received, but handshake done not received yet)\r\n* ready (or active) (handshake done received from server, or equivalent)\r\n2) Server side:\r\n* received (initial received)\r\n* validated (client address has been verified)\r\n* handshake (handshake packets received from client, handshake in progress)\r\n* false start (1RTT keys write received, but handshake not complete yet)\r\n* ready (handshake complete, handshake done sent)\r\n3) Both sides:\r\n* draining (close connection packet sent or received, waiting for some time)\r\n* disconnected (done with this connection)\r\n\r\n",
          "createdAt": "2020-03-08T23:24:39Z",
          "updatedAt": "2020-03-08T23:24:39Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I like the addition of `validated`. That can be really useful when debugging the early handshake stages.\r\n\r\n> * almost ready (1RTT keys received, but handshake done not received yet)\r\n> * ready (or active) (handshake done received from server, or equivalent)\r\n\r\nThis could be `handshake_completed` and `handshake_confimred`. Both of them would work for client as well as the server.\r\n\r\n> false start (1RTT keys write received, but handshake not complete yet)\r\n\r\nNot sure if we need this. We already have a `key_updated` event.",
          "createdAt": "2020-04-12T12:08:56Z",
          "updatedAt": "2020-04-12T12:10:01Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Here's my proposal:\r\n\r\n```\r\nenum ConnectionState {\r\n    validated, // only for the server, when the client's IP has been validated\r\n    handshake_completed, // TLS handshake successful\r\n    handshake_confirmed, // handshake confirmed, see sec. 4.1.2 of the QUIC-TLS draft\r\n    draining, // CONNECTION_CLOSE sent\r\n    closed // connection actually fully closed, memory freed\r\n}\r\n```\r\n\r\n@rmarx, @huitema What do you think?",
          "createdAt": "2020-04-12T12:17:13Z",
          "updatedAt": "2020-04-12T12:17:13Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "@marten-seemann I think that's too coarse. You have to consider scenarios in which Initial packets are exchanged for some time before handshake keys are available, e.g., for post quantum, and scenarios in which handshake packets are exchanged for some time before 1RTT keys are available, e.g., client auth. Also, per 4.1.2, handshake confirmed on the server happens at exactly the same time as handshake confirmed. That's why I use a \"false start\" state for the server.\r\n\r\nWe are discussing logging options here. Having detailed logging options does not hurt, there is no point in being too parsimonious. If you only want to log a subset of them, that's a fine implementation choice, but that should not prevent precise logging for those who want it.",
          "createdAt": "2020-04-12T17:25:09Z",
          "updatedAt": "2020-04-12T17:25:09Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "> Also, per 4.1.2, handshake confirmed on the server happens at exactly the same time as handshake confirmed.\r\n\r\nTrue. This event would be kind of redundant for the server. It's also kind of redundant redundant for the client, since this is the time when the client drops Handshake keys.\r\n\r\n> @marten-seemann I think that's too coarse. You have to consider scenarios in which Initial packets are exchanged for some time before handshake keys are available, e.g., for post quantum, and scenarios in which handshake packets are exchanged for some time before 1RTT keys are available, e.g., client auth. [...] That's why I use a \"false start\" state for the server.\r\n\r\nFirst of all, I don't understand the name \"false start\". My point in https://github.com/quiclog/internet-drafts/issues/49#issuecomment-612604685 was that we already have an event for this: it's the [key updated](https://quiclog.github.io/internet-drafts/draft-marx-qlog-event-definitions-quic-h3.html#name-key_updated) event.\r\n\r\nNow it seems like both \"false start\", `handshake_comfirmed` and `handshake_completed` are all redundant, since they all accompanied by key generation / key discarding events. Not sure what to make of that...",
          "createdAt": "2020-04-13T09:55:26Z",
          "updatedAt": "2020-04-13T09:55:26Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So, I've been trying to build a QUIC handshake/connection state machine to see which states we actually need. This initial design is garnered towards expressing the -entire- state machine with all state transitions. While I agree with @marten-seemann above that some of these can be deduced from e.g., `key_update` events, for now I'd like to keep this event as complete as possible, so it can be used without those other events as well. \r\n\r\n**I believe that we need 8 states in total** (mainly to allow for some phases to last longer than 1 RTT/1 flight):\r\n\r\n1. attempted (initial sent/received) \r\n2. peer_validated (peer address validated by: [client sent Handshake packet OR client used CONNID chosen by the server](https://tools.ietf.org/html/draft-ietf-quic-transport-32#section-8.1))\r\n3. handshake_started \r\n4. false_start (1 RTT can be sent, but handshake isn't done yet)\r\n5. handshake_complete ([TLS handshake complete](https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#section-4.1.1): Finished received and sent) \r\n6. handshake_confirmed ([HANDSHAKE_DONE sent/received](https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#section-4.1.2)) (connection is now \"active\", 1RTT can be sent)\r\n7. draining (connection_close sent/received)\r\n8. closed (draining period done)\r\n\r\nFollowing [the handshake examples in the transport draft](https://tools.ietf.org/html/draft-ietf-quic-transport-32#section-7.1), this would lead to the following events and transitions: \r\n\r\n**Client:**\r\n- send initial\r\n\t- state = attempted \r\n- get initial \r\n\t- state = validated _(not really \"needed\" at the client, but somewhat useful to indicate progress nonetheless)_\r\n- get first Handshake packet\r\n\t- state = handshake_started \r\n- get Handshake packet containing ServerFinished\r\n\t- state = handshake_complete \r\n- send ClientFinished\r\n\t- state = false_start \r\n\t(1RTT can now be sent)\r\n- get HANDSHAKE_DONE \r\n\t- state = handshake_confirmed \r\n\r\n**Server:**\r\n- get initial \r\n\t- state = attempted \r\n- send initial _(don't think this needs a separate state, since some handshake will always be sent in the same flight as this?)_\r\n- send handshake EE, CERT, CV, ... \r\n\t- state = handshake_started \r\n- send ServerFinished\r\n\t- state = false_start \r\n\t(1RTT can now be sent)\r\n- get first handshake packet / something using a server-issued CID of min length \r\n\t- state = validated \r\n- get handshake packet containing ClientFinished\r\n\t- state = handshake_complete \r\n- send HANDSHAKE_DONE\r\n\t- state = handshake_confirmed \r\n\r\nThis has a few ugly things, of course:\r\n- The server `validated` and `false-start` events won't always be in the same order, depending on how long the handshake takes (e.g., with a large CERT, handshake might need several flights to complete, causing `validated` to come before `false-start`)\r\n- At the server side, `handshake_complete` and `handshake_confirmed` will always fire directly after one another (this is also true [in the TLS draft's definitions](https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#section-4.1.2) however)\r\n- The `false_start` and `validated` aren't really needed at the client side (but do provide a nice parallel in logic to the server's progression imo)\r\n\r\nFinally, for users not wishing to log all states this fine-grainedly, this condenses nicely to:\r\n1. attempted\r\n2. handshake_started\r\n3. handshake_confirmed\r\n4. closed\r\n\r\nWhat do people think? Did I miss something?",
          "createdAt": "2020-10-31T19:49:37Z",
          "updatedAt": "2020-10-31T19:49:37Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "From an implementation point of view, you probably want to separate \"false_start\" (on the server side) and \"almost_ready\" on the client side. The server side is more constrained, because it cannot receive 1-RTT packets. Also, when the client enters the \"almost_ready\" start, the TLS stack on the client has seen the server certificate and validated the \"server finished\" message. In contrast, the server will only know that there is no MITM or 0-RTT replay attack when its TLS stack validates and receives the \"client finished\" message, so in theory the server has to apply some caution before sending data.",
          "createdAt": "2020-10-31T20:14:29Z",
          "updatedAt": "2020-10-31T20:14:29Z"
        },
        {
          "author": "martinthomson",
          "authorAssociation": "MEMBER",
          "body": "Our implementation has \"waiting for initial\", which roughly corresponds to your \"attempted\", but also encapsulates the server side prior to receiving the initial.  We don't keep that state very long server side; your description implies that it persists, but I don't think that is helpful.\r\n\r\nThen we have \"handshaking\", which we keep orthogonal to the states where various keys are available.  Keeping key availability separate is better than trying to enumerate the various availability options.  false_start is a problem, I think in that it implies something else; an \"early write\" state is fine.  In this state you can sometimes send, based on what keys are available, but you can never receive.  Also, trying to conflate address validation state with handshake state will likely complicate things more than necessary.\r\n\r\nThen we have \"complete\" where TLS is done.  And \"confirmed\" where you have thrown out handshaking state.\r\n\r\nWe use the states from the spec for closing, which is not a single state, but three.\r\n\r\nSo aside from your closed state, the summary form is probably best.  Logging both address validation and key availability independently would be good.",
          "createdAt": "2020-11-01T01:19:35Z",
          "updatedAt": "2020-11-01T01:19:35Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thank you both @huitema and @martinthomson for your input! \r\n\r\nChanges I've made for -02:\r\n1. renamed \"false_start\" to \"early_write\". I appreciate that this is potentially not entirely the correct term, but I was thinking mainly of non-protocol experts trying to following along and \"early write\" seemed easiest to grok. Open to other suggestions for -03. \r\n2. changed to having 3 closing states: closing, draining, closed\r\n3. added explicit guidance to support the condensed/simpler set \r\n\r\n@martinthomson: we keep support for logging the key updates separately as well. WRT address validation, this will be re-evaluated once I add proper support for connection migration/path management. For now, I'm keeping it in there because @huitema suggested it above and it's the most logical place to put it at this point. \r\n\r\n@martinthomson: I do not have anything before \"attempted\" because this event is connection scoped and IIUC servers don't have a connection concept before the first initial from the client arrives (similar for the client). In qlog, this is more generally reflected by other events like `server_listening` atm.  \r\n\r\n",
          "createdAt": "2020-11-03T11:50:32Z",
          "updatedAt": "2020-11-03T11:50:32Z"
        }
      ]
    },
    {
      "number": 50,
      "id": "MDU6SXNzdWU1NjAyMDI4Mjc=",
      "title": "general observations",
      "url": "https://github.com/quicwg/qlog/issues/50",
      "state": "OPEN",
      "author": "xquery",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "The following is a 'bag' of general comments ... perhaps not so actionable but I did not find a mail list to send these kind of general observations.\r\n\r\n**scope**\r\n\r\nSome readers may try to contrast/compare this effort with higher level http logging formats (eg. NCSA, common log format and friends) ... might be worth reducing their confusion by adding some context eg. qlog sits near pcap.\r\n \r\nYou may consider explicitly constraining scope to h2/h3 and degrade gracefully for use with other protocols as a side effect of good design instead of assert broad applicability.\r\n\r\nThere is a statement of compliance attempted in 'tooling section' but this document defines a high level schema eg. I would have expected the only statement of compliance achievable (in this document) is the correct validation of schema against instance data.\r\n\r\nUnlike pcap (which is defined in terms of an api) qlog (so far) is defined in the form of a schema - hence I was looking for a clear definition of optional vs not required ... my expectation was for the core of qlog to be as small as possible.\r\n\r\nI would separate out protocol definition (endpoint) ... I am sure there exists a good IETF example of this ... but I am too lazy to find and will point you to a W3C set of specs as example https://www.w3.org/TR/2013/REC-sparql11-overview-20130321/\r\n\r\n**json**\r\n\r\nYou might consider adding some section on json convention/style (assert snake_case, etc) eg. remarking on challenges of using json for representing log data (limitations with datetime, decimal, no comments - all come to mind).\r\n\r\nYou are defining a high level schema (which for me implies no dependency on a concrete format like json) but as you have used json throughout to illustrate relationships/structure - I was looking (maybe missed it) for a non normative json schema definition.\r\n\r\n**keys**\r\n\r\nerror is buried in the text, should be normatively defined.\r\n\r\nI dislike the term 'vantage_point' ... I understand the requirements but maybe considering other terms like 'src' and 'target' are more appropriate.  \r\n\r\n**values**\r\n\r\nhave you considered defining a time unit in some human readable datetime (including tz notation ex.iso-8601 et al https://www.w3.org/International/core/2005/09/timezone.html)  \r\n\r\n**transforms**\r\nHave you considered demonstrating how transforms might work \r\nI like the way csv spec goes about this https://www.w3.org/2013/csvw/wiki/Main_Page\r\n\r\n**general** \r\n\r\nIt is unclear how easy for a database to index qlog formatted json. \r\n\r\nI think the section on 'Practical Use' might consider how compressed json compares to a binary format.\r\n\r\n",
      "createdAt": "2020-02-05T08:01:56Z",
      "updatedAt": "2020-09-08T15:40:59Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 51,
      "id": "MDU6SXNzdWU1NjE2NDczMTY=",
      "title": "QLOGDIR environment variable",
      "url": "https://github.com/quicwg/qlog/issues/51",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Maybe the main schema should specify something like SSLKEYLOGFILE that implementations SHOULD adhere to. \r\n\r\nThough it needs to be a directory, not 1 file, since we probably don't want to dump all qlogs into 1 single file as we do with the SSL keys. \r\n\r\nA good option might be QLOGDIR.\r\n\r\nWe should also specify how to write/name individual files in that directory (or at least list options)\r\n\r\nTODO: find out where SSLKEYLOGFILE Is specified exactly (seems a bit difficult to google).\r\n\r\nCC @bagder @xquery",
      "createdAt": "2020-02-07T13:47:15Z",
      "updatedAt": "2020-09-01T19:13:31Z",
      "closedAt": "2020-09-01T19:13:31Z",
      "comments": [
        {
          "author": "bagder",
          "authorAssociation": "NONE",
          "body": "I don't think `SSLKEYLOGFILE` is specified anywhere and I don't know exactly how it came to exist, but I know that Firefox and Chrome with Wireshark have supported it a fairly long time and curl does too since a while back. It's just very convenient to have several applications agree on how to do this. I would very much like to have curl support the qlog variable as well.",
          "createdAt": "2020-02-07T13:50:23Z",
          "updatedAt": "2020-02-07T13:50:23Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "This wfm, I need a parameter to pass to control behaviour anyway and this avoids me having to make my own",
          "createdAt": "2020-02-07T15:17:49Z",
          "updatedAt": "2020-02-07T15:17:49Z"
        }
      ]
    },
    {
      "number": 52,
      "id": "MDU6SXNzdWU1NjYxMTQxNjQ=",
      "title": "mandatory new field in key_updated compromises security",
      "url": "https://github.com/quicwg/qlog/issues/52",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "On a production system you probably don't want to log TLS secrets, even if you qlog (some of the) connections. The `new` field in the `key_updated` event therefore should not be mandatory. \r\n\r\nI'm not sure I understand the `old` field either. If you're logging 1-RTT key updates and their sequence numbers, the key would already be written to the qlog, so there's no need to export it again. Or am I missing something?\r\n\r\nMaybe it would be a good idea to keep key material to the SSLKEYLOGFILE and not even offer an option to write them to qlog?",
      "createdAt": "2020-02-17T07:49:23Z",
      "updatedAt": "2020-10-31T13:57:58Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Additionally, we should add an \"owner\" field to the `key_update` event.\r\n\r\nNow, difference between client/server keys is made with the trigger and also the KeyType: this should be made more consistent with the other events. See also #44. \r\n\r\nAn endpoint would then emit separate events for client and server key updates, which *should* work event if key calculation is delayed (though not 100% sure yet). \r\n",
          "createdAt": "2020-02-17T10:27:58Z",
          "updatedAt": "2020-02-17T11:05:46Z"
        }
      ]
    },
    {
      "number": 53,
      "id": "MDU6SXNzdWU1NjY5MTU2NjY=",
      "title": "Provide clearer usage advice",
      "url": "https://github.com/quicwg/qlog/issues/53",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "future-versions"
      ],
      "body": "At the moment, it's not entirely clear how qlog is \"supposed to be used\".\r\n\r\nFor example, it's not clear to implementers why some fields (e.g., quic version) are duplicated across `connection_started` and also the PacketHeader.\r\n\r\nWe should provide some examples of what things look like if you implement \"all of qlog\" and what should happen if you only implement the Core events (i.e., some fields in the Core events can be skipped if you're using the Base or Extra events instead). This is also important info for tool implementers. \r\n\r\nThis also depends on the use case: tracing while debugging vs production-level logging. ",
      "createdAt": "2020-02-18T14:05:55Z",
      "updatedAt": "2020-11-27T17:22:29Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thinking about this more, this seems to have become an untenable situation going forward to -03. \r\nqlog straddles the weird line between being a replacement for pcaps, as well as having to provide events for logging conceptual events not reflected in pcaps. \r\n\r\nThis was fine in the beginning, as everyone can/did log packet contents (e.g., ACK frames) and we could skip many events related to things clear from the wire (e.g., `packet_acked` or `flow_control_updated` etc.). However, for implementations that would not want to log the wire image itself, we would have to add these latter types of events for everything... (ref #107). Tools would then also have to be flexible enough to get this info both from frames and these other events. \r\n\r\nLong story short: we're tying to be a one-stop-shop, defining everything. That might be fine, but then we probably need to explicitly and quite clearly split up the wire-image events from the conceptual events (and provide alternatives for all and clear guidance). \r\n\r\nThis really could use wider discussion. \r\n\r\n",
          "createdAt": "2020-10-31T16:36:39Z",
          "updatedAt": "2020-10-31T16:36:39Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "We had a clear example today of how a separate `flow_control_updated` event is useful. A misbehaving client was lowering flow control limits (probably because it retransmits FC frames as they were in the past, rather than create a new FC update with new limits). qvis showed this as lowering the limits, even though the server probably didn't actually apply the lower limits at its end. It was good that qvis showed the limits (leading to the discovery of this problem), but it again highlights that there is a difference between receipt of a given frame and how that's actually applied in the implementation. ",
          "createdAt": "2020-11-27T17:22:29Z",
          "updatedAt": "2020-11-27T17:22:29Z"
        }
      ]
    },
    {
      "number": 54,
      "id": "MDU6SXNzdWU1NzExOTQ3MDA=",
      "title": "Allow more wire-image indicators",
      "url": "https://github.com/quicwg/qlog/issues/54",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "Currently, we abstract out a lot of the on-the-wire specifics.\r\n\r\nA good example is in the STREAM frame: there, the length and offset fields are optional, depending on how the frame should be handled. Simply having the same fields optional in qlog doesn't convey quite the same semantics: did the implementation simply not log them or were they not present from the start? \r\n\r\nMore importantly though: if no length is set, the frame extends to the end of the packet, so it does have a length, which you'd probably want to log (that's the way it's currently designed), but so you loose the info that the length field wasn't encoded on the wire. \r\n\r\nThis is just one example of similar problems across the board. I rather like the simplicity of the current setup, but we should have ways to signal the explicit wire image as well. \r\n\r\ncc @huitema",
      "createdAt": "2020-02-26T09:36:21Z",
      "updatedAt": "2021-08-19T10:24:23Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I can see three options:\r\n1. provide a more fine-grained, optional `raw_frame_type` field that encodes the actual stream type number instead of the conceptual name we have in frame_type (like how UnknownFrame works today)\r\n2. require people to log the (partial) (STREAM) frame header in the raw field to allow for later re-parsing\r\n3. do nothing\r\n\r\nProposal: use 1.",
          "createdAt": "2021-08-18T09:52:21Z",
          "updatedAt": "2021-08-18T13:16:43Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "Can you elaborate on 1 more? By the time my parser informs me I have a STREAM frame, I might have discarded the on-wire bytes",
          "createdAt": "2021-08-18T10:00:28Z",
          "updatedAt": "2021-08-18T10:00:28Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This would be an -extra- option to log besides the `frame_type` in case you really need to know if you got 0x08, 0x09, 0x0A ... or 0x0F (at least for STREAM, for ACK it'd be 0x02 or 0x03). \r\n\r\nThis could be parsed if you logged the first few bytes in `raw` for example, but having a separate field would be more direct. We have precedent for this in e.g., `ConnectionCloseFrame.raw_error_code`.\r\n\r\nIf you don't have that information available at the point you're logging but still need it well... you'd need to log somewhere closer to the wire? In the ACK case, it is implicit through the logging of ECN info, for stream it is somewhat for the presence of the FIN bool, but for length and offset, it's more difficult to know sometimes. \r\n\r\nThis is not crucial information, but could be good to know in some highly specific edge case debugging.\r\n\r\nGot a bug in pcap2qlog about this just the other day, where I forgot to extrapolate the length field from the QUIC packet length if it wasn't present in the STREAM frame itself (https://github.com/quiclog/pcap2qlog/issues/7)",
          "createdAt": "2021-08-18T13:24:00Z",
          "updatedAt": "2021-08-18T13:24:00Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "> This could be parsed if you logged the first few bytes in raw for example, but having a separate field would be more direct. We have precedent for this in e.g., ConnectionCloseFrame.raw_error_code.\r\n\r\nSome the the question here is what do you mean by wire image. Should something like `raw_error_code` be raw bytes underlying the varint (maintaining the information on how the number was encoded on the wire), or the parsed varint.\r\n\r\nSince `raw_error_code` a single int, it must be the parsed varint, which is slightly easier. But even today I can't populate that because my implementation has discarded the data by the time I come to generate the qlog. Changing the code would boil down to me changing the logging pipeline, parsing the same value twice, and/or storing the data twice just for qlog. \r\n\r\nI'll note that for H3 this is even harder, because we have to handle non-atomic varint reads as STREAM data comes.",
          "createdAt": "2021-08-18T15:30:19Z",
          "updatedAt": "2021-08-18T15:30:19Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So the idea was:\r\nOption 1: parsed varint (so literally the 0x08 - 0x0F for STREAM)\r\nOption 2: raw wire image (so \"unparsed\" varint)\r\n\r\nI do see the confusion... probably we should use another word than `raw` here, since `raw_error_code` is intended to also be the parsed varint, but the `raw:RawInfo` fields are intended to be pure wire bits. \r\n\r\nWith regards to your implementation not having that info available... I'm not sure what you want me to say... these are optional fields that you can output if needed/available, but not something I would expect many implementations to do (by default). I don't see a way of solving the original issue here (representing all the wire image nuances in some form) without having access to those nuances at the logging location :) \r\n\r\nCould you elaborate on `because we have to handle non-atomic varint reads as STREAM data comes` with an example maybe? Not sure what you mean there? \r\n\r\n\r\n\r\n",
          "createdAt": "2021-08-19T07:55:52Z",
          "updatedAt": "2021-08-19T07:55:52Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "The main point is that it's fairly straightforward to log the unprocessed bytes of a QUIC packet or QUIC frame, that's because an implementation will have received those in whole and know their length.  E.g. Read UDP, everything in the datagram.\r\n\r\nFor things on top of QUIC streams it becomes harder because they can span lots of packets. A streaming parser will possibly not have an entire frame available when it want to log an event.\r\n\r\nIf the proposal is to log the parsed varint, it makes things slightly easier ",
          "createdAt": "2021-08-19T10:24:23Z",
          "updatedAt": "2021-08-19T10:24:23Z"
        }
      ]
    },
    {
      "number": 55,
      "id": "MDU6SXNzdWU1NzExOTU3ODk=",
      "title": "More fields should be optional in ConnectionCloseFrame",
      "url": "https://github.com/quicwg/qlog/issues/55",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, everything is required, which isn't optimal.\r\n\r\nAdditionally, qvis should use more of the present information. \r\n\r\ncc @huitema",
      "createdAt": "2020-02-26T09:38:09Z",
      "updatedAt": "2020-09-08T15:43:03Z",
      "closedAt": "2020-09-08T15:43:03Z",
      "comments": []
    },
    {
      "number": 56,
      "id": "MDU6SXNzdWU1NzExOTg5Njk=",
      "title": "Allow logging of partial raw data",
      "url": "https://github.com/quicwg/qlog/issues/56",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Currently, we use the `raw` field in multiple events to allow logging of the raw data.\r\n\r\nIt would be interesting to allow logging for only the first x bytes, which can help in debugging.\r\n\r\nSome options:\r\n\r\n1. New `raw_partial` field, containing the partial hex-encoded data\r\n2. New `raw_length` field, indicating the length of the `raw` field. If it doesn't match the `length` parameter (or equivalent), we know `raw` is truncated\r\n3. No new fields: we can derive `raw`'s length from the size of the string. Then use similar logic as 2) to detect truncation\r\n4. No new fields, end `raw` field with `...` at the end of the string. Perfectly human readable, bit of a hassle when decoding the bytes to e.g., ASCII + less optimal for a potential binary format\r\n\r\nPersonally, I would prefer 3. We will strongly advise AGAINST logging `raw` in typical usage scenarios anyway: it's only to be used for core debugging. In these latter cases, the person debugging probably knows the stack a bit more deeply and understands that it's logging just partial raw values. \r\n\r\ncc @huitema",
      "createdAt": "2020-02-26T09:43:23Z",
      "updatedAt": "2020-11-02T17:05:28Z",
      "closedAt": "2020-11-02T17:05:28Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Related to #104 and #102",
          "createdAt": "2020-09-08T15:47:58Z",
          "updatedAt": "2020-09-08T15:47:58Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Solved by allowing truncated values and specifying a separate length field (so basically option 2 above). ",
          "createdAt": "2020-11-02T17:05:28Z",
          "updatedAt": "2020-11-02T17:05:28Z"
        }
      ]
    },
    {
      "number": 57,
      "id": "MDU6SXNzdWU1NzEyMDA1NDc=",
      "title": "Add IP addresses to datagram_* events",
      "url": "https://github.com/quicwg/qlog/issues/57",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "design",
        "current-version",
        "privacy"
      ],
      "body": "We currently extracted these to other events, assuming they wouldn't change or only change sparingly at specific times, handled by other events (e.g., when doing migration).\r\n\r\nHowever, this is not always the case. For example, @huitema mentioned:\r\n\r\n> NAT rebinding, probes of packets before migration\r\n\r\nFor these cases, it would be interesting to have (optional) IP from/to addresses in the datagram_* events as well. ",
      "createdAt": "2020-02-26T09:45:54Z",
      "updatedAt": "2021-08-18T10:10:52Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 58,
      "id": "MDU6SXNzdWU1NzEyNTQ1NDg=",
      "title": "Consider splitting up parameters_set",
      "url": "https://github.com/quicwg/qlog/issues/58",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "quic-http3-fields",
        "future-versions"
      ],
      "body": "Currently, the parameters related events aggregate all sorts of parameters, doesn't matter where they come from. Good example is transport:parameters_set, which contains mostly data that's transported via TLS (Transport params, alpn), but also some other fields (like QUIC version). \r\n\r\nSome people (@huitema, @marten-seemann) have advocated splitting up this event into others. I personally don't see the benefit of that, so this issue is to track outside arguments and proposed solutions.",
      "createdAt": "2020-02-26T11:09:41Z",
      "updatedAt": "2021-08-18T09:44:47Z",
      "closedAt": null,
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "One problem with the current design is that it couples QUIC's transport parameters with the handshake. Some of that data is provided by TLS to QUIC, but other things like ALPN are not used by the QUIC transport. \r\n\r\nA more natural model could be a series of handshake events, as suggested by others.",
          "createdAt": "2020-02-26T11:47:53Z",
          "updatedAt": "2020-02-26T11:47:53Z"
        }
      ]
    },
    {
      "number": 59,
      "id": "MDU6SXNzdWU1NzEyNzIxMTI=",
      "title": "Add more TLS-specifics",
      "url": "https://github.com/quicwg/qlog/issues/59",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "Currently, we have few options for logging a lot of TLS related data (e.g., cipher suites, supported groups, (E)SNI, ...). \r\n\r\nNeed to figure out a generic form for TLS (extensions) data so it can be logged using qlog as well. \r\n\r\nNote: this is getting in the \"new TCP+TLS+HTTP/2 schema\" territory ",
      "createdAt": "2020-02-26T11:37:15Z",
      "updatedAt": "2020-09-08T15:43:21Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 60,
      "id": "MDU6SXNzdWU1Nzc0NTA0NzY=",
      "title": "packet_dropped header_decrypt_error should be header_parse_error",
      "url": "https://github.com/quicwg/qlog/issues/60",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Header decryption can never fail: it's just an XOR with a byte mask (header protection is not authenticated). You'd drop a packet though if header parsing fails, so maybe we can rename the trigger?",
      "createdAt": "2020-03-08T05:51:31Z",
      "updatedAt": "2020-09-08T12:30:28Z",
      "closedAt": "2020-09-08T12:30:28Z",
      "comments": []
    },
    {
      "number": 62,
      "id": "MDU6SXNzdWU1Nzc1Mzk2MjY=",
      "title": "Logging of Retry and Version Negotiation packets",
      "url": "https://github.com/quicwg/qlog/issues/62",
      "state": "CLOSED",
      "author": "huitema",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Initial, Handshake, 0-RTT and 1-RTT packets have a payload composed of a set of frames. Retry and Version Negotiation packets don't. The payload of retry packets is a retry token; the version negotiation packets contain a list of proposed versions. I wonder what the proper logging should be.\r\n\r\nStaying close to the transport spec would get:\r\n```\r\n[118740, \"TRANSPORT\", \"PACKET_RECEIVED\", { \r\n    \"packet_type\": \"version\",\r\n    \"header\": { \r\n        \"packet_number\": \"0\",\r\n        \"packet_size\": 43,\r\n        \"payload_length\": 20,\r\n        \"scid\": \"96f7ef87d6603a79\",\r\n        \"dcid\": \"130b28a505315b13\" },\r\n    \"proposed_versions\": [ \"ff00001b\", \"ff000019\", \"8aca3a8a\" ]}]\r\n\r\n[113660, \"TRANSPORT\", \"PACKET_RECEIVED\", {\r\n    \"packet_type\": \"retry\",\r\n    \"header\": {\r\n        \"packet_number\": \"0\",\r\n        \"packet_size\": 80,\r\n        \"payload_length\": 32,\r\n        \"scid\": \"fa49f056d84c11c1\",\r\n        \"dcid\": \"5bdfe3c33300b8b8\" },\r\n    \"retry_token\": \"0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef\" }]\r\n```\r\nDoes this look right?",
      "createdAt": "2020-03-08T18:01:06Z",
      "updatedAt": "2020-11-02T17:08:27Z",
      "closedAt": "2020-11-02T17:08:27Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Was solved by including `supported_versions`, `retry_token`, `retry_token_length` and `stateless_reset_token` directly on `packet_sent` and `packet_received` (as this can conceptually be seen as being part of the \"payload\" of those special purpose packets, rather than their headers)",
          "createdAt": "2020-11-02T17:08:27Z",
          "updatedAt": "2020-11-02T17:08:27Z"
        }
      ]
    },
    {
      "number": 64,
      "id": "MDU6SXNzdWU1ODA0Mjk3OTU=",
      "title": "Properly specify stateless reset, retry and migration",
      "url": "https://github.com/quicwg/qlog/issues/64",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "These concepts were in flux when -01 was made and are now much more settled.\r\n\r\nAny thoughts on how to best approach this are more than welcome.",
      "createdAt": "2020-03-13T07:50:57Z",
      "updatedAt": "2020-03-28T10:24:20Z",
      "closedAt": "2020-03-28T10:24:20Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "For stateless reset, I can see two options:\r\n\r\n1. make it a new PacketType and then simply use `packet_received` / `packet_sent`\r\n2. make it a new event type with custom semantics\r\n\r\nAt least one implementer has indicated a preference for (1), since their stack only intends to support the core events. \r\n",
          "createdAt": "2020-03-13T08:05:59Z",
          "updatedAt": "2020-03-13T08:05:59Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "For stateless reset, both works for me. Most important thing is to get a way to log it at all, since this would be an interesting signal in production.",
          "createdAt": "2020-03-13T09:49:16Z",
          "updatedAt": "2020-03-13T09:49:16Z"
        }
      ]
    },
    {
      "number": 65,
      "id": "MDU6SXNzdWU1ODA0MzkwMTU=",
      "title": "Change data_moved to the transport category",
      "url": "https://github.com/quicwg/qlog/issues/65",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, `data_moved` is in the HTTP category, but it's (application) protocol agnostic and can be used for other application-layer protocols as well.\r\n\r\ncc @marten-seemann ",
      "createdAt": "2020-03-13T08:11:40Z",
      "updatedAt": "2020-09-07T19:40:28Z",
      "closedAt": "2020-09-07T19:40:28Z",
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "strong agree!",
          "createdAt": "2020-04-10T17:34:54Z",
          "updatedAt": "2020-04-10T17:34:54Z"
        }
      ]
    },
    {
      "number": 66,
      "id": "MDU6SXNzdWU1ODM1Njc3NDk=",
      "title": "relax ordering requirement",
      "url": "https://github.com/quicwg/qlog/issues/66",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "The spec currently says:\r\n> Events in each individual trace MUST be logged in strictly ascending timestamp order (though not necessarily absolute value, for the \"delta_time\" setup). Tools are NOT expected to sort all events on the timestamp before processing them.\r\n\r\nThis poses problems for multi-threaded implementations that implement a streaming encoder. Since qlogs take up a lot of memory for long-lived / active connections, implementing a streaming encoder is the only way to run qlog in production, without risking to overflow the host's memory.\r\n\r\nIf you have a multithreaded application, it's not possible to guarantee that the events will be strictly ordered by timestamp.",
      "createdAt": "2020-03-18T08:51:22Z",
      "updatedAt": "2020-11-01T13:04:52Z",
      "closedAt": "2020-11-01T13:04:52Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I've been thinking about this while implementing an automated sort() in qvis to prevent this from going wrong (kazu also had this problem).\r\n\r\nIn and of itself, it's not necessary to -log- in order I think. But it saves a lot of time in (especially web-based) tooling if you don't have to sort all logs prior to using them. So we could say something like:\r\n\r\n> Events SHOULD be logged in ascending timestamp order. Tools are not expected to do sorting. If an implementation cannot guarantee ordered logs, they can use a postprocessing step to order the logs if their tool of choice does not offer automatic sorting.\r\n\r\nThis is similar to wireshark's approach IIUC (https://www.wireshark.org/docs/wsug_html_chunked/AppToolsreordercap.html)\r\n\r\nThough I am not 100% sure that sort() solves all problems... we've had some issues with wireshark recently where packets captured on different interfaces (but ending up in the same pcap) had quite a bit of timestamp differences and re-ordering on the timestamp field would be obviously wrong. Now, this is probably an artifact of the internal tcpdump implementation etc. and QUIC/H3 stacks should be much less affected. However, given that qlog is envisioned as a wider format (and because I can envision people splicing pcap-to-qlog with direct-qlog events from the application), I can't simply dismiss this. \r\n\r\n",
          "createdAt": "2020-03-18T09:03:28Z",
          "updatedAt": "2020-03-18T09:03:28Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "The whole point of using a streaming encoder is to not have to load the whole qlog file into memory at the same time. A post-processing step (which would have to happen when the whole qlog is written) would require me to do exactly that, so that's not an option.",
          "createdAt": "2020-03-18T09:07:12Z",
          "updatedAt": "2020-03-18T09:07:12Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I'm thinking more of an \"offline\" post-processing step. e.g., either in-bulk by a separate server/process as a cron-job or immediately prior to loading into a tool that doesn't support ordering itself. \r\n\r\nFor example, qvis currently detects if traces are un-ordered and does a sort() if that's the case. You could see that as a \"post processing step\" built in to the tooling itself. This is plenty fast enough for smaller traces (say up to 100MB) but can be slower for larger ones (though those aren't optimal in qvis either way).\r\n\r\nI think the whole point will be a bit moot in practice, since I would expect tools to have this built-in in practice, but that doesn't mean I would want to require this in the text. \r\n\r\nMaybe @nibanks has some insight into how windows ETW handles this type of thing? ",
          "createdAt": "2020-03-18T09:13:10Z",
          "updatedAt": "2020-03-18T09:13:29Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "That would be possible, but kind of ugly, since it would mean that a QUIC implementation cannot export semi-valid qlog on its own, and is reliant on external programs to fix the exported data. ",
          "createdAt": "2020-03-18T09:20:25Z",
          "updatedAt": "2020-03-18T09:20:25Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So I'm not sure what the solution would be then unless you'd force the tools to sort the logs themselves. Is that what you're advocating for? ",
          "createdAt": "2020-03-18T11:04:50Z",
          "updatedAt": "2020-03-18T11:04:50Z"
        }
      ]
    },
    {
      "number": 69,
      "id": "MDU6SXNzdWU1ODkxNDQzOTY=",
      "title": "PTO is per PN-space",
      "url": "https://github.com/quicwg/qlog/issues/69",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, we log `pto_count` in `metrics_updated`. However, we can have multiple PTO's running across multiple PN spaces and there is no proper way to correlate them with a PN space in metrics_updated.\r\n\r\nThis also impacts the `loss_timer*` event types. \r\n\r\nPossible resolutions:\r\n- Add pn_space attribute to `metrics_updated`\r\n- Split PTO count into a separate event (potentially merge with loss_timer?)\r\n\r\nTODO: reason more about how these metrics are tied to PN spaces in general (are there others than PTO that are duplicated)\r\n\r\ncc @marten-seemann ",
      "createdAt": "2020-03-27T13:45:29Z",
      "updatedAt": "2020-03-28T10:29:31Z",
      "closedAt": "2020-03-28T10:29:31Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "> * Add pn_space attribute to metrics_updated\r\n\r\nMost other metrics in the `metrics_updated` event are independent of the PN space, so that would be weird.\r\n\r\n> * Split PTO count into a separate event (potentially merge with loss_timer?)\r\n\r\nI'd prefer to do that. Not sure if it makes sense to merge is with the loss timer events, since we also need to be able to log a reset of the PTO count to 0 (which doesn't require setting of a timer).",
          "createdAt": "2020-03-27T13:51:04Z",
          "updatedAt": "2020-03-27T13:51:04Z"
        }
      ]
    },
    {
      "number": 72,
      "id": "MDU6SXNzdWU1ODk1NTEzNzU=",
      "title": "Allow listing which events were supported by the logger",
      "url": "https://github.com/quicwg/qlog/issues/72",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "When looking at a qlog at this time, if there is a certain event type missing, you don't know if it's because those events never occurred or if the implementation simply doesn't support/log that event type. \r\n\r\nThis is especially troublesome if you want to selectively enable/disable certain types to reduce overhead when you're doing targeted \"live\" debugging on a deployed system.\r\n\r\nThe simplest solution I can see is to add a new field to `configuration`, for example:\r\n\r\n> supportedEvents:Array\\<string\\> // each string is category:event_type (e.g., transport:packet_sent)\r\n\r\nSome bikeshedding can help to decide if we need two separate fields (supportedCategories separately for example) or if we can cut out the category in here completely (as there is little overlap in event names atm).\r\n\r\nThis would also be interesting for doing a fast \"is this trace compatible with this visualization\"-check in qvis and others tools. \r\n\r\nThanks to @mjoras for reporting.",
      "createdAt": "2020-03-28T10:36:52Z",
      "updatedAt": "2020-11-02T19:49:42Z",
      "closedAt": null,
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "This only captures a subset of the possible changes. For example, you wouldn't be able to tell if a  qlog implementation already supported the recently added `stateless_reset` packet type or not.\r\n\r\nIn the end, I think it makes more sense to add some kind of versioning scheme to your qlog file (which is orthogonal to the `qlog_version`), and would not be interpreted by tools.",
          "createdAt": "2020-03-29T08:53:36Z",
          "updatedAt": "2020-03-29T08:53:36Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I'm not sure I follow you here...\r\nIf the implementation doesn't support stateless_reset, it won't log them either in the first place, so them being absent from the `supportedEvents` list is the same.\r\n\r\nThis is not really intended to show what an implementation \"supports\" but more what is has \"enabled\". The situation is that as a user, you get a random qlog file in front of you, on which you need to do analysis. You're looking for the occurrence of a certain event type, but it isn't there. Is that because the event type wasn't being logged for this log (e.g., mvfst wants to selectively log only -some- of the supported event types to keep overhead down) or because it actually never occurred during the connection (e.g., signalling the bug you're looking for).\r\n\r\nCould you expand on the orthogonal versioning scheme? For your example of the `stateless_reset`, that would just be `draft-02` going forward from my viewpoint. \r\n\r\n\r\n\r\n",
          "createdAt": "2020-03-29T10:53:44Z",
          "updatedAt": "2020-03-29T10:53:44Z"
        }
      ]
    },
    {
      "number": 74,
      "id": "MDU6SXNzdWU1ODk2MDg4Nzg=",
      "title": "Add packet_number to frames_processed",
      "url": "https://github.com/quicwg/qlog/issues/74",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "With recent discussions on that it's sometimes expensive to log parsed frames in packet_received/packet_sent directly, it would be interesting to make frames_processed a bit more usable in practice.\r\n\r\nGiving it a packet_number allows it to be more easily linked to a specific packet and thus can be combined with packet_sent/received.\r\n\r\nThough, maybe we should rather go for a frame_created/frame_parsed equivalent to H3, as _processed only implies _parsed at this point. In that vein, maybe make it multiple frameS instead of just 1? ",
      "createdAt": "2020-03-28T16:19:26Z",
      "updatedAt": "2020-09-07T13:37:28Z",
      "closedAt": "2020-09-07T13:37:28Z",
      "comments": []
    },
    {
      "number": 75,
      "id": "MDU6SXNzdWU1OTAyMDI5MDU=",
      "title": "Add way to log contents of version negotiation packet",
      "url": "https://github.com/quicwg/qlog/issues/75",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Currently, there is no way to do this.\r\n\r\nPossible approaches:\r\n1. add `supported_versions:Array<string>` to `parameters_set` (similar to ALPN in #28)\r\n2. add `supported_versions:Array<string>` to the `packet_*` events (similar to how we do stateless_reset\r\n\r\nI personally have a preference for nr. 2, since it's consistent with how other packets are handled. ALPN is after all indeed a parameter, not a full packet. \r\n\r\ncc @mpiraux",
      "createdAt": "2020-03-30T11:09:53Z",
      "updatedAt": "2020-11-03T11:08:57Z",
      "closedAt": "2020-11-03T11:08:57Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I'd argue that we need both. The supported versions is a parameter of the server that's interesting to know independent of if version negotiation was ever performed or not.\r\n\r\nFor the client, it's important to have a way to log the contents of a version negotiation packet, so adding it to the `packet_received` event makes sense.",
          "createdAt": "2020-04-14T09:37:13Z",
          "updatedAt": "2020-04-14T09:37:13Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Related to #62 ",
          "createdAt": "2020-10-31T13:56:38Z",
          "updatedAt": "2020-10-31T13:56:38Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Option 2 was introduced in commit ac00848b50c1da3feaf50f43938e962a091396b0.\r\n\r\nHowever, we currently still lack a way to indicate which versions each endpoint supports by themselves (which is not always communicated over the wire). ",
          "createdAt": "2020-11-01T20:02:23Z",
          "updatedAt": "2020-11-01T20:02:23Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This was resolved for now by adding the new `version_information` event. Per #85, I'm not entirely sure that's the best approach here though. Closing this for now and keeping that issue open for general discussion. We can revisit this later depending on the outcome. \r\n\r\n",
          "createdAt": "2020-11-03T11:08:57Z",
          "updatedAt": "2020-11-03T11:08:57Z"
        }
      ]
    },
    {
      "number": 76,
      "id": "MDU6SXNzdWU1OTU2NzI3NDI=",
      "title": "packet_buffered should have a packet_size field",
      "url": "https://github.com/quicwg/qlog/issues/76",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This field would be really helpful for debugging. Without a packet size, there's no way to correlate a buffered packet to a packet that is later dequeued from the buffer.",
      "createdAt": "2020-04-07T08:01:26Z",
      "updatedAt": "2020-07-22T07:48:08Z",
      "closedAt": "2020-07-22T07:48:08Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Good point.\r\n\r\nReminder to me: maybe mention in the comments that it's primarily useful when you're buffering because keys were not available yet (e.g., during handshake).\r\n\r\nAlso: related to #40 ",
          "createdAt": "2020-04-08T09:07:03Z",
          "updatedAt": "2020-04-08T09:07:20Z"
        }
      ]
    },
    {
      "number": 78,
      "id": "MDU6SXNzdWU1OTg0MDUzODI=",
      "title": "revisit connection_state_updated",
      "url": "https://github.com/quicwg/qlog/issues/78",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "I see the following problems with the `connection_state_updated` event:\r\n1. `attempted` seems to be a duplicate of `connection_started` for the client (i.e. the two events would always be emitted at the same time)\r\n2. `reset` is impossible to log. You send a stateless reset if you lost state for a connection (after a crash or reboot, or if a packet was misrouted to the wrong backend server). In any case, there\u2019s no connection state to update by definition.\r\n3. `handshake` seems to be a duplicate of connection_started for both sides.\r\n\r\nI think these events could be removed without losing any information in the log.\r\n\r\nI suggest adding a new event for [confirmation of the handshake](https://quicwg.org/base-drafts/draft-ietf-quic-tls.html#name-handshake-confirmed). Maybe it would make sense to rename `active` to `handshake_completed` and add a `handshake_confirmed`?",
      "createdAt": "2020-04-12T04:01:04Z",
      "updatedAt": "2020-11-02T20:37:30Z",
      "closedAt": "2020-11-02T20:37:30Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Potential duplicate of #49, should be handled together. \r\n\r\n(meaning that, yes, this should be handled for -02)",
          "createdAt": "2020-04-12T11:31:59Z",
          "updatedAt": "2020-04-12T11:31:59Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "After some thinking, I feel it might worthwhile to see if we can transform `connection_started` into a `parameters_set` equivalent for the `connectivity` category.",
          "createdAt": "2020-04-12T12:11:05Z",
          "updatedAt": "2020-04-12T12:11:05Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Adding to my list, `keepalive` should probably not be a connection state. The QUIC specification doesn't  say a lot about keep-alives other than you can send a packet once in a while if you have nothing else to send.\r\nMaybe it's enough to set this as a `trigger` on the `packet_sent` event?",
          "createdAt": "2020-04-12T12:16:04Z",
          "updatedAt": "2020-04-12T12:16:04Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "@marten-seemann just reported on slack that a separate `connection_closed` event would be interesting to log the reason the connection was closed (for which we're now either relying on the CONNECTION_CLOSE frame contents or an (internal_)error event). \r\n\r\nIt seem like adding a `reason` field to `connection_state_updated` would work there too.\r\nAlternatively, this could be part of the envisioned `parameters_set` connectivity event that would replace both separate `connection_started` and `connection_close` semantics, though I'd feel a bit uneasy putting a `reason` field in `parameters_set` (semantics seem off).  \r\n\r\nBest to take a step back and look at this from a higher viewpoint to see if making all this generic gives us more benefits than simply having separate events for everything. \r\n",
          "createdAt": "2020-04-20T15:45:58Z",
          "updatedAt": "2020-04-20T15:46:10Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Here's my suggestion for a better `connection_state_updated` definition:\r\n```\r\nenum ConnectionState {\r\n    client_address_verified, // when the server considers the client's source address verified\r\n    handshake_complete, // handshake completed\r\n    handshake_confirmed, // handshake confirmed\r\n    draining, // CONNECTION_CLOSE sent\r\n    closed // connection actually fully closed, memory freed\r\n}\r\n```\r\n\r\nI added a `client_address_verified` to my earlier suggestion, since with https://github.com/quicwg/base-drafts/pull/3924, servers can make this decision based on multiple different criteria.\r\n\r\n@rmarx What do you think?",
          "createdAt": "2020-07-27T04:18:33Z",
          "updatedAt": "2020-07-27T04:18:33Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "I like splitting `active` into `handshake_complete` and `handshake_confirmed` as @marten-seemann is suggesting above, and I also like `client address verified` as an intermediate server state. On the client side, I would like to see logging of the transition between `started` and `heard_from_the_server`, which is pretty much the client equivalent of `client_address_verified`.\r\n\r\nOn the other hand, all these states can be trivially deduced from observing the packet flow. @rmarx is the connection_state event really useful?",
          "createdAt": "2020-08-02T00:25:57Z",
          "updatedAt": "2020-08-02T00:25:57Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I have to re-read the draft myself first, but a merge of Marten's proposal (with a \"started\" state or similar put back in) and Christian's suggestion of `heard_from_server` seems sensible at first glance.\r\n\r\nWith regards to \"do we need this event at all\"... it depends. If you're logging all packets: potentially not, though that might hide implementation bugs (state transfer too early/late). However, as @marten-seemann has also said wrt a separate `connection_closed` event (instead of simply watching the `connection_state_updated` for this) and the discussion on needing a `packet_acked` event (#107): when writing tools that try to quickly deduce these state transitions from a trace, it can be useful to have these \"duplicate\" events as well. I don't think I'd write many tools that fully rely on only these myself, and I wouldn't mark them as \"core\" events in the spec, but I can see why some people like to keep them in and have a preference for this myself as well (up to a certain point...)",
          "createdAt": "2020-08-02T10:37:53Z",
          "updatedAt": "2020-08-02T10:37:53Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Related to #43 ",
          "createdAt": "2020-10-31T14:00:18Z",
          "updatedAt": "2020-10-31T14:00:18Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Closing this and moving to #43 as the main tracking issue for this. ",
          "createdAt": "2020-11-02T20:37:30Z",
          "updatedAt": "2020-11-02T20:37:30Z"
        }
      ]
    },
    {
      "number": 79,
      "id": "MDU6SXNzdWU1OTg0NzE3MTI=",
      "title": "Add support for connection migration",
      "url": "https://github.com/quicwg/qlog/issues/79",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "Now that this is a bit more mature, it should be added to draft-02.\r\n\r\nVia @marten-seemann:\r\n> So I would assume that would best be modeled using a `path_probed` event (which has ips, ports, CID), and then a `path_confirmed` and a `path_abandoned` event\r\n\r\nSomewhat ties into #49 and #78 (and all other connectivity events really...).\r\nAlso look into how this is modeled in qlog for multipath by UCL (@mpiraux)",
      "createdAt": "2020-04-12T12:13:33Z",
      "updatedAt": "2021-08-18T09:44:32Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 80,
      "id": "MDU6SXNzdWU1OTg4MDAyNTQ=",
      "title": "Remove trigger fields from individual events",
      "url": "https://github.com/quicwg/qlog/issues/80",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Triggers are now said to be a global optional property of all \"data\" fields in an event.\r\n\r\nYet, some events (like `key_retired` and `key_updated` still include them. Make sure they don't.\r\n\r\ncc @marten-seemann ",
      "createdAt": "2020-04-13T10:07:15Z",
      "updatedAt": "2020-09-07T10:27:46Z",
      "closedAt": "2020-09-07T10:27:46Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "There were more of these than I expected, but all have been removed now. ",
          "createdAt": "2020-09-07T10:27:46Z",
          "updatedAt": "2020-09-07T10:27:46Z"
        }
      ]
    },
    {
      "number": 85,
      "id": "MDU6SXNzdWU2MDM2ODIzNzM=",
      "title": "split up events",
      "url": "https://github.com/quicwg/qlog/issues/85",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "design",
        "high-level-schema",
        "current-version"
      ],
      "body": "This is a high-level observation based on my experience of 1. adding qlog support for quic-go and 2. writing some tooling to sift through a pile of logs.\r\n\r\nWhen adding qlog support for quic-go, I already found it confusing that qlog bundles things that have little to do with each other into the same event. Examples for these are:\r\n* The values in `parameters_set` event in `transport` that are not part of the QUIC transport parameters.\r\n* The `pto_count` in `metrics_updated`.\r\n* The `connection_state_updated` event. This is the worst in this list.\r\n\r\nIn my implementation, I worked around this by exposing an API that exposes different functions, which then would encode the same qlog event (with the respective fields set). For example, I have a `qlog.UpdatedPTOCount()` and a `qlog.UpdatedMetrics()`, which both emit a `metrics_updated` event.\r\n\r\nWriting my own qlog parser, I'm now encountering the same problem again. For example, one interesting thing to monitor on a production system would be the reason why a connection was closed (to see if there are any PROTOCOL_VIOLATIONS, for example). It would make filtering much easier if there was a `connection_closed` event, instead of having to look at optional fields in all the `connection_state_updated` events emitted over the lifetime of the connection. A similar argument applies to the PTO count (Connections that experience a lot of PTO events might be interesting to look at. Connections that collect many RTT samples are not).\r\n\r\nFrom my discussions with @rmarx (and I hope that I'm paraphrasing him correctly here), the main argument for having fewer events was that it makes things easier to implement. I hope that I laid out my argument here that the opposite is the case.",
      "createdAt": "2020-04-21T03:43:01Z",
      "updatedAt": "2021-08-18T10:06:23Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So to me, this is a core question that I'd like to resolve before finalizing draft-02.\r\n\r\nMy viewpoint has indeed always been that too many individual events and definitions would lead people to support only a minor subset. As it is, even with heavy coalescing, we have a large amount of events today and many implementations only implement a subset of those. \r\n\r\nThat being said, I can see the appeal of splitting things out again, yet that would mean doing that at all layers (e.g., you can't have everything split out at `transport` but keep everything aggregated in `http` (or am I wrong about that?)).\r\n\r\nThere is another aspect of \"backwards compatibility\" with existing implementations that are being re-used (e.g., Lucas' Rust crate, qvis). I'm not sure if people are willing to make major changes at this point. On the other end: we probably shouldn't get bogged down by that at this point yet.\r\n\r\nSo I'd like some more input on this from other active implementers/contributors: @lpardue, @huitema, @jlaine, @nibanks, @mpiraux\r\n\r\n\r\n\r\n",
          "createdAt": "2020-04-21T08:41:07Z",
          "updatedAt": "2020-04-21T08:41:07Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "The crate is easy to update, I don't have many consumers of it right now and I do not have concerns about backwards compatibility. As long as qlog is versioned (which it is) I have no qualms about breaking changes. \r\n\r\nIn summary, qlog crate is not a concern in the decision you make",
          "createdAt": "2020-04-21T15:26:22Z",
          "updatedAt": "2020-04-21T15:26:22Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "After further discussion on slack, I think @marten-seemann's overall viewpoint is:\r\n\r\n- Events can be grouped, but only if they (a) logically belong together and/or (b) share the same fields\r\n\r\nThis leads to the following concrete example changes:\r\n- In the example of `connection_state_updated`, if there is a `reason` for the `connection_close` (see #78), that reason won't be present for `connection_attempted` and so it makes sense to split up those events.\r\n- In the example of `metrics_updated`, almost everything happens as the result of receiving an ACK, but `pto_count` does not (due to timer firing), so they should be split up as well. (tangent: max_ack_delay is a constant and should probably be in a `parameters_set` recovery equivalent)\r\n\r\nTentative conclusion: we don't need to split up everything as it stands now, just go through the events and make sure they adhere to the general principle above. I tend to agree with that. \r\n\r\nA prime candidate for re-evaluation is `transport:parameters_set`\r\n\r\n",
          "createdAt": "2020-07-08T08:38:47Z",
          "updatedAt": "2020-07-08T08:48:23Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "As indicated in the last comment above, I understand the arguments behind wanting to split up connection_state_updated and metrics_updated. \r\n\r\nI have now however spent a considerable amount of time thinking about splitting up `transport:parameters_set`, and I just don't see how it can be improved practically without introducing a large amount of one-of events or ending up with 2 very similar events in concept. \r\n\r\nConcretely, if parameters_set would indeed only contain the actual TLS-transport \"transport parameters\" from the QUIC draft, we'd need either:\r\n1. a separate `settings_set` event (or `configuration_chosen` or something) to contain other things in there (like chosen ALPN value, chosen version, chosen cipher, whether a retry is always required (e.g., DDoS prevention mode), whether early data is supported, etc.)\r\n2. multiple separate events, one for each thing: `version_selected`, `alpn_selected`, `cipher_selected`, ... etc. \r\n\r\nThis is then made more complicated by other issues that I can't seem to place easily either:\r\n- #28: how to list which ALPNs an endpoint supports (not the same as the one it actually sends/chooses)\r\n- #75: similar for the versions an endpoint supports (especially needed as not all connections send a VNEG containing (some of) this info)\r\n- #88: indicate which parameters were restored for 0-RTT (in that issue, @marten-seemann even advocates splitting up `parameters_set` into `parameters_sent` and `parameters_restored`, creating even more event types). \r\n\r\nAll these things could (for me) conceptually just be part of `parameters_set` (e.g., new `supported_versions` and `chosen_version` fields, logged at appropriate times with the correct owner). \r\nThe other option would be to split this out into several events, ending up with `local_configuration_set`, `configuration_chosen`, `parameters_restored`, etc. next to `parameters_set`... which, tbh, when listing it like that, I'm not sure is less confusing in the long run than having the single `parameters_set`.\r\n\r\nI somewhat have the feeling that I don't understand @marten-seemann's motivations for wanting to split up `parameters_set` the same way I do the two other examples in the first comment of this issue. At the moment, it feels mostly because of the semantics of the term `parameters` which is used for an explicit purpose in the QUIC drafts. Put differently: if we just renamed `parameters_set` to `configuration_chosen` (or similar), would you then still advocate for splitting the event? \r\n\r\nIf the answer is yes, I'd really like a concrete proposal for how to split them up exactly (mainly: how many different events would need to be created? option 1 or 2 above? and why?). \r\n\r\nInput from others in this is of course also greatly appreciated, as currently it seems mostly me and @marten-seemann having conflicting viewpoints. If we can't resolve this easily by tomorrow, I will punt this to draft-03. \r\n",
          "createdAt": "2020-11-01T20:01:16Z",
          "updatedAt": "2020-11-01T20:01:16Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "> Put differently: if we just renamed parameters_set to configuration_chosen (or similar), would you then still advocate for splitting the event?\r\n\r\nYes, definitely! This is not about the name, but by the confusing created by stuffing unrelated things into the same event. I'm not sure I understand the motivation for keeping the number of events small, event types are cheap (both in terms of specifying them, in terms of implementing them). \r\nWhat's not cheap is writing tooling that needs to figure out what actual event a \"catch-all\" event like `parameters_set` corresponds to. I doubt that this will be possible without some complicated heuristics. How do I distinguish between TPs restored and TPs taken from a default configuration? Can a tool rely on a `parameters_set` that sets the ALPN doesn't at the same time set QUIC TPs?",
          "createdAt": "2020-11-02T08:18:52Z",
          "updatedAt": "2020-11-02T08:19:17Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I decided to take the middle road for draft-02 to see how it feels.\r\n\r\nI have now split out QUIC versions and ALPN to separate events (`version_information` and `alpn_information`) as those were the two most pressing fields in need of treatment (see also their specific issues, e.g., #74, #28). This does make these things easier to grok and log, I admit. However, doing this for other similar stuff (especially things like TLS ciphers, key share groups, signature algo's, ...) will cause many more event types. \r\n\r\nWhile I agree that event types are cheap in concept, I've always been afraid that adding all these fine-grained events will feel daunting for new qlog implementers or people updating to a new draft or, especially, new tooling implementers (though there haven't been many of those). If most things are in the `parameters_set` event, which they probably want to support anyway, it should feel like less effort to also support additional fields. I'm not saying that's correct in practice, but just to explain why I've been somewhat hesitant to add many new event types. \r\n\r\nI feel that the relatively small scope of qlog in -00 and -01 has contributed to the adoption levels we're seeing, but maybe the argument can be made that now that we have a \"critical mass\" we can start splitting things out, expecting people to incrementally follow along. It does also probably make it easier to make \"dumb\" tools that just plot the data instead of those that do considerably more processing/logic in the tools like qvis (which is the type of tool @marten-seemann is most interested in, IIUC). \r\n\r\nIn short, I'm keeping this open, as this is a main general design decision going forward. \r\n\r\n\r\n",
          "createdAt": "2020-11-03T11:24:58Z",
          "updatedAt": "2020-11-03T11:24:58Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "I think one high level design decision needs to be made here first. Is the format of the logs supposed to be optimized for the performance of implementations generating them or for tools that are processing them? Generally, I believe it should be optimized for the ones generating them. Tools can afford the extra time and complexity because they're not in the production loop.\r\n\r\nAssuming there's general agreement with optimizing for the implementations and not the tools, then splitting up events makes sense in my opinion. For most of these things, the instantaneous action/operation that would trigger these events is very often isolated from much of everything else. Therefore trying to force extra packaging or coalescing requires implementations that don't already have it, to manage additional state.\r\n\r\nAs to the worry that all the individual events will make it feel daunting for new users/implementers of qlog, this is not unfounded, but things should be structured such that generally as many events as possible are optional, but you only get the full benefit out of the tools if you implement them all. In my opinion, tools should be **very** resilient to missing events for several reasons:\r\n\r\n1. Not all may be implemented (yet?).\r\n2. Filtering at collection time may be enabled (e.g. for performance reasons).\r\n3. Events may be lost at collection time (log buffer overflows are **very** common).\r\n4. Events containing PII data may not be allowed to be collected in production.\r\n\r\nThis obviously makes things much more complicated for the tool, but that's just unfortunately how things are.",
          "createdAt": "2020-11-03T16:22:39Z",
          "updatedAt": "2020-11-03T16:23:37Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Linking this to #107 for future reference, since that also contains a piece of this puzzle. ",
          "createdAt": "2021-04-23T07:58:18Z",
          "updatedAt": "2021-04-23T07:58:18Z"
        }
      ]
    },
    {
      "number": 86,
      "id": "MDU6SXNzdWU2MTA2NDIwNTU=",
      "title": "Need to add support for the token in an Initial packet",
      "url": "https://github.com/quicwg/qlog/issues/86",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Probably needs to be in the PacketHeader struct",
      "createdAt": "2020-05-01T08:41:49Z",
      "updatedAt": "2020-09-08T15:31:44Z",
      "closedAt": "2020-09-08T15:31:44Z",
      "comments": []
    },
    {
      "number": 88,
      "id": "MDU6SXNzdWU2MjM4MTk0NDk=",
      "title": "How to log transport parameters restored for 0-RTT",
      "url": "https://github.com/quicwg/qlog/issues/88",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "When initiating a 0-RTT connection, the client restores transport parameters that it remembers from the last connection. Currently, it has to use the `parameters_set` event for this, with `owner` equal to `server`.\r\n\r\nAs I've already argued in #85, the `parameters_set` event would benefit from being split up. Taking this issue into consideration, maybe `parameters_sent`, `parameters_received` and `parameters_restored` would be a good fit?",
      "createdAt": "2020-05-24T08:24:27Z",
      "updatedAt": "2020-11-03T11:27:29Z",
      "closedAt": "2020-11-03T11:27:29Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I have now added `transport:parameters_restored` and `http:parameters_restored` to help deal with this. I'm personally still not convinced this is better than simply logging them with \"owner\" equal to \"server\" as was the intent for draft-01, but do like the fact that it's more explicit this way. \r\n\r\nIt will depend a bit on how we're going to end up doing `parameters_set` in general (see #85). If we keep that, maybe an \"owner\" value of \"restored\" would be an interesting middle ground. Closing for now though. ",
          "createdAt": "2020-11-03T11:27:27Z",
          "updatedAt": "2020-11-03T11:27:27Z"
        }
      ]
    },
    {
      "number": 89,
      "id": "MDU6SXNzdWU2MjQxMzIzNTg=",
      "title": "Make traditional JSON the default, provide two optimization options",
      "url": "https://github.com/quicwg/qlog/issues/89",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, we utilize what I'd call a \"csv\" optimization, where the `time, category, event name and data fields` omit their keys (these are defined once in `event_fields`, much like csv columns are defined on top) and only log their values. This saves some bytes, but is non-trivial to parse (need to remember the order of the columns to know which value represents what) and to serialize (serializers typically don't like this type of thing).\r\n\r\nThis also breaks a bit with traditional JSON, which just lists the key names for every field as well. Using normal JSON would make it easier to serialize and parse, but increase the file size. \r\n\r\nThere is a third optimized option, which is to replace all keys (and potentially also values) with indices into a lookup table/dictionary. This was discussed in #30 and, especially in combination with compression, seems like a good optimization option. \r\n\r\nSo, to summarize, we have three options:\r\n1. csv column optimization (current default and only supported)\r\n2. pure JSON\r\n3. dictionary optimization\r\n\r\nThe proposal is to switch qlog to nr 2 as default, and present nr 1 and 3 as optional optimizations (which can also be done post-hoc and offline). There would not be a given static dictionary (at least not in draft-02), with the dynamic dictionary always included in the qlog. Implementations are of course free to provide a built-in static dictionary themselves.\r\n\r\nTools would be required to only support nr 2, with optional support for 1 and 3. qvis would support all 3. \r\n\r\nCompression (gzip, brotli or other) would be also described but not mandated (qvis already supports gzip and brotli atm). \r\n\r\ncc @marten-seemann @LPardue\r\n\r\nI also know @martinthomson had strong opinions on this, so it would be interesting to hear from you as I'd like to get this right for -02 now. ",
      "createdAt": "2020-05-25T08:22:55Z",
      "updatedAt": "2020-09-05T16:15:21Z",
      "closedAt": "2020-09-05T16:15:20Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I'd prefer to only have only 2. The choice of JSON as a logging format already means that we don't care about file size. I see little point in introducing piecemeal improvements to JSON's inefficiency to create what is essentially a new file format.\r\n\r\nIn addition to 2 I'd like to see a binary format (I know I've been nagging with this for a long time) that was built with efficiency considerations from the ground up.",
          "createdAt": "2020-05-25T08:28:11Z",
          "updatedAt": "2020-05-25T08:28:11Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Moving to only/mainly 2 does make a binary format a lot easier I think, as things can be more directly mapped and interchanged (at least from what I know now of protobufs). \r\n\r\nOne option would be to say: qlog draft is format agnostic (but uses JSON as examples because it's readable) and the events can be presented in other formats as well (i.e., qlog just defines the fields and their types per event, not their eventual \"on the wire\" serialization). Tools should provide conversions between other forms and JSON if they want to support alternate forms. Then, anyone can just make e.g., a protobuf format based on that. \r\n\r\nI am planning to move away from TypeScript format for the event definitions anyway, as it's needed to define e.g., the difference between 64-bit numbers, smaller numbers and strings (see #39). That requires a custom mapping to TypeScript/JSON anyway, so a protobuf (or similar) mapping fits in that logic too. ",
          "createdAt": "2020-05-25T09:41:36Z",
          "updatedAt": "2020-05-25T09:41:36Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "I think there's a good chance I could switch the `qlog` crate to 2) without an API change. Addding an API method would allow user selection, and be non-breaking in the first case.\r\n\r\nIt seems nice if logs could self-identify the serialization format, otherwise you're relying on tools to do heuristics. This could be done with file extensions, or qlog parameters, or file magic. It's probably hard to get complete coverage but something might be a quick win.",
          "createdAt": "2020-05-25T13:09:30Z",
          "updatedAt": "2020-05-25T13:09:46Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I was wondering if CBOR should be the standard format. The representation is very similar to JSON, but it provides better typing support:\r\n1. it can unambiguously represent uint64s (so #39 would be solved)\r\n2. it supports byte strings, eliminating the need for byte to string conversions (as remarked in #30). Those happen quite often, e.g. for connection IDs, retry token, stateless reset tokens etc.\r\n\r\nI'm not sure human readability should be a goal. For my part, I've never felt the urge to look at a raw qlog file, mostly thanks to amazing tools like qvis. I don't expect this situation to shift in favor of viewing raw files in the future, if at all, more tools will make it even less necessary to do so.\r\nThat being said, CBOR could easily be converted to a human-readable file format, should the need to manually inspect a trace arise.\r\n\r\nThere are also moderate file size savings, but those wouldn't be the main motivation here. CBOR of course doesn't provide any compression of map keys / values, so I'd expect CBOR qlogs to still be quite wasteful. Not sure if there's a schema-less serialization format that can use something like a dictionary to compress commonly used identifiers.",
          "createdAt": "2020-05-26T03:40:57Z",
          "updatedAt": "2020-05-26T03:44:55Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Finished this transformation in f5db7cdc8cd0cf37bfe5f1b0b4c54fc56ffc5f28.\r\n\r\nDraft 02 will use default JSON as prime format, with NDJSON for streaming. CBOR is discussed as an option, but provides few benefits over normal JSON when paired with compression. \r\n\r\nThe text now also includes (limited) discussion and reasoning on the choice of JSON as the default format, per tests mainly discussed in #30. \r\n",
          "createdAt": "2020-09-05T16:15:20Z",
          "updatedAt": "2020-09-05T16:15:20Z"
        }
      ]
    },
    {
      "number": 90,
      "id": "MDU6SXNzdWU2MjQ3MTE5Mjg=",
      "title": "Add events indicating reasons for stalls",
      "url": "https://github.com/quicwg/qlog/issues/90",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "For example, an application might have more data ready to send, but cannot due to Flow Control or Congestion Control or Anti-Amplification limits. \r\n\r\nThese are currently only observable for the Flow Control case and only if the sender sends *_BLOCKED frames (which is optional). \r\n\r\nI'm not sure in which category this type of event would belong though... maybe look at msquic's handling (they have this type of event for sure). \r\n\r\ncc @scw00",
      "createdAt": "2020-05-26T08:50:30Z",
      "updatedAt": "2021-08-18T10:07:16Z",
      "closedAt": "2021-08-18T10:07:16Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Duplicate of more detailed #132 ",
          "createdAt": "2021-08-18T10:07:16Z",
          "updatedAt": "2021-08-18T10:07:16Z"
        }
      ]
    },
    {
      "number": 91,
      "id": "MDU6SXNzdWU2MjQ3MTQ4MzM=",
      "title": "Add mechanism for tracking coalesced packets",
      "url": "https://github.com/quicwg/qlog/issues/91",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Currently, this can be done implicitly by looking at `datagrams_sent` and `datagrams_received` events, but: a) these are very chatty if enabled for the entire connection and b) it's still implicit.\r\n\r\nOne proposed option (cc @marten-seemann) would be to add an optional `datagram_id` field to the `packet_*` and `datagrams_*` events that allows explicit correlation. This id would be an implementation-specific thing though, since QUIC itself does not define it (can be as easy as an implementation incrementing a counter).\r\n\r\nAnother point from Marten:\r\n> Note that this would also allow to correlate packets that processed at different times: assume that one packet contained in a datagram can be processed immediately, but it is coalesced with a packet of an encyrption level that the endpoint doesn\u2019t have keys for, and needs to buffer first\r\n\r\nIn that case, we probably also need to add the datagram_id to the `packet_buffered` event",
      "createdAt": "2020-05-26T08:54:28Z",
      "updatedAt": "2020-11-01T20:32:43Z",
      "closedAt": "2020-11-01T20:32:43Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "And to `packet_dropped`.",
          "createdAt": "2020-05-26T09:07:47Z",
          "updatedAt": "2020-05-26T09:07:47Z"
        }
      ]
    },
    {
      "number": 94,
      "id": "MDU6SXNzdWU2NDIzNTgwMDc=",
      "title": "Add support for retry token and integrity tag",
      "url": "https://github.com/quicwg/qlog/issues/94",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "Related to #86 , probably also best at home in the PacketHeader struct.\r\n\r\nProposal:\r\n- use a single `token` field for both retry and initial tokens\r\n- use a single `token_length` field for initial (explicit) and retry (implicit), `integrity_tag` field for retry",
      "createdAt": "2020-06-20T11:16:37Z",
      "updatedAt": "2020-11-18T10:19:57Z",
      "closedAt": "2020-11-18T10:19:57Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I don\u2019t think we need to log the integrity tag. We also don\u2019t log the AEAD tag for normal packets.",
          "createdAt": "2020-06-20T12:37:16Z",
          "updatedAt": "2020-06-20T12:37:16Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "It would probably be interesting to log if the token is a Retry token or a NEW_TOKEN token.\r\nFor the client, this bit of information is trivially available, for the server it is after it unprotects the token (assuming unprotecting succeeds), as servers are required to be able to distinguish between Retry and NEW_TOKEN tokens.",
          "createdAt": "2020-07-08T08:58:20Z",
          "updatedAt": "2020-07-08T08:58:20Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This was partially fixed in https://github.com/quiclog/internet-drafts/commit/ac00848b50c1da3feaf50f43938e962a091396b0. That was just the most straightforward change though, just adding fields that allow logging the tokens.\r\n\r\nThis does not yet allow differentiating NEW_TOKEN from Retry and we currently have no way of keeping those two separate (or e.g., to log that a NEW_TOKEN was successfully accepted). \r\n\r\nI am unsure about the design for that though... my gut tells me to move to separate `token_created` and `token_processed` events, which would in turn also allow logging the token's raw contents instead of logging them in the `packet_*` events. \r\n\r\nExample:\r\n```\r\ntoken_created\r\n\ttype: \"retry\"|\"resumption\"|\"stateless_reset\",\r\n\r\n       metadata:any, // to allow implementations to log which field are contained within an (encrypted) token\r\n\t\r\n\traw_length?:uint32,\r\n\traw?:bytes\r\n\r\ntoken_processed\r\n\ttype: \"retry\"|\"resumption\"|\"stateless_reset\",\r\n\tstatus: \"accepted\"|\"rejected\",\r\n\t\r\n       metadata:any, // to allow implementations to log which field are contained within an (encrypted) token\r\n\r\n\traw_length?:uint32,\r\n\traw?:bytes\r\n\r\n\ttrigger: why accepted/rejected \r\n\t\tinvalid_format\r\n\t\tinvalid_source\r\n\t\tinvalid_contents\r\n\t\t-> NOTE: for retry, this should also lead to a connection close with INVALID_TOKEN\r\n\r\n```\r\n\r\nHowever, I'm not sure this is the best approach. I'm going to mark this extension for draft-03 and keep the more straightforward option for draft-02. ",
          "createdAt": "2020-09-08T15:37:20Z",
          "updatedAt": "2020-09-08T15:37:20Z"
        }
      ]
    },
    {
      "number": 95,
      "id": "MDU6SXNzdWU2NTMwODU3NTI=",
      "title": "remove the time_units configuration",
      "url": "https://github.com/quicwg/qlog/issues/95",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "All time values are encoded as floats, so it doesn't make any difference if we encode them in ms or in \u03bcs.\r\n\r\nRemoving the configuration option makes it easier to implement qlog parsers, since there's less state to carry around to parse events.",
      "createdAt": "2020-07-08T08:09:14Z",
      "updatedAt": "2020-07-11T20:49:16Z",
      "closedAt": "2020-07-11T20:49:16Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "While I agree it makes it more difficult to parse, I'm not sure we can remove this?\r\n\r\nWould you advocate for forcing implementation to log either ms or \u03bcs (and do x1000 or /1000 if they use the other internally) then? Currently, I think we have about 4 implementations doing \u03bcs. ",
          "createdAt": "2020-07-08T08:12:48Z",
          "updatedAt": "2020-07-08T08:12:48Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "It doesn't matter which one is removed. Currently, I'm logging in ms (just because it's the default).\r\nChanging this to \u03bcs would basically just being a change from calling `duration.Milliseconds()` to `duration.Microseconds()` (see https://github.com/lucas-clemente/quic-go/blob/master/qlog/event.go#L14). I assume it's the same for other implementations: You have one (language/implementaton-specific) time representation, and you convert that to whatever unit you export to qlog.",
          "createdAt": "2020-07-08T08:27:47Z",
          "updatedAt": "2020-07-08T08:27:47Z"
        }
      ]
    },
    {
      "number": 96,
      "id": "MDU6SXNzdWU2NTMxMDY1MTI=",
      "title": "in_recovery is a congestion_state_updated event and doesn't belong in metrics_updated",
      "url": "https://github.com/quicwg/qlog/issues/96",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "indicating whether the CC has entered recovery can currently be done in two ways, should probably removed this from `metrics_updated`.\r\n\r\ncc @marten-seemann ",
      "createdAt": "2020-07-08T08:40:20Z",
      "updatedAt": "2020-07-08T09:29:59Z",
      "closedAt": "2020-07-08T09:29:59Z",
      "comments": []
    },
    {
      "number": 97,
      "id": "MDU6SXNzdWU2NTMxMTA2OTA=",
      "title": "Indicate (encoded) sizes",
      "url": "https://github.com/quicwg/qlog/issues/97",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Currently we do not have many fields for indicating (compressed) sizes of things.\r\n\r\nWe have the `packet_size`, but this is in the wrong place (#40) and `payload_length` (though it's not well-defined whether packet_size includes the TLS suffix). \r\n\r\nHowever, we lack size indicators for datagrams and, especially frames. When creating the qvis packetization diagram, this was very annoying, as I'd have to reconstruct the encoded frame headers to properly render those (and even then there might be rounding issues if the sender didn't encode things in the absolute minimum of bytes allowed). \r\n\r\nIn comparison, wireshark output does include exact sizes for these fields for TCP/TLS/H2 and this was quite handy. \r\n\r\nAnother point: need some way to indicate the used TLS AEAD tag length (though that should be constant for the entire connection and depends on the used cipher IIUC. For TCP+TLS from Wireshark I also had to manually calculate this from the cipher definitions though, which was a PITA). \r\n\r\nFinally, make terminology consistent (_size vs _length)\r\n",
      "createdAt": "2020-07-08T08:46:33Z",
      "updatedAt": "2020-11-02T16:54:20Z",
      "closedAt": "2020-11-02T16:54:20Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "From a discussion on slack, most are in favor of adding AEAD length to the general packet_size field (one reasons is because the tag also contributes to cwnd calculation)",
          "createdAt": "2020-08-06T14:10:11Z",
          "updatedAt": "2020-08-06T14:10:11Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "We have a bit of a weird situation with packet_size, payload_size and header_size, in that if you have 2, you can calculate the third from those... so do we want to specify all three? \r\n\r\nI would reckon that packet_size and payload_size will typically be readily available to implementations, but header_size might be more difficult to come by (as headers can be of varying sizes, while payload is \"the rest of the packet after the header has been processed\"). \r\n\r\nFinally, there is overlap with what we currently call \"raw_length\" if we're logging the full raw byte contents of the packet (in the \"raw\" field, which we currently name \"raw\" across all events for consistency). To keep naming consistent, you'd want this \"raw_length\" here as well, but you also kind of want \"packet_size\" to show the core semantics (especially as I'd suspect most won't log the raw values (and accompanying \"raw_length\") in most places, but do log packet_size). A similar remark for datagram_size in the datagram_* events... do we live with having the same field defined twice with different names or do we remove packet_size and datagram_size and explain that people should use raw_length for those instead (I'm personally tending to this latter option).\r\n\r\nCould use some input on this @marten-seemann, @huitema, @dtikhonov\r\n\r\n",
          "createdAt": "2020-09-07T20:00:22Z",
          "updatedAt": "2020-09-07T20:00:22Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Ended up not logging the header_length and writing out how it can be calculated from total length and payload length and aead length.\r\n\r\nCurrently, aead length is logged separately in `transport:parameters_set`, which is not optimal, but good enough for now until we figure out what to do with that event and how to split it up (see #85)\r\n\r\n\r\nFinally, I ended up keeping explicit length fields when they are used in the QUIC/H3 drafts. This is not the case for the `packet_size` field, so that has now been changed to `raw.length` instead. I'm not entirely enamored by this, as arguably .packet_size was clearer, but since we're moving packet_size out of Header anyway (see #40), it felt best to keep things consistent and punt this to the new RawInfo approach. \r\n",
          "createdAt": "2020-11-02T16:54:20Z",
          "updatedAt": "2020-11-02T16:54:20Z"
        }
      ]
    },
    {
      "number": 100,
      "id": "MDU6SXNzdWU2NTMxMTYzNDc=",
      "title": "make it possible to log persistent congestion",
      "url": "https://github.com/quicwg/qlog/issues/100",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "design",
        "current-version"
      ],
      "body": "This would be *really* important for generating metrics.\r\n\r\nLogically, it's a congestion event, but I'm not sure if it would probably make sense to add this as a state to the `congestion_state_updated` event, because once you declare persistent congestion, your congestion controller enters either slow start or congestion avoidance (not sure which one, haven't implemented persistent congestion yet), which are already `congestion_state_updated` events.",
      "createdAt": "2020-07-08T08:54:37Z",
      "updatedAt": "2021-08-18T10:09:13Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So currently this is done using a trigger of \"persistent_congestion\" on the `congestion_state_updated` event (i.e., https://quiclog.github.io/internet-drafts/draft02/draft-marx-qlog-event-definitions-quic-h3.html#name-congestion_state_updated).\r\n\r\nReading your issue above, that seems like all that's needed? I know you have more experience with persistent_congestion at this point, so wondering if that is enough or we need something else?  ",
          "createdAt": "2020-09-08T12:26:44Z",
          "updatedAt": "2020-09-08T12:26:44Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I'm unsure if this is still an issue given my comment above @marten-seemann? ",
          "createdAt": "2020-10-31T13:52:21Z",
          "updatedAt": "2020-10-31T13:52:21Z"
        }
      ]
    },
    {
      "number": 101,
      "id": "MDU6SXNzdWU2NTMxMjM3NjI=",
      "title": "Combine category and event type",
      "url": "https://github.com/quicwg/qlog/issues/101",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, we have two separate fields for category and event type.\r\n\r\nIn a default JSON form, you'd have:\r\n```\r\n{\r\n    category: \"transport\",\r\n    type: \"parameters_set\"\r\n}\r\n```\r\n\r\nHowever, the event type names (e.g., `parameters_set`, `state_updated`) aren't unique to the categories at the moment. \r\n\r\nThis can lead to some issues:\r\n- Processing qlog requires you to always check the category as well (cannot just look at the event_type)\r\n- Makes them difficult to encode in formats like protobuf (e.g., https://github.com/quiclog/pcap2qlog/blob/binary/src/converters/types/qlog.proto#L54) (and I assume things like serde as well @LPardue?) because you cannot easily de-serialize based just on the type-name.\r\n\r\nOne solution would be to combine both into one field:\r\n```\r\n{\r\n    type: \"transport:parameters_set\"\r\n}\r\n```\r\n\r\nThis should make it easier to de-serialize just based on the type field (and make it into an enum) and easier to do a `switch` when processing events. \r\n\r\nAnother option would be to make sure each event has a unique name, but that would come down the pre-pending the category (or something similar) anyway afaict (e.g., `transport_parameters_set`), which is basically the same thing. \r\n\r\nI don't see many use cases where you'd only want to log one category (and thus could leave that out and just log the event names to save some space). I also don't know if compression would be that much worse overall if we'd combine the two into one field. If we'd move to regular JSON as the default (#89), it would probably save space, as then we'd only have a single field per-object instead of 2 (as in the examples above).\r\n\r\nWhat do people think? CC @LPardue  @marten-seemann @mpiraux @triplewy @mikkelfj @nibanks @jlaine\r\n\r\n \r\n",
      "createdAt": "2020-07-08T09:04:43Z",
      "updatedAt": "2020-09-05T16:18:38Z",
      "closedAt": "2020-09-05T16:18:38Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Makes sense to me. I support making this change.",
          "createdAt": "2020-07-08T09:17:31Z",
          "updatedAt": "2020-07-08T09:17:31Z"
        }
      ]
    },
    {
      "number": 102,
      "id": "MDU6SXNzdWU2NTMxMjQ1OTY=",
      "title": "remove redundant length fields",
      "url": "https://github.com/quicwg/qlog/issues/102",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Once we require hex-encoding for byte-fields (which, as far as I can see from other peoples' qlogs, is already the de-facto standard), we don't need length fields any more. This applies to the `scil` and `dcil` in the `Header` (as well as the proposed token length in #94), the `NewTokenFrame`, `NewConnectionIDFrame` (and probably also the QPACK events, but I'm not an expert on those).",
      "createdAt": "2020-07-08T09:05:51Z",
      "updatedAt": "2020-11-02T16:50:46Z",
      "closedAt": "2020-11-02T16:50:45Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I kind of disagree, as I think an important use case is where you'd not want to log the raw values but only the lengths. \r\n\r\nWe can argue whether that's the case for the CIDs of course, but for tokens and qpack data (and, obviously, payloads), I think people should have the option to not log the raw values. \r\n\r\nThis flows from privacy/security concerns, as well as storage efficiency for larger deployments. \r\n\r\nI do think we could add text stating something like \"if you log the raw values in hex, the length field is redundant, and tools SHOULD be able to derive length from hex\"?",
          "createdAt": "2020-07-08T09:13:08Z",
          "updatedAt": "2020-07-08T09:13:08Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Good point. I can see why you want to log tokens (since they create a correlation spanning two separate connections).\r\n\r\n> I do think we could add text stating something like \"if you log the raw values in hex, the length field is redundant, and tools SHOULD be able to derive length from hex\"?\r\n\r\nI'd make this an even stronger statement: \"\"if you log the raw values in hex, the length field is redundant and SHOULD (or MUST?) be omitted. Tools MUST be able to derive length from hex\".",
          "createdAt": "2020-07-08T09:20:09Z",
          "updatedAt": "2020-07-08T09:22:53Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Fixed by above commits.\r\n\r\nMain draft now explains how truncated raw byte values should be accompanied by a length field and that tools should be able to derive the length field from the raw byte values. \r\n\r\nEvent definitions draft references this explicitly when discussing the RawInfo approach. ",
          "createdAt": "2020-11-02T16:50:45Z",
          "updatedAt": "2020-11-02T16:50:45Z"
        }
      ]
    },
    {
      "number": 104,
      "id": "MDU6SXNzdWU2NTMxMzAxNTY=",
      "title": "consider removing StreamFrame.raw",
      "url": "https://github.com/quicwg/qlog/issues/104",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "design",
        "future-versions",
        "privacy"
      ],
      "body": "I can't see how logging the exact contents of a STREAM frame could facilitate debugging / analysis of QUIC connections.\r\n\r\nArguably, a transport-level logging system should not log application data exchanged, as this might expose user data to places where it doesn't belong. While qlog can't prevent implementations from adding additional JSON fields to existing events, it should not encourage this behavior.",
      "createdAt": "2020-07-08T09:14:00Z",
      "updatedAt": "2021-08-18T10:10:23Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "While I agree from a security/privacy perspective that it shouldn't be encouraged, I disagree somewhat about the non-usefulness in debugging (esp. if you go beyond just H3 and look at things like DoQ or MASQUE). \r\n\r\nTwo direct alternatives I can see at the moment:\r\n- Remove from QUIC STREAM, but keep it on H3 DATA (though this means people can't easily get this without also logging H3/app-layer events, which e.g., things like quant might not like)\r\n- Add a generic `raw` and/or `raw_payload` field for all events to use (much like what we have for `trigger`). This makes it less obvious per-event (so less encouraged you might say) while still keeping a common name for interoperable tooling. \r\n\r\nOverall though, I'd vote to just keep it as-is. While it shouldn't be encouraged, it should imo be -possible- to express in the format for specific use cases. I'd even go one step further and add an explicit `raw` field to the datagram_* events (especially `datagram_dropped`) as I've seen several times in the slack that packets aren't being decoded correctly and having the raw values available could help there. \r\n\r\nIf we do keep `raw`, I'd propose to work out a scheme to allow logging only the first x-bytes though (e.g., `raw: 0xABABCD...(436)` indicating there were 436 more bytes not logged). ",
          "createdAt": "2020-07-08T09:23:36Z",
          "updatedAt": "2020-07-08T09:27:44Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Added a generic \"RawInfo:data\" field in the last commit. Byte-fields can be logged in a truncated form now as well (see main draft), which alleviates some of the privacy issues. \r\n\r\nKeeping this issue open to remember to add stringent prohibitions on logging/exposing raw data in the privacy section later. \r\n",
          "createdAt": "2020-11-02T16:49:14Z",
          "updatedAt": "2020-11-02T16:49:14Z"
        }
      ]
    },
    {
      "number": 105,
      "id": "MDU6SXNzdWU2NTUwMDg1NDk=",
      "title": "Log Retry and Connection in same Qlog file, use ODCID for indentification",
      "url": "https://github.com/quicwg/qlog/issues/105",
      "state": "OPEN",
      "author": "huitema",
      "authorAssociation": "NONE",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "design",
        "high-level-schema",
        "current-version"
      ],
      "body": "Many implementations identify the Qlog file using the \"Initial DCID\" used by the client. In the case of Retry, this results in two Qlog traces: one identified by the original DCID that contains the first initial packet of the client and the Retry packet that the server produced, and a second one identified by the Initial DCID used in the subsequent connection.\r\n\r\nMy proposal is to use a single file for the retry and for the next connection, identified by the ODCID. But I wonder whether that's going to break something.",
      "createdAt": "2020-07-10T20:06:03Z",
      "updatedAt": "2021-08-18T10:11:49Z",
      "closedAt": null,
      "comments": [
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "The current spec kind of gives up on the issue. It says \"Note that this can make it difficult to match logs from different vantage points with each other. For example, from the client side, it is easy to log connections with version negotiation or stateless retry in the same trace, while on the server they would most likely be logged in separate traces.\" My point is that it can be solved on the server, if the server keys logging events with the ODCID.",
          "createdAt": "2020-07-10T20:11:56Z",
          "updatedAt": "2020-07-10T20:11:56Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "> My point is that it can be solved on the server, if the server keys logging events with the ODCID.\r\n\r\nThat's correct, and it's a trivial thing to do. The server needs to encode the ODCID in the token anyway, to be able to send it in the transport parameters. In fact, that's [how quic-go does it](https://github.com/lucas-clemente/quic-go/blob/e7fa420e264c4d319625c6dbf7cdf1c7668e7535/server.go#L452-L456).",
          "createdAt": "2020-07-11T01:36:30Z",
          "updatedAt": "2020-07-11T01:36:46Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "@huitema I'm not 100% sure what the issue is here.\r\n\r\nThe current qlog text explicitly mentions using the ODCID as filename for qlog files as the \"lowest common denominator\". Furthermore, qlog files can contain multiple individual traces, as the `traces' property is an array. So it's already perfectly possible to log one trace for the first connection and then a second trace for the retried one after that. As @marten-seemann said, there are people doing just that already. Maybe the problem is in the wording? That you interpret a `trace' as a single file, and I interpret it as a list of events, where 1 file can contain multiple traces? \r\n\r\nAnother approach would be to use the `group_id' field and not set that to an ODCID but assign that a sort of internal server number based on IP+port or something to uniquely identify a client across attempts. That would work even for \"version negotiation\", as there you don't have the luxury of having a stable ODCID. I don't want to mandate this type of thing in the text though, since it all implies the server needs to keep extra state around to match up connections, and some (most?) won't want to do that (in production). \r\n\r\nIn short: I'm not sure what you'd like me to change to the text at this time. \r\n\r\n\r\n\r\n",
          "createdAt": "2020-07-11T15:53:59Z",
          "updatedAt": "2020-07-11T15:53:59Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "> So it's already perfectly possible to log one trace for the first connection and then a second trace for the retried one after that. As @marten-seemann said, there are people doing just that already.\r\n\r\nActually, that's not what I'm doing. I'm not logging the first Intitial received and the Retry sent at all on the server side (only on the client side), since there's no reasonable way of logging events that happen outside of a connection (see #106).",
          "createdAt": "2020-07-12T01:08:58Z",
          "updatedAt": "2020-07-12T01:08:58Z"
        }
      ]
    },
    {
      "number": 106,
      "id": "MDU6SXNzdWU2NTUwMTI5OTY=",
      "title": "Logging events outside of connections",
      "url": "https://github.com/quicwg/qlog/issues/106",
      "state": "CLOSED",
      "author": "huitema",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Servers typically notice events happening outside of connections: packets for which the DCID is not recognized, malformed Initial packets, etc. When debugging and looking at both client traces and server traces, it might be useful to match a client packet with an out-of-connection event at the server. I wonder how to do that within the qlog framework.",
      "createdAt": "2020-07-10T20:15:49Z",
      "updatedAt": "2020-09-05T16:18:06Z",
      "closedAt": "2020-09-05T16:18:06Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I encountered the same issue. I think the root of the problem is that qlog is not streamable. Otherwise, you could just have a `server.qlog` and append every event that's not matched to any connection.\r\n\r\nSure, you can always play some tricks to work around this issue, like exporting a server qlog every one hour, for example. Downside is, of course, that you wouldn't have access to the events that happened with the last hour.\r\n\r\nBroadening the scope of this issue, I'd say the root cause is that qlog is trying to make it possible to have multiple traces per file. Sure, it's possible, but only by giving up on streamability. I'm not sure if that's a feature worth having though, considering how much complexity it creates for the format itself (and for parsers that want to support it). I'd actually prefer to have a format that looks something like this:\r\n```\r\n<header>\r\n   config options, vantage, other trace-related metadata\r\n</header>\r\n<events>\r\n\r\n<events>\r\n```\r\n",
          "createdAt": "2020-07-11T01:34:15Z",
          "updatedAt": "2020-07-11T01:34:15Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So, here again (like with #105, which I see as similar to this, maybe read my reply there first) I'm not sure what the issue is.\r\n\r\nIf an event cannot be matched to a connection, it's difficult to log it together with other events without keeping extra state and doing some work. That is usually relatively easy though: you can e.g., match IP+port of a malformed initial to other proper packets from the same source and aggregate them in the same trace based on that. Then you do need to add extra logic for migration etc. but it's certainly possible I'd say? \r\n\r\nAnother option is as @marten-seemann mentions to have a single big `server.qlog' that includes all the events that don't nicely match to a connection (this could also include things you reply to with a version negotiation for example). I think Lars does this for quant. To me, it depends on how you want to debug your setup and how you approach these types of errors. I'm not sure if there needs to be more text on this? \r\n\r\n-----------\r\n\r\nI am however unsure about why this `server.qlog` wouldn't be possible with the JSON-based setup... each qlog event is self-contained (it's a single array with some values and in draft-02 will be a single object) and can trivially be appended to a file by prepending it with a `,`. \r\n\r\nThe thing that makes a JSON file that was \"streamed\" a bit more awkward is that you'd need to close it with a `]}]}' to be \"valid JSON\". However, qvis for example includes a fallback to a streaming parser (http://oboejs.com) to deal with files that don't do this and it seems to work perfectly fine (was initially added for cases where the endpoint shuts down unexpectedly and doesn't have time to print those final closing characters). Furthermore, this case is trivially fixed by a post-processor that adds those characters if they're not found at the end of a file. \r\n\r\nAm I missing something crucial in this discussion on streaming? Several people have brought this up (e.g., @martinthomson) but I have always considered this a non-issue. If we were switch to e.g., a csv-format, you'd have to write custom parsers for that as well (which would likely be slower than optimized, built-in JSON parsers), while now at least you get a free JSON parser if your files are well-formed (which, from my experience, most are or can be made to be). \r\n\r\nI also don't agree this is due to having support for multiple traces in one file. You can have just a single trace and use `group_id' to split things out later. The only thing this adds is the extra `]}`. Even if we left that out and stayed with JSON, you'd still be stuck with the other `]}' to close the `<events>` list and total object. \r\n\r\nFinally, especially for @marten-seemann, these might be moot points for draft-02, as that should make it much easier to use protobufs or similar instead of JSON. Still, I'd love some feedback on my points above, to make sure I'm not missing a key point in this discussion. \r\n\r\n",
          "createdAt": "2020-07-11T16:12:46Z",
          "updatedAt": "2020-07-11T16:12:46Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "> I am however unsure about why this server.qlog wouldn't be possible with the JSON-based setup... each qlog event is self-contained (it's a single array with some values \r\n\r\nI'm not sure if I understand your point. I thought this is not the case. You can have multiple traces per file, so you'd have a file where events are appended at different locations within that file.\r\nThis is why I suggested getting rid of this corner case by saying that `1 qlog file == 1 trace`. That would simplify things quite a bit.\r\n\r\n> Am I missing something crucial in this discussion on streaming? Several people have brought this up (e.g., @martinthomson) but I have always considered this a non-issue.\r\n\r\nI'd be curious to hear what other peoples' requirements are here.\r\nFor me, streaming means that you have a valid at any given moment. With the qlog format that's not possible since you'll always be missing some closing `]` and `}`.\r\nImagine you want to build a tool like the UNIX command line utility `tail` for qlog, which outputs events as soon as they come in. This would be hard to do, as you're dealing with invalid JSON most of the time. \r\nThings are further complicated by the fact that JSON doesn't define the order of the fields within an object (for example, it would be valid qlog if `common_fields` comes after the `events`, and iirc, I've seen at least one qlog implementation write files like that).\r\n\r\n>  If we were switch to e.g., a csv-format, you'd have to write custom parsers for that as well (which would likely be slower than optimized, built-in JSON parsers), while now at least you get a free JSON parser if your files are well-formed (which, from my experience, most are or can be made to be).\r\n\r\nWhen I think of slow encoders, I think of JSON...\r\nThat being said, I don't think JSON buys us a lot here. The fact that qlogs have `common_fields` and `event_fields`, and that events are not exported as objects but as arrays makes it quite cumbersome to write a qlog exporter / parser. As I understand, the `event_fields` are effectively an attempt to build in some compression into the format, an attempt rendered moot by the fact that JSON is an inherently space-inefficient file format. gzipping a tyical qlog gives you a file smaller than 10% of the original file size... so I can't help to think of this as a premature optimization.",
          "createdAt": "2020-07-12T02:32:10Z",
          "updatedAt": "2020-07-12T02:32:10Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "+1 on premature optimization. I tripped on the event_fields when writing a python parser for the qlogs, and I see that others have similar issues. If you want to reduce volume, it would be simpler to just have shorter names for the variables.",
          "createdAt": "2020-07-12T02:37:29Z",
          "updatedAt": "2020-07-12T02:37:29Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "+1 on format too. I would very much like to be able to just add an event by appending the data at the end of the log file. I can do that with my binary logs, and then call a converter to produce the qlog and add the required set of curly and square brackets at the end. But with an actual qlog file, I would have to roll back the end of the file, remove the end brackets, write the event, and then add the brackets again. Kind of, not funny.\r\n",
          "createdAt": "2020-07-12T03:09:04Z",
          "updatedAt": "2020-07-12T03:09:04Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I believe this was resolved with the introduction of the streaming NDJSON option (discussed in #109) and other options I outlined in https://github.com/quiclog/internet-drafts/issues/106#issuecomment-657087933. If not, feel free to re-open. \r\n\r\n\r\n",
          "createdAt": "2020-09-05T16:18:06Z",
          "updatedAt": "2020-09-05T16:18:06Z"
        }
      ]
    },
    {
      "number": 107,
      "id": "MDU6SXNzdWU2NTU1NjA4MzM=",
      "title": "Do we need an acked_packet event?",
      "url": "https://github.com/quicwg/qlog/issues/107",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "We have a `lost_packet` event, but no corresponding `acked_packet` event. That event would fire when a packet is acknowledged and removed from the map of sent packets.\r\n\r\nA parser that wants to track when a packet is (first) acknowledged would have to build a map of sent packets, and remove packets from that map when they are either acknowledged, declared lost or when the packet number space is lost.",
      "createdAt": "2020-07-13T03:49:47Z",
      "updatedAt": "2020-11-01T20:34:19Z",
      "closedAt": "2020-11-01T20:34:19Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So this is similar to \"do we need a `connection_closed` event?\" in that there's a question of how many \"redundant\" ways we can have to log the same event. \r\n\r\nFor connection close and packet acked, the reasoning initially was that those could be fully parsed from the corresponding frames inside `packet_sent` and `packet_received` and thus didn't need an extra event. \r\n\r\nI can now see the reasoning for wanting a specific `connection_closed` event (e.g., logging an internal reason that you don't send over the wire), but I'm not sure what a separate `acked_packet` event would give us. For some use cases it would make it easier (if you're not parsing frames inside the `packet_*` events), but in most, I feel it would make things more complicated (do I need to log both? Do I skip logging of ACK frames if I do `acked_packet`? etc.). I do see that receipt of an ACK frame is potentially different from adding/removing to the internal packet datastructure (given duplicate acks), but not sure that should be exposed in a default way in qlog (we have many more of those type of `implied` actions that are expected to happen upon frame processing. Though there is some precedent of exposing that type of thing, e.g., in `data_moved`). In most cases, it was expected that tools could derive this type of action from the logged frames (e.g., like how I track retransmissions and gaps in streams in qvis: those are also not explicitly logged).",
          "createdAt": "2020-07-13T14:15:51Z",
          "updatedAt": "2020-07-13T14:18:11Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "Personally, I agree with @marten-seemann. MsQuic logs (to [ETW](https://docs.microsoft.com/en-us/windows/win32/etw/event-tracing-portal)) events or state changes for things. For qlog, we then have a converter. We don't log the contents of every packet or frame. For packets, we track when they're created, acknowledged, dropped, assumed lost, deemed spuriously lost, etc. IMO, tools that process the logs should not have to know how to process a logged ACK frame to then go calculate which in-flight packets have now been acknowledged. Another reason, is that our logging system doesn't assume full state was contained within the log file. The logs may have been started mid run or the fixed fixed log buffer rolled over. In those cases, you wouldn't necessarily have the created event for a packet and wouldn't know what is already in-flight.",
          "createdAt": "2020-07-13T14:30:59Z",
          "updatedAt": "2020-07-13T14:30:59Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Paraphrasing an argument I made in a Slack conversation:\r\n \r\nI can see @rmarx's argument that logging both the ACK frame and `packet_acked` is kind of redundant, given that a parser can build a copy of the packet map. However, I\u2019d rather log a `packet_acked` event instaed of the content of ACK frames. I care more about the state changes than about what redundant ACK ranges get serialized on the wire.",
          "createdAt": "2020-08-03T15:09:41Z",
          "updatedAt": "2020-08-03T15:09:41Z"
        }
      ]
    },
    {
      "number": 109,
      "id": "MDU6SXNzdWU2Njc2MjkwNjI=",
      "title": "Add streaming option",
      "url": "https://github.com/quicwg/qlog/issues/109",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Current thinking is to allow http://ndjson.org and to log the qlog header information as a separate object on top. \r\nThis would remove the possibility to log multiple traces in the same qlog file if it uses the streaming option, so users would need to use `group_id` in those cases.\r\n\r\nWould also require the addition of a \"format\" field to the qlog metadata header (though we probably need that anyway if we want to keep support for other JSON-based optimizations like `event_fields`.\r\n\r\nWe first need to check how this plays with oboe.js in qvis though, to see if we need to add another parser in the mix. \r\n\r\nSee also #106 and #2 for more discussion.\r\n\r\nFor comparison:\r\n```\r\nDraft-01 would look like this (if, like me, JSON serializers would be too lazy to add quotes):\r\n{\r\n    version: draft-01,\r\n    traces: [\r\n        {\r\n             vantage_point: client,\r\n             common_fields: [ ... ],\r\n             event_fields: [ ... ], \r\n             events: [\r\n                 [ 55, transport, packet_sent, { ... } ],\r\n                 [ 66, transport, packet_received, { ... } ],\r\n                 ...\r\n             ]\r\n        }\r\n    ]\r\n}\r\n\r\nDraft-02 would be more like:\r\n{\r\n    version: draft-02,\r\n    format: \"ndjson\",\r\n    trace: {\r\n             vantage_point: client,\r\n             common_fields: [ ... ]\r\n     }\r\n}\r\n{ time: 55, name: \"transport:packet_sent\", data: { ... } }\r\n{ time: 66, name: \"transport:packet_received\", data: { ... } }\r\n...\r\n```\r\n\r\nCC @marten-seemann @huitema",
      "createdAt": "2020-07-29T07:49:26Z",
      "updatedAt": "2020-09-05T16:25:57Z",
      "closedAt": "2020-09-05T16:25:57Z",
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I like this idea. In the interest of keeping parsers simple, I would be supportive of completely replacing the current qlog format with this.\r\nAs I've said elsewhere, I don't think that the complexity that comes with putting multiple traces into the same file justifies the complexity.",
          "createdAt": "2020-07-29T08:00:15Z",
          "updatedAt": "2020-07-29T08:00:15Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "I agree with @marten-seemann. We should optimize for the primary case, which is definitely single machine/trace.",
          "createdAt": "2020-07-29T11:12:46Z",
          "updatedAt": "2020-07-29T11:12:46Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "Streaming would definitely be useful for me too. Currently, I have to use a two stage approach to solve that: stream-supporting binary log, then convert to qlog once I am sure the end is reached. And yes, all usage is single machine/trace.",
          "createdAt": "2020-07-29T18:11:00Z",
          "updatedAt": "2020-07-29T18:11:00Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "support this, would be good to see a short example of the difference between new and old formats so I can start planning",
          "createdAt": "2020-07-29T23:33:32Z",
          "updatedAt": "2020-07-29T23:33:32Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I've updated the issue with an example, PTAL. \r\n\r\nI'm highly skeptical that that type of thing would be de-serializable automatically with something like @LPardue's serde, but a girl can dream. ",
          "createdAt": "2020-07-30T08:58:37Z",
          "updatedAt": "2020-07-30T08:58:37Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "Thanks. FWIW, the current qlog format is effectively not deserializable using serde either, so nothing would be lost.\r\n\r\nedit: hmm, actually the new format might make it more straightforward to use a semi-automated deserializer",
          "createdAt": "2020-07-30T09:03:36Z",
          "updatedAt": "2020-07-30T09:05:52Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Initial support for \"newline delimited JSON\" qlog streaming is now in qvis per https://github.com/quiclog/qvis/commit/8504c0e4581b28c985f97eff701589b866bde4b9\r\n\r\nAn example draft-02 NDJSON file can be found in attachment (should load just fine in the live qvis atm).\r\nNow that I'm certain this can be done without major performance issues, I will move forward with this for qlog draft-02. \r\n\r\nIn the meantime, further feedback based on the example file is of course welcome. \r\n\r\n[newline_delimited.zip](https://github.com/quiclog/internet-drafts/files/5137476/newline_delimited.zip)\r\n\r\n",
          "createdAt": "2020-08-27T16:01:36Z",
          "updatedAt": "2020-08-27T16:01:36Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This issues should have been resolved by the choice of NDJSON as streaming format as of https://github.com/quiclog/internet-drafts/commit/f5db7cdc8cd0cf37bfe5f1b0b4c54fc56ffc5f28",
          "createdAt": "2020-09-05T16:25:57Z",
          "updatedAt": "2020-09-05T16:25:57Z"
        }
      ]
    },
    {
      "number": 110,
      "id": "MDU6SXNzdWU2Nzk4MTM1MDI=",
      "title": "push_allowed may be misleading",
      "url": "https://github.com/quicwg/qlog/issues/110",
      "state": "CLOSED",
      "author": "dtikhonov",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "The \"push_allowed\" data element is `parameters_set` event is odd in that other data elements log actual settings values while \"push_allowed\" is derived from the value of `MAX_PUSH_ID` frame.\r\n\r\nIn addition, for pushing to be allowed, a second condition is necessary:  There must be enough unidirectional stream credit.  For example, if only three unidirectional streams are allowed, it effectively means that pushing is not possible, as those will be taken by the control and the two QPACK streams.",
      "createdAt": "2020-08-16T19:41:52Z",
      "updatedAt": "2020-09-07T10:21:24Z",
      "closedAt": "2020-09-07T10:21:24Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I agree this is unclear.\r\nThe thinking was that you'd be able to see the MAX_PUSH_ID frame when that's logged as part of `frame_created` or `frame_parsed` and the `push_allowed` would be a more high-level indicator if applications don't log the frames individually (e.g., to save space).\r\n\r\nGiven this, would you advocate:\r\n1. removing `push_allowed` altogether\r\n2. properly defining `push_allowed` as meaning both MAX_PUSH_ID > 0 AND unidirectional credit at the same time\r\n3. replacing `push_allowed` with a `max_push_id` field\r\n",
          "createdAt": "2020-08-19T13:12:50Z",
          "updatedAt": "2020-08-19T13:12:50Z"
        },
        {
          "author": "dtikhonov",
          "authorAssociation": "NONE",
          "body": "Well, `MAX_PUSH_ID` is already logged, so we don't need (3).  (2) may be onerous to log because now the implementation needs to add checks in at least two places and log `push_allowed`...  Let the tool do it!\r\n\r\nThus, I vote for (1).",
          "createdAt": "2020-08-20T12:49:21Z",
          "updatedAt": "2020-08-20T12:49:21Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Was removed and explanation text added. ",
          "createdAt": "2020-09-07T10:21:24Z",
          "updatedAt": "2020-09-07T10:21:24Z"
        }
      ]
    },
    {
      "number": 111,
      "id": "MDU6SXNzdWU2Nzk4MTU5OTY=",
      "title": "data_moved describes three layers, but only two are specified",
      "url": "https://github.com/quicwg/qlog/issues/111",
      "state": "CLOSED",
      "author": "dtikhonov",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "> Used to indicate when data moves between the HTTP/3 and the transport layer (e.g., passing from H3 to QUIC stream buffers and vice versa) or between HTTP/3 and the actual user application on top (e.g., a browser engine). This helps make clear the flow of data, how long data remains in various buffers and the overheads introduced by HTTP/3's framing layer.\r\n\r\nThe paragraph above describes three layers: transport, HTTP/3, and user application.\r\n\r\nThe definition allows for only two layers:\r\n\r\n```\r\n    from?:\"application\"|\"transport\",\r\n    to?:\"application\"|\"transport\",\r\n```\r\n\r\nIn addition, the definition of \"application\" is ambiguous: it could be the application protocol (HTTP/3) or the user application.",
      "createdAt": "2020-08-16T19:58:10Z",
      "updatedAt": "2020-09-07T19:40:40Z",
      "closedAt": "2020-09-07T19:40:40Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So, the current thinking is that this is always an HTTP level event, so there is no need to specify the \"third\" layer, as it is always HTTP. \r\n\"application\" in this case will always be the user application, not the application protocol (which, I agree, is not entirely clear or obvious).\r\n\r\nGiven this explanation, would you push for:\r\n1. making this a more generic event by adding the \"third layer\" as well (not sure which category we would use for this event then though)\r\n2. re-naming \"application\" to something else here to separate it from HTTP3/application protocol more clearly\r\n3. keeping it as is but adding text to explain it more clearly\r\n",
          "createdAt": "2020-08-19T13:10:27Z",
          "updatedAt": "2020-08-19T13:10:27Z"
        },
        {
          "author": "dtikhonov",
          "authorAssociation": "NONE",
          "body": "I'd vote for (1), with the three layers being:\r\n1. transport (or QUIC);\r\n2. HTTP/3; and\r\n3. application.\r\n\r\nNote that the data may skip the HTTP/3 layer ([lsquic](https://github.com/litespeedtech/lsquic), for example, tries hard to avoid intermediate buffering) altogether, so the event should be able to describe that as well.",
          "createdAt": "2020-08-20T12:56:08Z",
          "updatedAt": "2020-08-20T12:56:08Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Could you give an example of how data can skip the H3 layer in practice? I can understand this if you're for example using raw DATAGRAM frames in QUIC that don't use the HTTP/3 DATAGRAM stuff, but the moment you're carrying H3, you still need to strip out the frame headers in the H3 layer, no? ",
          "createdAt": "2020-08-20T13:07:48Z",
          "updatedAt": "2020-08-20T13:07:48Z"
        },
        {
          "author": "dtikhonov",
          "authorAssociation": "NONE",
          "body": "Here is how reading from an HTTP/3 stream works in lsquic (in the best-case scenario):\r\n\r\n1. The packet is decrypted and the decrypted payload is stored in a new memory object.  (This is data copy number 1.)\r\n2. The packet is parsed.  This creates _STREAM_ frame marker objects.\r\n3. If, as a result of a new marker, reading from a stream becomes possible, the user is notified via an \"on stream write\" event.  Note that *in the case of HTTP/3 stream, special magic happens internally*: the stream is fast-forwarded through the framing.  _DATA_ frames are processed and discarded.  You can peek at [how it's done in the `read_data_frames()` function](https://github.com/litespeedtech/lsquic/blob/v2.19.5/src/liblsquic/lsquic_stream.c#L1360L1363).\r\n4. The user then reads data from stream using one of two ways.\r\n   - **copy read**.  In this case, `lsquic_stream_read()` or `lsquic_stream_readv()` is called and data is copied into user-supplied buffer(s).  (This is data copy number 2.)\r\n   - **zero copy**.  User can call `lsquic_stream_readf()` with a callback.  This callback will then be given a pointer to the data from the  first copy (in Step 1).  See [line 1367](https://github.com/litespeedtech/lsquic/blob/v2.19.5/src/liblsquic/lsquic_stream.c#L1367) -- this is where this callback is called.  Here, the user can copy the data or process it directly.\r\n\r\nNote that there was no copy from transport layer into any intermediate layer.  So, no, stripping out frame headers does not mean that data must be copied.",
          "createdAt": "2020-08-20T14:20:34Z",
          "updatedAt": "2020-08-20T14:20:34Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Is tied to #65 ",
          "createdAt": "2020-09-07T13:40:36Z",
          "updatedAt": "2020-09-07T13:40:36Z"
        }
      ]
    },
    {
      "number": 112,
      "id": "MDU6SXNzdWU2Nzk4MTczNTI=",
      "title": "QPACK encoder and decoder each has its own state",
      "url": "https://github.com/quicwg/qlog/issues/112",
      "state": "CLOSED",
      "author": "dtikhonov",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Each peer has two QPACK states: encoder and decoder.  `qpack`'s `state_updated` and `dynamic_table_updated` events do not make such differentiation, making the specification incomplete.  For example:\r\n\r\n> This event is emitted when one or more entries are added or evicted from QPACK's dynamic table.\r\n\r\nWhich dynamic table is meant: encoder or decoder?",
      "createdAt": "2020-08-16T20:06:37Z",
      "updatedAt": "2020-09-07T10:17:26Z",
      "closedAt": "2020-09-07T10:17:26Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Closed by adding an \"owner\" field to `dynamic_state_updated`.\r\n\r\nOther qpack events either already had this field or are split out into created/parsed or encoded/decoded events, which makes this implicit. ",
          "createdAt": "2020-09-07T10:17:26Z",
          "updatedAt": "2020-09-07T10:17:26Z"
        }
      ]
    },
    {
      "number": 113,
      "id": "MDU6SXNzdWU2Nzk4MTc2MzE=",
      "title": "QPACK: dynamic table entries are \"inserted,\" not \"added\"",
      "url": "https://github.com/quicwg/qlog/issues/113",
      "state": "OPEN",
      "author": "dtikhonov",
      "authorAssociation": "NONE",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "The draft should use the QPACK terminology.",
      "createdAt": "2020-08-16T20:08:19Z",
      "updatedAt": "2021-08-18T10:12:57Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So, I'm not entirely sure what to do here... I based myself mainly on this section, which does use \"added\"/\"evicted\": \r\nhttps://tools.ietf.org/html/draft-ietf-quic-qpack-16#section-3.2.2\r\n\r\nHowever, I agree that in other places, \"inserted\" is used for the same/similar operations. I have changed it to \"inserted\" in qlog, as I trust @dtikhonov's good judgement, but wonder if this should be made consistent in the QPACK text? \r\n\r\nSimilarly, several diagrams refer to the \"dropping point\" or \"dropped count\", which I -assume- is the same as \"evicted\" or \"eviction index\" etc. The \"dropping point\" is not mentioned in the running text anywhere in any case. Maybe that should also be made more consistent?\r\n\r\nCC'ing @afrind on this. If needed, I can make issues in the quicwg repo for this. \r\n",
          "createdAt": "2020-09-07T10:11:23Z",
          "updatedAt": "2020-09-07T10:11:23Z"
        },
        {
          "author": "dtikhonov",
          "authorAssociation": "NONE",
          "body": "You're right: \"inserted\" is used nine times in the draft, while \"added\" is used six times.  My claim that entries are only \"inserted,\" not \"added,\" may have been incorrect!",
          "createdAt": "2020-09-08T20:27:23Z",
          "updatedAt": "2020-09-08T20:27:23Z"
        }
      ]
    },
    {
      "number": 114,
      "id": "MDU6SXNzdWU2Nzk4MTgxMjA=",
      "title": "qpack.instruction_sent -- which \"sent\" time is meant?",
      "url": "https://github.com/quicwg/qlog/issues/114",
      "state": "CLOSED",
      "author": "dtikhonov",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "> This event is emitted when a QPACK instruction (both decoder and encoder) is sent.\r\n\r\nA QPACK instruction is:\r\n- written to the encoder (or decoder) stream, which is then\r\n- packetized, and\r\n- the packet (or packets!) is sent.\r\n\r\nWhich of the three events above is meant is not clear.",
      "createdAt": "2020-08-16T20:11:32Z",
      "updatedAt": "2020-09-07T10:04:05Z",
      "closedAt": "2020-09-07T10:04:05Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Resolved by renaming `instruction_sent/received` to `instruction_created/parsed`, as an analogy to the HTTP/3 `frame_created/parsed` events. \r\n\r\nThanks for noticing this @dtikhonov!",
          "createdAt": "2020-09-07T10:04:05Z",
          "updatedAt": "2020-09-07T10:04:05Z"
        }
      ]
    },
    {
      "number": 115,
      "id": "MDU6SXNzdWU2ODE4ODYxODI=",
      "title": "QPACK: check data types",
      "url": "https://github.com/quicwg/qlog/issues/115",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Commit 128f3840cf951e8032c25896683b369cb92d13e6 adds proper data type definitions (e.g., uint64 instead of just \"number\", bytes instead of \"hex string\") to the qlog event fields.\r\n\r\nThese were a bit difficult to figure out for QPACK events (with the whole \"prefixed integer\" stuff), so I've put everything at uint64 for now. While this is the \"safest\" option, elsewhere in the document I've taken the approach of choosing the smallest \"likely\" integer size for a given value. One example is the datagram_size: it's unlikely we'll see datagrams larger than uint32 in practice (you could even argue uint16?), so this field is not a uint64. Similarly, the length of a QUIC STREAM frame is also just uint32, not 64. This approach should help make binary qlog derivations more optimized. \r\n\r\nAs such, I was hoping someone with more QPACK experience could help indicate the \"minimal\" data type size for the different fields. \r\n\r\nA secondary aspect is the values logged for \"name\" and \"value\" (e.g., in InsertWithoutNameReferenceInstruction). I'm not sure if these should be readable strings (e.g., \"Content-Encoding\" or their hex/byte equivalents (e.g., \"abcde1234\"). For debugging it makes more sense if they are the readable strings, though I'm not sure it's logical to treat them that way inside a QPACK implementation. Alternative is the make the datatype for those `string | bytes` (one of both) and let the logger/tools figure it out. \r\n\r\nSo, TLDR:\r\n1. Which QPACK number-esque fields can do with less than 64 bits in practice?\r\n2. Which data type should name and value fields have in qlog? \r\n\r\nI was hoping for some input on this from maybe @dtikhonov, @lpardue, @afrind. Thanks in advance!\r\n\r\n\r\n\r\n",
      "createdAt": "2020-08-19T14:27:50Z",
      "updatedAt": "2020-09-07T10:04:54Z",
      "closedAt": "2020-09-07T10:04:53Z",
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "I don't have answers sorry, only a question. Have you considered making the name string and value string optional?",
          "createdAt": "2020-08-19T16:28:05Z",
          "updatedAt": "2020-08-19T16:28:05Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "@LPardue yes, and most already are, but it seems I missed a few. Will be fixed, thanks for reporting. ",
          "createdAt": "2020-08-19T16:34:08Z",
          "updatedAt": "2020-08-19T16:34:08Z"
        },
        {
          "author": "dtikhonov",
          "authorAssociation": "NONE",
          "body": "> Similarly, the length of a QUIC STREAM frame is also just uint32, not 64.\r\n\r\nI looked at the latest version of the draft and stream IDs in the \"qpack\" section are all uint64...",
          "createdAt": "2020-08-20T13:09:47Z",
          "updatedAt": "2020-08-20T13:09:47Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "> > Similarly, the length of a QUIC STREAM frame is also just uint32, not 64.\r\n> \r\n> I looked at the latest version of the draft and stream IDs in the \"qpack\" section are all uint64...\r\n\r\nyes, because the IDs can conceivably go higher than 32. However, the raw_length of the STREAM frame (https://quiclog.github.io/internet-drafts/draft-marx-qlog-event-definitions-quic-h3.html#name-streamframe) can never span more than just the single packet, and I assume individual packets won't be larger than 32 bits in practice. (the \"length\" field there should then probably also be uint32 instead of 64, though the offset should remain at 64). \r\n",
          "createdAt": "2020-08-20T13:18:48Z",
          "updatedAt": "2020-08-20T13:18:48Z"
        },
        {
          "author": "dtikhonov",
          "authorAssociation": "NONE",
          "body": "Oh, I see where I went wrong! :-)\r\n\r\nThe updated \"qpack\" types in the draft look OK.",
          "createdAt": "2020-08-20T13:59:24Z",
          "updatedAt": "2020-08-20T13:59:24Z"
        },
        {
          "author": "afrind",
          "authorAssociation": "NONE",
          "body": "Seems like you could probably reduce the table capacity and table size to 32 bits, as I have a hard time seeing someone reserving up to 4GB for this purpose.  That said, it is possible in the protocol, so if you want to be able to handle even the crazies I guess you have to stick to 64.  ",
          "createdAt": "2020-08-20T15:47:06Z",
          "updatedAt": "2020-08-20T15:47:06Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thanks all for the review.\r\n\r\nName and value (and their lengths) are now always optional and some uint64's have become uint32's (we do not want to encourage the crazies ;)) ",
          "createdAt": "2020-09-07T10:04:53Z",
          "updatedAt": "2020-09-07T10:04:53Z"
        }
      ]
    },
    {
      "number": 116,
      "id": "MDU6SXNzdWU2OTQ4NjY2MDE=",
      "title": "Add certificate verification events",
      "url": "https://github.com/quicwg/qlog/issues/116",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "quic-http3-fields",
        "future-versions"
      ],
      "body": "In real deployments, getting some feedback on certificate validation events is useful (e.g., these are included in NetLog).\r\n\r\nI wonder if these can be done as triggers... but on what event would those triggers be logged then? Maybe on a connection close if validation fails? What if it succeeds? \r\n\r\nAs I've seen some discussion about these things being async and sometimes depend on remote fetches (e.g., for OCSP), it would probably be useful to have separate events though. \r\n\r\nI need to get a better overview of the types of events though to decide on how to log this. Probably add something simple for draft-02 and extend in -03. ",
      "createdAt": "2020-09-07T08:37:28Z",
      "updatedAt": "2021-08-18T10:14:23Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 117,
      "id": "MDU6SXNzdWU3MDE1OTAxNTE=",
      "title": "token logging",
      "url": "https://github.com/quicwg/qlog/issues/117",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "Currently (in draft-02) tokens are logged like this:\r\n```\r\n    retry_token?:bytes, // only if header.packet_type === retry\r\n    retry_token_length?:uint32, // only if header.packet_type === retry\r\n```\r\n\r\nIt would be nice if it was possible if the server could also log tokens received on Initial packets. More interesting than the raw byte representation of a token would be the data encoded in a token. The most interesting bit is probably if the token is a Retry token or a NEW_TOKEN token. Implementations could then add more fields and fill them with data that's encoded into the token.",
      "createdAt": "2020-09-15T04:07:02Z",
      "updatedAt": "2020-11-02T19:48:52Z",
      "closedAt": "2020-11-02T19:48:52Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So, this is an absolute mess... but it's a mess in the specs as well. \r\n\r\nRetry (from the server) and stateless reset tokens are logged in the packet events directly, because they are sent in the body of their respective packet types.\r\n\r\nThen, tokens included in the initial, are logged in the PacketHeader struct (see https://quiclog.github.io/internet-drafts/draft02/draft-marx-qlog-event-definitions-quic-h3.html#name-packetheader). There is no specified way in the spec to know whether the initial token is retry or NEW_TOKEN, except for the semantics of the connection state at that time, so that's what the current setup is with qlog as well (which, I agree, is suboptimal). \r\n\r\nI -could- add a kind of `token_type?: \"retry\"|\"resumption\"` to PacketHeader I guess, but then there will be situations where implementations don't want to log that/don't have that information available at that location etc. \r\n\r\nAs for the \"what exactly is in a token\"... this is hyper implementation-specific, so you couldn't make interoperable tools for that anyway. I considered adding a generic `token_contents:any` field, but given the above I'd have to repeat that for the `retry_token` and PacketHeader:token separately, which is again... a mess. So I'm really not sure about the cleanest solution. \r\n\r\nAs explained in https://github.com/quiclog/internet-drafts/issues/94, I was planning on keeping this floating for -02 and probably moving to separate token-based events in -03 to make this cleaner. \r\n",
          "createdAt": "2020-09-15T09:27:58Z",
          "updatedAt": "2020-09-15T09:27:58Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "> Then, tokens included in the initial, are logged in the PacketHeader struct (see https://quiclog.github.io/internet-drafts/draft02/draft-marx-qlog-event-definitions-quic-h3.html#name-packetheader). There is no specified way in the spec to know whether the initial token is retry or NEW_TOKEN, except for the semantics of the connection state at that time, so that's what the current setup is with qlog as well (which, I agree, is suboptimal).\r\n\r\nThat's not true. An implementation MUST be able to distinguish between them, see https://quicwg.org/base-drafts/draft-ietf-quic-transport.html#name-token-construction:\r\n> A token sent in a NEW_TOKEN frames or a Retry packet MUST be constructed in a way that allows the server to identify how it was provided to a client. These tokens are carried in the same field, but require different handling from servers.\r\n\r\n> As for the \"what exactly is in a token\"... this is hyper implementation-specific, so you couldn't make interoperable tools for that anyway.\r\n\r\nIn principle, yes, although the spec imposes a few restrictions:\r\n> Tokens sent in NEW_TOKEN frames MUST include information that allows the server to verify that the client IP address has not changed from when the token was issued.\r\n\r\nand\r\n> Servers SHOULD ensure that tokens sent in Retry packets are only accepted for a short time. \r\n\r\nVery likely, implementations will save the creation time and the peer's remote address into the token.",
          "createdAt": "2020-09-15T09:45:03Z",
          "updatedAt": "2020-09-15T09:45:14Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Fixed for draft-02 by extracting out a separate Token class. Open to revisiting this for draft-03. ",
          "createdAt": "2020-11-02T19:48:52Z",
          "updatedAt": "2020-11-02T19:48:52Z"
        }
      ]
    },
    {
      "number": 118,
      "id": "MDU6SXNzdWU3MTU0Mjg2Njk=",
      "title": "key update logging",
      "url": "https://github.com/quicwg/qlog/issues/118",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "The spec is not clear on when to log key updates. I'm trying to debug a failure of the key update interop runner test case, and qlog just doesn't give me enough information what's going on.\r\nThe main problem is that there's no `key phase` information available on the `PacketHeader`.\r\n\r\n* During the handshake (all keys with trigger `tls`), it's most useful to log when a new key becomes available, as it allows you to see why packets might end up as undecryptable.\r\n* Key updates for 1-RTT keys are more tricky: For a locally initiated key update, it's only clear how to log the send key. You do compute the receive key at the same point, but you don't use it until the client has acted upon the key update.\r\n\r\nI think the following would be the easiest:\r\n\r\n1. Add a `key_phase` field on the `PacketHeader`. This is the key phase `N`, not the key phase bit. The receiver will know the full key phase value after successfully decrypting a packet. For undecryptable packets, there should be a `key_phase_bit` field.\r\n2. Split the `key_updated` event: The event in its current form makes a lot of sense for TLS-initiated updates. For 1-RTT key updates, there's no need to distinguish between the `server_1rtt_secret` and the `client_1rtt_secret`.",
      "createdAt": "2020-10-06T07:43:28Z",
      "updatedAt": "2020-10-31T13:58:10Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Related to #52 ",
          "createdAt": "2020-10-31T13:58:09Z",
          "updatedAt": "2020-10-31T13:58:09Z"
        }
      ]
    },
    {
      "number": 119,
      "id": "MDU6SXNzdWU3MzM3MjQxNjQ=",
      "title": "Make initiator clear in connection_started",
      "url": "https://github.com/quicwg/qlog/issues/119",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version",
        "privacy"
      ],
      "body": "Currently, `connection_started` utilizes `src_ip` and `dst_ip` (and equivalent for ports), where the intended meaning is that src means the initiator (typically client) and dst the server. \r\n\r\nHowever, this is a) unclear and b) it does not allow deducing what the \"local\" ip is for where this trace was captured without correlating client/server with the vantagepoint (and if that vantagepoint is network, it becomes more murky). \r\n\r\nSome options for solving:\r\n1. rename fields to `local_ip` and `remote_ip`  \r\n2. add `initiator` field (e.g., with values 'local' and 'peer')\r\n3. completely revise how we log paths/IPs and potentially decouple from `connection_started` (also good in terms of privacy, migration, multipath, ...). \r\n\r\nOption 3 is probably best, should revisit when properly fixing migration in qlog (see also #79 and #57)\r\n\r\ncc @marten-seemann \r\n",
      "createdAt": "2020-10-31T13:47:19Z",
      "updatedAt": "2021-08-18T10:15:42Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 120,
      "id": "MDU6SXNzdWU3MzQ1ODAxNDQ=",
      "title": "Allow logging of TLS internals",
      "url": "https://github.com/quicwg/qlog/issues/120",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "future-versions"
      ],
      "body": "Depending on some TLS parameters, things might behave strangely on a QUIC level.\r\n\r\nFor example, TLS key shares can apparently use different \"group types\", e.g., p-256 or x25519 (this is somehow separate from the cipher it uses... I really need to brush up on my TLS understanding). The client chooses one of the groups that it thinks the server will support. If it doesn't the server will send an initial back, to which the client replies with another ClientHello using the correct group type, leading to a 2RTT QUIC handshake instead of 1RTT. An example can be seen in https://quic-tracker.info.ucl.ac.be/traces/20201101/2 (or if that's not longer available, a quic-tracker to mvfst connection setup, which seems to do this consistently).\r\n\r\nThis example above has already caught two separate researchers by surprise, and it should really be possible to expose this in qlog for easier debugging. \r\n\r\nIn general, I think we can do with providing more options for logging TLS-level information, but for that I first need to understand the variables better (or find someone to propose the concrete things to surface in qlog for that). ",
      "createdAt": "2020-11-02T15:05:32Z",
      "updatedAt": "2020-11-02T15:07:02Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 121,
      "id": "MDU6SXNzdWU3MzQ5MDEwNDI=",
      "title": "Allow the logging of Session Ticket contents and stored transport params/SETTINGS",
      "url": "https://github.com/quicwg/qlog/issues/121",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "Currently, we can log which params/settings were restored upon attempting 0-RTT, but not which ones were actually stored at the end of a connection (though we might assume it were the correct ones, using the values from `parameters_set`).\r\n\r\nFor a server which encodes this information in for example the SessionTicket, we also cannot log which values are in the ticket when sending it, nor when receiving it, nor if early data was denied because of a mismatch therein. ",
      "createdAt": "2020-11-02T23:14:15Z",
      "updatedAt": "2021-10-04T14:07:08Z",
      "closedAt": null,
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": ">  (though we might assume it were the correct ones, using the values from parameters_set)\r\n\r\nThe client might also save the RTT (and RTT variance maybe?), which would not be a QUIC transport parameter.\r\n\r\n> For a server which encodes this information in for example the SessionTicket, we also cannot log which values are in the ticket when sending it\r\n\r\nI think _all_ servers would encode this in the SessionTicket, but maybe we should be flexible enough to allow for other options?\r\n\r\nThe way we could do this is by introducing a `parameters_saved` and a `parameters_restored` event, which allows to encode both QUIC transport parameters and other values. We might also add a `dest` / `src` field, so we can specify where those values were saved (in the session ticket / to disk / etc.).",
          "createdAt": "2021-10-04T14:07:08Z",
          "updatedAt": "2021-10-04T14:07:08Z"
        }
      ]
    },
    {
      "number": 122,
      "id": "MDU6SXNzdWU3MzQ5ODg0NjA=",
      "title": "the new Token is confusing",
      "url": "https://github.com/quicwg/qlog/issues/122",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "The `Token` introduced in https://github.com/quiclog/internet-drafts/commit/60690f4033624006b5bbac8797e69b8a78331ce3 doesn't make sense to me. I don't see the motivation for bundling stateless resets and Retry tokens into the same struct (other than incidentally, the spec calls them tokens).\r\n\r\nStateless reset tokens are by definition random values (or rather, a deterministic pseudorandom value derived from the connection ID). They are always 16 bytes and never contain any other information.\r\n\r\nOn the other hand, the token sent on the Initial can be a Retry token or a NEW_TOKEN token (I guess that's what a resumption token is). This token typically does contain additional information encoded into the value (in fact, as I've described in https://github.com/quiclog/internet-drafts/issues/117#issuecomment-692603028, the spec mandates that you encode a bunch of values into that token). I would have wished that at least those mandatory fields are clearly defined in the `Token`.",
      "createdAt": "2020-11-03T03:30:41Z",
      "updatedAt": "2021-08-18T10:17:27Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "From a discussion on Slack, @marten-seemann is in favor of splitting stateless reset tokens from the Token class and logging them as a `stateless_reset_token?:bytes` (which is the approach we had before and works well because the reset token is always 128 bits in length).\r\n\r\nWrt to specifying detail fields, from what I can gather there are two main ones:\r\n- `remote_address?:IPAddress` for a NEW_TOKEN \r\n- `timeout?:uint32` for a retry token\r\n\r\nAre there others that would benefit from being specified explicitly? ",
          "createdAt": "2020-11-03T11:06:25Z",
          "updatedAt": "2020-11-03T11:06:25Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I think most implementations encode the timestamp (and not the timeout) when the token was generated into the token, so they can decide if they want to accept a token based on current conditions.",
          "createdAt": "2020-11-03T12:28:03Z",
          "updatedAt": "2020-11-03T12:28:03Z"
        }
      ]
    },
    {
      "number": 124,
      "id": "MDU6SXNzdWU3NDY3MjcwMTU=",
      "title": "Add support for QUIC DATAGRAM and HTTP/3 DATAGRAM frames",
      "url": "https://github.com/quicwg/qlog/issues/124",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "future-versions"
      ],
      "body": "[QUIC DATAGRAM spec](https://tools.ietf.org/html/draft-ietf-quic-datagram-01)\r\n\r\n[HTTP/3 DATAGRAM spec ](https://tools.ietf.org/html/draft-schinazi-quic-h3-datagram-05)\r\n\r\nAn interesting point was made about this by @lpardue, in that these frames are almost identical, with the H3 layer just adding a flow_id. \r\nFor this, their implementation somewhat abstracts away the difference between these two, and their H3 code doesn't really have the concept of a DATAGRAM frame. \r\nFor this, it would be interesting to have the flow_id field defined on the QUIC-level DATAGRAM as well, not just the HTTP/3 frame. \r\n\r\nTo me, this feels a bit dirty, qlog not mirroring the specs to make implementation/logging easier. Still, it's something to consider.\r\n\r\nAn alternative is to implement this purely in the tooling. For example, qvis could just look for a flow_id field on the QUIC DATAGRAM frame, even though it's not defined in qlog proper. Alternatively, it could parse raw.data and extract the flow-id from that (which is worse...). \r\n\r\nThis raises an overall point about the robustness of the tooling and whether we should mention something like this in the qlog texts. ",
      "createdAt": "2020-11-19T16:19:40Z",
      "updatedAt": "2021-08-18T10:18:23Z",
      "closedAt": null,
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "I think there is a place for the H3 DATAGRAM frame qlog object. The quiche implementation, at present, only provides transport layer logging but it would be logical to log an H3 layer frame if we supported it.\r\n\r\nWith what quiche has today, I would not implement flow_id logging for transport DATAGRAM. That would require me to do some layering violation and means the generic transport code suddenly becomes application aware. Its unfair to ask someone else to do the same violation I'm not willing to do and they might well reject it just as I have done. But implementations often have different incentives \ud83d\ude00",
          "createdAt": "2020-11-19T16:53:02Z",
          "updatedAt": "2020-11-19T16:53:02Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "There is some overlap here with discussion in the draft repo about whether a flow-id should go in the transport. One comment there described a TAPS concept where interface boundaries can accept a function that can be executed on behalf of the caller. Qvis could for instance by default just plot all datagrams as 1 \"series\", or plot multiple \"series\" based on a user supplied transform function such as varint(dgram_frame.bytes[])",
          "createdAt": "2020-11-19T16:59:52Z",
          "updatedAt": "2020-11-19T16:59:52Z"
        }
      ]
    },
    {
      "number": 126,
      "id": "MDU6SXNzdWU3NTg5NjU5NTg=",
      "title": "QuicFrame length and payload_length",
      "url": "https://github.com/quicwg/qlog/issues/126",
      "state": "OPEN",
      "author": "kixelated",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [
        "current-version"
      ],
      "body": "I recently implemented draft 2 and was very confused about the these two fields, found in some of the QuicFrame classes.\r\n\r\n1. What does it mean when a frame has both `payload_length` and `length` (total frame size)? \r\nex. `PaddingFrame`, `PingFrame`, `AckFrame`, `ResetStreamFrame`, `StopSendingFrame`\r\n\r\nDoes `length` include the frame type while `payload_length` is the rest? That doesn't seem true for `PingFrame` and `PaddingFrame`, as `payload_length` == `length`. Also the frame type [must use the minimum size](https://www.ietf.org/archive/id/draft-ietf-quic-transport-32.html#section-12.4-16), so they're just going to be off by 1. Or does `payload_length` measure something else?\r\n\r\n\r\n====\r\n\r\n2. What about frames with both `payload_length` and `length` (not total frame size)?\r\nex. `CryptoFrame`, `StreamFrame`\r\n\r\nDo I need to make an exception for these frames? Is `payload_length` the aforementioned total length - 1, or is it the length of the STREAM/CRYPTO data? \r\n\r\nThe RFC says: > payload_length: length of the packet/frame payload, excluding AEAD tag. For many control frames, this will have a value of zero\r\n\r\nThat implies that `payload_length == length` for these frames, and `payload_length == 0` for every other type of frame???\r\n\r\n====\r\n\r\n3. What about frames with no `length` or `payload_length`?\r\nex. `NewTokenFrame`, `MaxDataFrame`, `MaxStreamDataFrame`, `MaxStreamsFrame`, ... \r\n\r\nIs there no way to measure the size or these frames? The length of most of them don't matter, although you can make the same argument for `ResetStreamFrame` and `StopSendingFrame`. It seems like somebody got distracted while going down the list.\r\n\r\n====\r\n\r\n4. What about classes with `raw_length`?\r\nex. `UnknownFrame`\r\n\r\nSeems inconsistent!",
      "createdAt": "2020-12-08T00:50:13Z",
      "updatedAt": "2020-12-20T10:12:23Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Hello Luke,\r\n\r\nThanks for opening this issue, because you're correct that there are some problems with this, as the design for how to do this has changed over time and there seem to be some leftovers/oversights. The person who \"got distracted going down the list\" was me ;) \r\n\r\nThe (currently) intended approach is to log actual lengths and payload lengths as part of an optional \"raw\" field, as described in https://tools.ietf.org/html/draft-marx-qlog-event-definitions-quic-h3-02#section-4.1. This is because many implementations won't log this info and it's only really useful for doing packetization analysis, which you don't always need, so it makes sense to split this up a bit. \r\n\r\nAs such, the `payload_length` and `length` fields on PingFrame, AckFrame, ResetStreamFrame, and StopSendingFrame and the `payload_length` field on PaddingFrame and CryptoFrame **should be removed and instead `raw.payload_length` and `raw.length` should be used**. \r\n\r\nThe `length` fields on Crypto and Stream remain and reflect the fields as defined in the QUIC docs, to make it easier to map them to qlog (this means that frame.length will be the same as raw.payload_length, but so be it...)\r\n\r\n_I'm not sure what to do with PaddingFrame. It doesn't have a length in the spec, but that would be useful to have in qlog. You could say implementations should then just log `raw.payload_length`, but not everyone has that type of flexible stack where that's easy to do if you don't log the `raw` field everywhere, so I'm in favor of keeping `length` on PaddingFrame as well._\r\n\r\nFinally, for UnknownFrame, `raw_length` and `raw` should also be changed to just use the generic `raw` field. \r\n\r\nKeeping this open to tackle for draft-03. Feel free to open a PR, otherwise I'll make the fixes over time. \r\n\r\n---\r\n\r\nAs I said in the other issue you opened in qvis, it's great to have this type of feedback. It can be tough keeping every detail consistent in this type of document and I find I tend to overlook things like this. If you find anything else that seems strange, don't hesitate to open an issue. \r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2020-12-08T10:57:11Z",
          "updatedAt": "2020-12-08T10:57:11Z"
        },
        {
          "author": "ptrd",
          "authorAssociation": "NONE",
          "body": "My 2 cents:\r\n- IMHO Padding should contain a length field (in kwik i do the same optimisation of combining padding bytes into one frame; i guess more people are doing so ;-))\r\n- for frames, having both length and payload_length wouldn't be very useful, would it? One can easily computed from the other (where \"easily\" is even an understatement ;-))",
          "createdAt": "2020-12-20T10:12:23Z",
          "updatedAt": "2020-12-20T10:12:23Z"
        }
      ]
    },
    {
      "number": 127,
      "id": "MDU6SXNzdWU3ODA3NDYzNTg=",
      "title": "Properly add double quotes for JSON keys as well",
      "url": "https://github.com/quicwg/qlog/issues/127",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "I've been lazy and didn't add double quotes for JSON keys, just for string field values.\r\nFor a more formal version, this should be changed. ",
      "createdAt": "2021-01-06T18:05:52Z",
      "updatedAt": "2021-08-18T10:19:27Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 128,
      "id": "MDU6SXNzdWU3ODExNzcyOTM=",
      "title": "Remove implementation detail from PacketType enum",
      "url": "https://github.com/quicwg/qlog/issues/128",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "At the moment, the PacketType enum has `onertt = \"1RTT\"` (and similar for 0RTT) because in most programming languages, enum keys cannot start with numerical characters. This has however led to some confusion in some cases, so it's probably best to leave out this implementation detail in the spec.\r\n\r\nSee also https://github.com/p-quic/pquic/issues/18#issuecomment-756005163",
      "createdAt": "2021-01-07T09:44:36Z",
      "updatedAt": "2021-10-06T09:53:51Z",
      "closedAt": "2021-10-06T09:53:51Z",
      "comments": [
        {
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "body": "@rmarx are you recommending just an editorial change to remove `= \"1RTT\"` and `= \"0RTT\"` or do you have something else in mind? \r\n\r\nI would see no issue in just using zerortt and onertt. Another option would be to add a prefix so that the first character is not a number, e.g. \r\n\r\n```\r\nenum PacketType {\r\n    initial,\r\n    handshake,\r\n    _0rtt,\r\n    _1rtt,\r\n    retry,\r\n    version_negotiation,\r\n    stateless_reset,\r\n    unknown\r\n}\r\n```\r\n",
          "createdAt": "2021-09-16T06:36:29Z",
          "updatedAt": "2021-09-16T06:36:29Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "It would indeed just be an editorial change, but to be backwards compatible with existing qlog implementations, we shouldn't do `onertt` and `zerortt` but just 1RTT and 0RTT (as those are the actual serializations used atm).\r\n\r\nThe point here is that I feel we don't need to take into account the fact that most programming languages don't allow numericals as the first character in an enum; that should be an implementation detail.\r\n\r\nSo I'd propose:\r\n```\r\nenum PacketType {\r\n    initial,\r\n    handshake,\r\n    0RTT,\r\n    1RTT,\r\n    retry,\r\n    version_negotiation,\r\n    stateless_reset,\r\n    unknown\r\n}\r\n``\r\n",
          "createdAt": "2021-09-16T09:51:03Z",
          "updatedAt": "2021-09-16T09:51:03Z"
        }
      ]
    },
    {
      "number": 129,
      "id": "MDU6SXNzdWU3ODE3NDY3NTk=",
      "title": "TransportError",
      "url": "https://github.com/quicwg/qlog/issues/129",
      "state": "OPEN",
      "author": "kazu-yamamoto",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [
        "editorial",
        "quic-http3-fields",
        "current-version"
      ],
      "body": " A.7.22.  `TransportError` should catch up the latest transport draft. Probably four errors are missing.",
      "createdAt": "2021-01-08T00:34:45Z",
      "updatedAt": "2021-08-18T10:21:05Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 130,
      "id": "MDU6SXNzdWU3ODc2NjEzODk=",
      "title": "Formal definition of CommonFields seems to be missing",
      "url": "https://github.com/quicwg/qlog/issues/130",
      "state": "CLOSED",
      "author": "ptrd",
      "authorAssociation": "NONE",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "high-level-schema",
        "current-version"
      ],
      "body": "Section https://tools.ietf.org/html/draft-marx-qlog-main-schema-02#section-3.3 defines class Trace that has a field\r\n`common_fields?: CommonFields`, \r\nhowever, the class CommonFields is not defined in the document.",
      "createdAt": "2021-01-17T08:50:09Z",
      "updatedAt": "2021-11-04T11:19:17Z",
      "closedAt": "2021-11-04T11:19:16Z",
      "comments": [
        {
          "author": "ptrd",
          "authorAssociation": "NONE",
          "body": "Hmm, 3.4.8 defines it. I missed it because i did a text search on \"CommonFields\", which occurs only once in the text.\r\nEven though it is defined as a dictionary that can contains anything, personally, i would still like to see a class definition of CommonFields in the text. This could at least define the 4 default fields.",
          "createdAt": "2021-01-17T08:56:34Z",
          "updatedAt": "2021-01-17T08:56:34Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This should now be fixed in the latest draft, at the bottom of the Section: https://datatracker.ietf.org/doc/html/draft-ietf-quic-qlog-main-schema-01#section-3.4.7.",
          "createdAt": "2021-11-04T11:19:16Z",
          "updatedAt": "2021-11-04T11:19:16Z"
        }
      ]
    },
    {
      "number": 131,
      "id": "MDU6SXNzdWU3ODc2Njc0NTk=",
      "title": "Improve definition of event and data",
      "url": "https://github.com/quicwg/qlog/issues/131",
      "state": "OPEN",
      "author": "ptrd",
      "authorAssociation": "NONE",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "As discussed on Slack, i find definition of event and data object a bit confusing. \r\nSome suggestions for improvement:\r\n- https://tools.ietf.org/html/draft-marx-qlog-main-schema-02#section-3.4.3: TransportPacketSentEvent is not an event in the terminology of this document, but an example of data object; as such, i'd suggest to name it TransportPacketSentData\r\n- it would help if the data serialization example in the same section would also show how the data object fits into the event (i.e. include the event in the example)\r\n- https://tools.ietf.org/html/draft-marx-qlog-event-definitions-quic-h3-02#section-5: i'd suggest to also mention each subsubheading / event-type will define the data class that is referred to in main-schema\r\n- why not use the more formal way of defining a data class used in the main-schema document (e.g. class TransportPacketSentData) in stead of the informal \"Data\" label this is now used in quic-schema? The latter confuses me, because it makes me wonder how it fits in the formal definition of event. Also, it would be helpful as one can find the QUIC example in main-schema (TransportPacketSentEvent) in the QUIC-document; currently this example cannot be found in the quic-doc, which is a bit confusing also as it states the example is taken from QUIC ;-)\r\n- the definition (example) of TransportPacketSentEvent in main-schema does not match the definition in quic-doc  section 3.5.3; either make them equal or add a note in the main-schema document that it is only partial.",
      "createdAt": "2021-01-17T09:33:04Z",
      "updatedAt": "2021-08-18T10:22:30Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 132,
      "id": "MDU6SXNzdWU3OTAxNTM0NTY=",
      "title": "Add events to explicitly indicate send blocking",
      "url": "https://github.com/quicwg/qlog/issues/132",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "msquic has separate events that indicate if the sender was blocked/delayed/idle and due to which cause (e.g., pacing, flow control limited, cwnd limited, etc.).\r\n\r\nThis is quite useful for debugging. While some of this can be deduced from looking at other existing qlog events, adding some more explicit events for this could be interesting. \r\n\r\n@nibanks: maybe you could give some pointers/links to where these events are defined for msquic for reference? \r\n\r\ncc @lpardue",
      "createdAt": "2021-01-20T16:56:04Z",
      "updatedAt": "2021-08-18T10:08:16Z",
      "closedAt": null,
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "As far as I could intuit, MS had events for blocked and unblocked. \r\n\r\nThis seemed to be an application/  implementation event, rather than something strictly transport related. So I wonder what type of category it would fit into.",
          "createdAt": "2021-01-20T17:00:15Z",
          "updatedAt": "2021-01-20T17:00:15Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "https://github.com/microsoft/msquic/blob/main/src/inc/quic_trace.h#L44\r\n```C\r\ntypedef enum QUIC_FLOW_BLOCK_REASON {\r\n    QUIC_FLOW_BLOCKED_SCHEDULING            = 0x01,\r\n    QUIC_FLOW_BLOCKED_PACING                = 0x02,\r\n    QUIC_FLOW_BLOCKED_AMPLIFICATION_PROT    = 0x04,\r\n    QUIC_FLOW_BLOCKED_CONGESTION_CONTROL    = 0x08,\r\n    QUIC_FLOW_BLOCKED_CONN_FLOW_CONTROL     = 0x10,\r\n    QUIC_FLOW_BLOCKED_STREAM_ID_FLOW_CONTROL= 0x20,\r\n    QUIC_FLOW_BLOCKED_STREAM_FLOW_CONTROL   = 0x40,\r\n    QUIC_FLOW_BLOCKED_APP                   = 0x80\r\n} QUIC_FLOW_BLOCK_REASON;\r\n```\r\nThe lack of any flags means it's unblocked.",
          "createdAt": "2021-01-20T17:00:52Z",
          "updatedAt": "2021-01-20T17:00:52Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "And the connection has a set of flags, as well as each stream has its own set.",
          "createdAt": "2021-01-20T17:01:43Z",
          "updatedAt": "2021-01-20T17:01:43Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "I guess my intuit was a bit off \ud83d\ude1c",
          "createdAt": "2021-01-20T17:01:43Z",
          "updatedAt": "2021-01-20T17:01:43Z"
        }
      ]
    },
    {
      "number": 133,
      "id": "MDU6SXNzdWU3OTUwODc3OTM=",
      "title": "Clarify that Retry, VNEG, and Stateless Reset packets don't have packet numbers",
      "url": "https://github.com/quicwg/qlog/issues/133",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "With draft-02, we moved packet_number to PacketHeader and used that field for all types of packets as well. \r\nHowever, packet_number is currently a required field, but Retry, Version Negotiation and Stateless Reset packets don't actually use packet numbers.\r\n\r\nI don't want to just make the packet_number field generally optional, since imo it shouldn't be for other packet types. Better (best?) solution is to add an explicit comment indicating the field MUST be omitted for the 3 exceptions and MUST be included for all others. ",
      "createdAt": "2021-01-27T13:10:01Z",
      "updatedAt": "2021-08-18T10:22:55Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 134,
      "id": "MDU6SXNzdWU3OTUwOTU4NTU=",
      "title": "Multipath support",
      "url": "https://github.com/quicwg/qlog/issues/134",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "quic-http3-fields",
        "future-versions"
      ],
      "body": "With the multipath conversation gaining traction in the QUIC wg, it's time to start thinking more seriously about adding (rough) multipath support to qlog and qvis to aid practical implementation efforts (e.g., see https://huitema.wordpress.com/2021/01/26/implementing-multipath-in-quic).\r\n\r\nThe simplest approach that I can see would be to associate a `path_id` with each qlog event:\r\n\r\n```\r\nEvent definition without multipath:\r\nclass Event {\r\n    time: number,\r\n    name:string,\r\n    data:any\r\n}\r\n\r\nEvent definition with multipath:\r\nclass Event {\r\n    time:number,\r\n    name:string,\r\n    path_id:number | string,\r\n    data:any\r\n}\r\n```\r\n\r\nThis would allow users to log all events belonging to a single \"connection\" to differentiate per-path events without having to split them up in separate qlog Trace objects. Additionally, it prevents from having to overload the existing `group_id` field with an additional meaning.\r\n\r\nHowever, the main problem I can see is that the `path_id` (which can be anything, preferably an opaque/obscured value) is not available everywhere in the code that wants to output a qlog event. For example, a congestion controller will wish to output the `recovery:metrics_updated` event, but might not necessarily have the `path_id` available in the code path where these metrics are calculated/available (e.g., if a congestion control method is re-used as-is between single-path and multi-path QUIC). Similar concerns exist for other events (e.g., ACK processing or event `packet_sent` if this is logged before the packet scheduler decides which path to take). \r\n\r\nWhile there are of course always solutions to this (e.g., pass the path_id as extra parameter/as global variable/put it on a stack/put it on a logging object reference/etc.) it is at this time unclear if this is an actual problem and if implementers would wish to add these patchwork \"solutions\" if required, just to get proper qlog output.\r\n\r\nCC @huitema @mpiraux\r\n\r\n\r\n",
      "createdAt": "2021-01-27T13:20:50Z",
      "updatedAt": "2021-08-18T10:23:23Z",
      "closedAt": null,
      "comments": [
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "I will try implement that and give you feedback. I think this is natural for QUIC level events, not so much for application level events.",
          "createdAt": "2021-01-27T20:25:29Z",
          "updatedAt": "2021-01-27T20:25:29Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Excellent! Having implementation experience will help here, while example output traces will help get something into qvis. \r\n\r\nThe `path_id` would indeed only be for transport-layer events. For application-layer events, I was thinking to either omit the `path_id` (and specify that events without path_id should be considered cross-path/valid for all paths/...) or give a special `path_id` value (e.g., \"app\"), though omitting it seems cleanest and most optimized. ",
          "createdAt": "2021-01-28T10:53:35Z",
          "updatedAt": "2021-01-28T10:53:35Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "I am finding a first difficulty: how does one define the path identifier? The uniflo ID in draft-deconinck and the DCID sequence number in draft-liu have very similar properties: they define flows in only one direction. But the numbers derived from the DCID are place holders. The \"actual path\" is defined by the addresses and ports from and to which packets are sent. The DCID maps to that when it is present, but what if is not? Today, a popular setup is for clients (but not servers) to use NULL connection IDs -- this minimizes overhead in the server-to-client direction. The solution that I presented in draft-huitema allows that; my implementation of draft-liu also allows it. But if there is no DCID in the packets sent from server to client, how shall I define the path-id?\r\n\r\nFor picoquic, I could use the DCID ID sequence number when the DCID is present, and an arbitrary \"path number\" when it is not. But doing that will not result in a good log, because if the choice is arbitrary the path-id in the client log may not match the path-id in the server log. We do want to be able to match events from client and server log, so we have to do something better. My take is the following:\r\n\r\n* If the DCID is present, use the number associated with it.\r\n* If the DCID is NULL, check whether there is a CID used in the reverse direction. If it is present, use the number associated with that CID.\r\n* If the DCID is NULL in both direction, use the number 0.\r\n\r\nNote that if solutions allow the use of NULL DCID, they will need to somehow provide a way to identify the paths -- if only because they need to ask the peer to \"abandon path X\" when they loose connectivity on that path, and they need an identifier for that. It is just that the proposals are not quite mature enough...\r\n\r\n ",
          "createdAt": "2021-01-29T00:40:40Z",
          "updatedAt": "2021-01-29T00:40:40Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "That is some very useful feedback! \r\n\r\nI hadn't considered that we need to define a way to choose the `path_id` to make it possible to sync up client and server-side traces purely on `path_id`... I think your proposal makes sense, though we would have to specify concretely how to derive the `path_id` \"number\" from the connection ID (i.e., simply taking the first/last 8 bits or similar is simple enough, but might not be optimal considering privacy down the line (e.g., in setups where you don't even want to log the real CIDs)). \r\n\r\nAn alternative approach would be to shift the client/server path correlation to the tools themselves (i.e., have them use knowledge about the Multipath extension and IP+port info to link `path_id`s), but that has similar privacy issues...\r\n\r\nIt seems like the final solution would indeed depend on the chosen Multipath design (e.g., if that always requires a DCID + seq nr or Uniflow ID, we can just use that). For now, we can probably make due with a simpler scheme like the one you propose to get implementation experience. \r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2021-01-29T16:15:45Z",
          "updatedAt": "2021-01-29T16:15:45Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "Personally, I'd add a PathCreated event, that defines an arbitrary ID and all the parameters necessary to describe it. You might also want a PathUpdated event if you need to modify any of those parameters before the PathDestroyed event. For all other events that must represent \"the path\" they merely use the arbitrary ID.\r\n\r\nWe generally try to use this model for all event logging in MsQuic, though, much of the time, we use the object * for the ID for additional usefulness when live debugging.",
          "createdAt": "2021-01-29T16:42:52Z",
          "updatedAt": "2021-01-29T16:43:16Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "@nibanks with arbitrary identifiers, how do you reconcile client log and server log?",
          "createdAt": "2021-01-29T16:45:39Z",
          "updatedAt": "2021-01-29T16:45:39Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "You obviously cannot just use the ID value. You must search for two paths with the same parameters and associate those path objects.",
          "createdAt": "2021-01-29T16:46:39Z",
          "updatedAt": "2021-01-29T16:46:39Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "That seems tantamount to the second option I described @nibanks, but the question then becomes: what are those parameters? IIUC those would mainly be IP+port info, which is not something a privacy-aware endpoint would want to include in their qlogs. ",
          "createdAt": "2021-01-29T16:50:07Z",
          "updatedAt": "2021-01-29T16:50:07Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "If you're warry of PII, you simply include a hash of the information. Then your parser must understand both raw data format and hash format. If one side includes raw and the other a hash, then the parser converts raw to hash and does the comparison.",
          "createdAt": "2021-01-29T16:56:43Z",
          "updatedAt": "2021-01-29T16:56:43Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So that is a more general question I'm struggling with wrt qlog privacy and whether hashing is enough. Conceptually, if the attacker is looking for a specific (set of) IP(s) or users, and the hashing function is known (which it has to be to correlate independent client-server logs), they could still derive if a trace was for a given IP/user or not by generating hashes for all IPs/users under consideration. \r\n\r\nI'm not at all sure if that's an actual concern in practice or even something that can be worked around (I need to do more reading on data anonymization). It's also a bit esoteric, as you'd only need to use that type of hashing if you know you want to cross-correlate logs (which you probably don't want to do in production?), otherwise you can just use internal opaque IDs. But that's a potential issue here imo, and one that could require a rework of the mechanism should we choose the hashing approach now and it is deemed too \"dangerous\" later. \r\n\r\nAs I've said however, for now to allow us to make progress, I have no qualms choosing this type of approach to get experience. I also feel some generic path-related events are needed (e.g., path_created, path_updated, path_removed etc.) besides just the `path_id`. ",
          "createdAt": "2021-01-29T17:18:20Z",
          "updatedAt": "2021-01-29T17:18:20Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "First off, I think the notion of privacy should be a separate Issue and not discussed here. Still, I don't think you're going to be able to completely solve this without exchanging a completely arbitrary value on the wire. If you want two independent parties to log the same thing, they have to agree on a mechanism to turn PII_DATA -> ANONYMIZED_DATA. So you have to standardize a mechanism to do that. If it's standardized then anyone who knows of a particular PII_DATA can convert it as well. The best you can do is have the method be key based, but that only helps if 1) both the client and server know the key and 2) the person you want to view the logs but not be able to correlate **not** know the key. I'm not sure how you'd achieve that.",
          "createdAt": "2021-01-29T17:23:36Z",
          "updatedAt": "2021-01-29T17:23:36Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "Yes, the tools could rely on addresses and ports to match paths. But in the presence of NAT the values changes. You end up requiring heuristics.\r\n\r\nAs for going to anonymized data, there is a whole body of literature on the subject, and it is not easy to be both anonymous and useful. Plus there is an interesting problem of comparing hashes after NAT.",
          "createdAt": "2021-01-29T18:00:34Z",
          "updatedAt": "2021-01-29T18:00:34Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "Another question regarding default values. What happens if there is path_id specified for some events, but not for others?\r\n\r\nAsking that because I would like to not include a path_id in the qlog files if not using multipath. My preference would be using a default \"path_id = 0\" when the element is absent.",
          "createdAt": "2021-01-30T06:53:47Z",
          "updatedAt": "2021-01-30T06:53:47Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "As I mentioned above (https://github.com/quiclog/internet-drafts/issues/134#issuecomment-768970236), I indeed feel you should be able to omit `path_id` on events that do not require it and that a single trace can perfectly contain events with and without `path_id` set. \r\n\r\nI don't fully agree with the semantics of making an omission imply a default path_id value though, as e.g., HTTP/3 events will probably always lack a `path_id` as they belong to \"all paths\" concurrently. \r\n\r\nPut differently: there is a (subtle) difference between \"omission = default value\" and \"omission = belongs to all paths\", and I'd prefer the latter. This also holds up in the non-multipath case.",
          "createdAt": "2021-01-30T10:40:33Z",
          "updatedAt": "2021-01-30T10:40:33Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "I have a bit of a situational argument. I have logging tests that simulate a connection, generate a log, and compare the log to the reference value. As I am implementing multipath log, I am running these monopaths tests and verifying that \"nothing changed\". The alternative would be to allow that something changes (allow path_id=0 here and there), and then check the result line by line to verify that the difference with the reference is as expected. Of course that's doable to. It is just way more time consuming...",
          "createdAt": "2021-01-30T23:57:20Z",
          "updatedAt": "2021-01-30T23:57:20Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "OK. At that point, I need some advice on the JSON formatting. In the traces, the events look like:\r\n```\r\n[0, \"recovery\", \"metrics_updated\", {\"bytes_in_flight\": 3202}],\r\n```\r\nAs you can see, we have a simplified notation, in which the headers are omitted. The simplification is defined in the header element:\r\n```\r\n\"event_fields\":[\"relative_time\",\"category\",\"event\",\"data\"],\r\n```\r\nOnce I have defined the \"events fields\", it appears that writing something like this is invalid:\r\n```\r\n[70892, \"path_id\": 1, \"recovery\", \"metrics_updated\", {\"bytes_in_flight\": 2747,\"smoothed_rtt\": 25681}],\r\n```\r\nI suppose that my only option would be to write:\r\n```\r\n\"event_fields\":[\"relative_time\",\"path_id\",\"category\",\"event\",\"data\"],\r\n...\r\n[70892, 1, \"recovery\", \"metrics_updated\", {\"bytes_in_flight\": 2747,\"smoothed_rtt\": 25681}],\r\n```\r\nWhich requires writing the path ID on every event. Is that correct?",
          "createdAt": "2021-01-31T02:06:26Z",
          "updatedAt": "2021-01-31T02:41:43Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "OK, so I went ahead and updated the picoquic qlog code to add a path_id to the event header when multipath is being negotiated. Although conceptually simple, that changes a lot of code in a lot of places. The PR is at https://github.com/private-octopus/picoquic/pull/1124.\r\n\r\nHere is an example of multipath log:\r\n[multipath_qlog_ref.txt](https://github.com/quiclog/internet-drafts/files/5899304/multipath_qlog_ref.txt)\r\n \r\n\r\n",
          "createdAt": "2021-01-31T06:58:30Z",
          "updatedAt": "2021-01-31T06:58:30Z"
        },
        {
          "author": "huitema",
          "authorAssociation": "NONE",
          "body": "This is another example of qlog with multipath traffic: \r\n[simple_multipath_qlog_ref.txt](https://github.com/quiclog/internet-drafts/files/5938171/simple_multipath_qlog_ref.txt). This one uses the \"simple multipath\" option that I defined in my original draft, which uses a single packet number space. As you will see, the sequence displays well with qvis, although some visualisation of path-id would be nice. The congestion graph, on the other hand, is also wrong. Maybe less wrong than the previous multipath variant, but there really should be one graph per path for congestion window, bytes in flight, etc.",
          "createdAt": "2021-02-07T02:52:17Z",
          "updatedAt": "2021-02-07T02:52:17Z"
        }
      ]
    },
    {
      "number": 135,
      "id": "MDU6SXNzdWU4MDE4MDg0MTI=",
      "title": "DPLPMTUD events",
      "url": "https://github.com/quicwg/qlog/issues/135",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "While DPLPMTUD is optional, there's an [entire section](https://quicwg.org/base-drafts/draft-ietf-quic-transport.html#name-datagram-packetization-laye) about it in QUIC transport.\r\n\r\nMinimal support for this in qlog would define an event `mtu_increased` for every increase of the MTU:\r\n```\r\n{\r\n     new_mtu: uint16\r\n}\r\n```\r\n\r\nI don't think we need a separate event for the sending of an MTU probe packet, but we should probably standardize a `trigger` for this. Suggestion: `mtu_probe`.\r\n\r\nOpen question: Do we want a separate failure event? Failure would be either the loss of an MTU probe packet, or (for implementations that pay attention to ICMP packets) the receipt of an ICMP Packet Too Big (PTB) message.",
      "createdAt": "2021-02-05T03:23:23Z",
      "updatedAt": "2021-08-18T10:23:53Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I agree it would be useful to have this information in qlog.\r\n\r\nIn terms of design, as always there are several options:\r\n1) have separate events for this (`mtu_updated`, `mtu_probe_sent`, `mtu_probe_lost`, etc.)\r\n2) integrate them into existing events( triggers on `packet_sent` and `packet_lost`, new `mtu` field in `metrics_updated`)\r\n3) a combination of these approaches (which is what you suggest IIUC)\r\n\r\nThis is imo a good example of where we need clear design guidelines on how to add new information/events to qlog. \r\n",
          "createdAt": "2021-02-09T13:41:25Z",
          "updatedAt": "2021-02-09T13:41:25Z"
        }
      ]
    },
    {
      "number": 136,
      "id": "MDU6SXNzdWU4MDI5Mjc3MTg=",
      "title": "add a field to log the code version",
      "url": "https://github.com/quicwg/qlog/issues/136",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "design",
        "high-level-schema",
        "current-version"
      ],
      "body": "With many iterations of my qlog implementation running in production now, it would be helpful if there was a way to tell which version of my code generated any particular qlog file (even better if qvis could display it somewhere).\r\n\r\nI suggest adding an optional `code_version` to the `Trace` container. Implementations could fill this field with whatever they want. In quic-go, I'd probably use something like `quic-go $(git describe --long --dirty)`.",
      "createdAt": "2021-02-07T11:14:07Z",
      "updatedAt": "2021-08-18T10:24:39Z",
      "closedAt": null,
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "A similar argument applies to architecture information. It would be useful to have a field to log OS / architecture / kernel information / compiler version.",
          "createdAt": "2021-02-07T11:36:20Z",
          "updatedAt": "2021-02-07T11:36:20Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I agree this is useful information, but I'm not 100% sure it makes sense to standardize this, as I'd assume the handling of this field would depend on the company/deployment/tool and as you say, the contents can also differ wildly. Note that it's in my opinion perfectly acceptable to have qvis display a field that isn't defined in the qlog docs as such (i.e., qvis is broader than qlog). \r\n\r\nIf we do want to include this type of thing in qlog proper, I'd propose putting it beneath the existing `configuration` field, or add a new `environment` field. ",
          "createdAt": "2021-02-09T13:45:45Z",
          "updatedAt": "2021-02-09T13:45:45Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "> Note that it's in my opinion perfectly acceptable to have qvis display a field that isn't defined in the qlog docs as such\r\n\r\nAre you suggesting that qvis defines additional fields / events? That's an interesting idea.\r\nIn this case though, I'd argue that `environment` (which is a lot better name than the `code_version` I suggested) is something that would be a useful thing to display for a variety of tools, so it would probably make sense to define it here.",
          "createdAt": "2021-02-09T13:57:56Z",
          "updatedAt": "2021-02-09T13:57:56Z"
        }
      ]
    },
    {
      "number": 137,
      "id": "MDU6SXNzdWU4MjAxNTgzNDQ=",
      "title": "Prepare for adoption",
      "url": "https://github.com/quicwg/qlog/issues/137",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "List of thinks to keep in mind when preparing for QUIC wg adoption:\r\n- Split QUIC and HTTP/3 event definitions into separate drafts (ensure proper cross-reference)\r\n- Update editor names and affiliations\r\n- Specify which value of `protocol_type` to use for each document (and change to array-based already?)\r\n- Move shared stuff to the main schema document\r\n  - RawInfo (though not 100% sure that's generic enough for all protocols?)\r\n  - The whole \"generic\" category (error, warning, verbose, etc.)\r\n  - Potentially the \"Importance\" indicators (Core, Base, Extra)\r\n- Add more information about \"previous versions\" (e.g., two main versions in production, -01 and -02, those pre-date these adopted documents)\r\n- Define a new version codepoint for the adopted drafts (now it's still draft-03-wip, but we also can't just do draft-00 or we'll overlap soon. Maybe qlog-0x?)\r\n- rename master branch to main #140 \r\n- Send e-mail to mailing list detailing the changes. Chairs will send a separate email with call for adoption afterwards.\r\n\r\nConcrete steps for splitting / preparing the drafts according to @lpardue:\r\n\r\n```\r\ncp draft-marx-qlog-event-definitions-quic-h3.md draft-marx-qlog-quic-events.md\r\ncp draft-marx-qlog-event-definitions-quic-h3.md draft-marx-qlog-h3-events.md\r\n\r\n# add comment into draft-marx-qlog-event-definitions-quic-h3.md saying \"beginning the split\"\r\n\r\ngit add draft-marx-qlog-event-definitions-quic-h3.md draft-marx-qlog-quic-events.md draft-marx-qlog-h3-events.md\r\n\r\ngit commit -m \"starting document split\"\r\n\r\n# then delete all the non-relevant text in draft-marx-qlog-quic-events.md and draft-marx-qlog-h3-events.md, and move necessary text to main-schema, then\r\n\r\ngit -rm draft-marx-qlog-event-definitions-quic-h3.md\r\ngit add draft-marx-qlog-quic-events.md draft-marx-qlog-h3-events.md\r\n\r\ngit commit -m \"complete document split\"\r\n\r\n# then update editors and other metadata in the 3 documents\r\n\r\ngit commit -m \"prepare for adoption\"\r\n\r\n# then submit 03, 00, 00 as individual I-Ds that we can issue a call for adoption on\r\n```\r\n\r\n",
      "createdAt": "2021-03-02T16:04:51Z",
      "updatedAt": "2021-05-15T19:31:24Z",
      "closedAt": "2021-05-15T19:31:24Z",
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "I hadn't appreciated you might need to also move stuff into the main schema. If that is too onerous a task at this stage then you could just mark it in the docs and leave it there for the being.\r\n\r\nThe important thing is the get the overall structure in place and agreed. The content of each document can then be evolved through the working group.",
          "createdAt": "2021-03-18T18:21:32Z",
          "updatedAt": "2021-03-18T18:21:32Z"
        }
      ]
    },
    {
      "number": 139,
      "id": "MDU6SXNzdWU4MzQ3MDkwODQ=",
      "title": "How to deal with (aggregated) measurements",
      "url": "https://github.com/quicwg/qlog/issues/139",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "future-versions"
      ],
      "body": "The [spindump project](https://github.com/EricssonResearch/spindump) provides (aggregated) protocol measurements (e.g., RTT, loss, connection count, etc.) from middleboxes. They would like to use qlog as an output format and have [prototyped](https://github.com/EricssonResearch/spindump/blob/master/src/spindump_event_printer_qlog.c) what that [might look like](https://github.com/EricssonResearch/spindump/blob/master/Format.md#qlog-format).\r\n\r\nExample of their current output:\r\n```\r\n$ src/spindump --input-file src/../test/trace_quic_rfc_quant_long_qlog.pcap --textual --format text --not-report-notes --format qlog\r\n\r\n{\"qlog_version\": \"draft-02\", \"qlog_format\": \"JSON\", \"description\": \"Spindump measurements\", \"traces\": [\r\n\r\n { \"vantage_point\": { \"type\": \"network\" }, \"events\": [\r\n\r\n     {\"time\": 1614616215488286, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"connection_started\", \r\n\r\n      \"ip_version\": \"ipv4\", \"src_ip\": \"10.30.0.167\", \"dst_ip\": \"91.190.195.94\", \"src_port\": \"49702\", \"dst_port\": \"4433\", \"src_cid\": \"041d0cd3\", \"dst_cid\": \"c2e9970d6b5925175646\", \r\n\r\n      \"data\": {\"packets1\": 0, \"packets2\": 0, \"bytes1\": 0, \"bytes2\": 0}},\r\n\r\n     {\"time\": 1614616216598876, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"connection_started\", \r\n\r\n      \"ip_version\": \"ipv4\", \"src_ip\": \"10.30.0.167\", \"dst_ip\": \"91.190.195.94\", \"src_port\": \"49702\", \"dst_port\": \"4433\", \"src_cid\": \"041d0cd3\", \"dst_cid\": \"0487c887\", \r\n\r\n      \"data\": {\"packets1\": 2, \"packets2\": 1, \"bytes1\": 2728, \"bytes2\": 298, \"bandwidth1\": 1500, \"bandwidth2\": 298}},\r\n\r\n     {\"time\": 1614616216598876, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 2, \"packets2\": 1, \"bytes1\": 2728, \"bytes2\": 298, \"bandwidth1\": 1500, \"bandwidth2\": 298, \"right_rtt\": 109806}},\r\n\r\n     {\"time\": 1614616217177621, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 7, \"packets2\": 18, \"bytes1\": 3159, \"bytes2\": 21320, \"bandwidth1\": 1500, \"bandwidth2\": 21320, \"right_rtt\": 70432}},\r\n\r\n     {\"time\": 1614616217178198, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 7, \"packets2\": 19, \"bytes1\": 3159, \"bytes2\": 21415, \"bandwidth1\": 1500, \"bandwidth2\": 21415, \"left_rtt\": 577}},\r\n\r\n     {\"time\": 1614616217178198, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 7, \"packets2\": 19, \"bytes1\": 3159, \"bytes2\": 21415, \"bandwidth1\": 1500, \"bandwidth2\": 21415, \"full_rtt_initiator\": 71009}},\r\n\r\n     {\"time\": 1614616217545056, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 9, \"packets2\": 26, \"bytes1\": 3275, \"bytes2\": 30375, \"bandwidth1\": 1500, \"bandwidth2\": 30375, \"right_rtt\": 366858}},\r\n\r\n     {\"time\": 1614616217545056, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 9, \"packets2\": 26, \"bytes1\": 3275, \"bytes2\": 30375, \"bandwidth1\": 1500, \"bandwidth2\": 30375, \"full_rtt_responder\": 367435}},\r\n\r\n     {\"time\": 1614616217546034, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 9, \"packets2\": 30, \"bytes1\": 3275, \"bytes2\": 34607, \"bandwidth1\": 1500, \"bandwidth2\": 34607, \"left_rtt\": 978}},\r\n\r\n     {\"time\": 1614616217546034, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 9, \"packets2\": 30, \"bytes1\": 3275, \"bytes2\": 34607, \"bandwidth1\": 1500, \"bandwidth2\": 34607, \"full_rtt_initiator\": 367836}},\r\n\r\n     {\"time\": 1614616217643280, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 11, \"packets2\": 30, \"bytes1\": 3386, \"bytes2\": 34607, \"bandwidth1\": 1775, \"bandwidth2\": 34607, \"right_rtt\": 97246}},\r\n\r\n     {\"time\": 1614616217643280, \"protocol_type\": QUIC, \"group_id\": \"sd-0\", \"event\": \"measurement\", \r\n\r\n      \"data\": {\"packets1\": 11, \"packets2\": 30, \"bytes1\": 3386, \"bytes2\": 34607, \"bandwidth1\": 1775, \"bandwidth2\": 34607, \"full_rtt_responder\": 98224}}  \r\n\r\n ]}]}\r\n```\r\n\r\nThe semantics of logging measurements from a middlebox can differ from logging endpoint events, as the middlebox doesn't have all the contextual information.\r\n\r\nOne example is the `connection_started` event vs possible events like `connection_migrated` or `tuple_changed` (which we don't have yet, but will someday #79). The middlebox can't really tell the difference for a protocol like QUIC, and always logging either `_started` or `_changed` is semantically not 100% correct (it's more like \"first observed\").\r\n\r\nSomething similar can be said for using `recovery:metrics_updated` to log changes to e.g., RTT or loss rates. They have now defined a custom `measurement` event, which I feel is maybe too generic. You could also question if logging all measurement fields together in a single event is optimal (though this is the approach we do take with things like `metrics_updated`. See #85 for more discussion).\r\n\r\nAnother interesting observation is the need to log metrics in two directions, as the middlebox is somewhere in between 2 endpoints in the network. This all seems to indicate measurement-specific events is the way to go (i.e., not re-using existing qlog  endpoint events), as it would be confusing to have those semantics in endpoint events. \r\n\r\nSomething not yet reflected in here are the possibility to log percentiles, which seems interesting as a generic option for (aggregated) measurement logging. \r\n\r\nCC @jariarkko @ihlar\r\n\r\n ",
      "createdAt": "2021-03-18T11:40:32Z",
      "updatedAt": "2021-08-18T13:31:39Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 140,
      "id": "MDU6SXNzdWU4MzQ4NjYwNTY=",
      "title": "Move default git branch from master to main",
      "url": "https://github.com/quicwg/qlog/issues/140",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "In preparation of QUIC wg adoption (which plans to take over ownership of this entire repo), we should make \"main\" the default branch instead of \"master\". \r\n\r\nI plan to do this sometime over the coming weeks; this is just a heads-up so people don't suddenly see local checkouts breaking. ",
      "createdAt": "2021-03-18T14:15:03Z",
      "updatedAt": "2021-08-02T13:03:51Z",
      "closedAt": "2021-08-02T13:03:51Z",
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "Closing as done",
          "createdAt": "2021-08-02T13:03:51Z",
          "updatedAt": "2021-08-02T13:03:51Z"
        }
      ]
    },
    {
      "number": 141,
      "id": "MDU6SXNzdWU4MzQ5Mzc1ODU=",
      "title": "Fix up TypeScript-based data definition language",
      "url": "https://github.com/quicwg/qlog/issues/141",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "There are some problems with the current definition in -02, mostly identified by @mikkelfj.\r\nIt will depend on if we stick with this approach later whether these comments need to be addressed or not. Some of them are relevant to other data definition languages as well.\r\n\r\n1. we define booleans as strings \"true\" / \"false\", while JSON has native true/false\r\n2. we currently have many mixed-type fields (e.g., things that are string | uint32). While e.g., binary serializers (say protocol buffers/flatbuffers) are free to choose which type/types is/are most appropriate for them to support, we should probably indicate which of the options is the \"main\" type.\r\n3. Similarly to 2., where we use the `any` type, we should indicate a `default` option or example of what might be expected/used in the typical case\r\n4. The packetType enum that uses onertt = \"1RTT\" and zerortt = \"0RTT\" does so for a purely JavaScript-esque reason which shouldn't be reflected in the draft",
      "createdAt": "2021-03-18T15:22:42Z",
      "updatedAt": "2021-08-18T13:33:52Z",
      "closedAt": "2021-08-18T13:33:52Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Duplicate of/related to #143, use that for further tracking",
          "createdAt": "2021-08-18T13:33:50Z",
          "updatedAt": "2021-08-18T13:33:50Z"
        }
      ]
    },
    {
      "number": 142,
      "id": "MDU6SXNzdWU4NDYyMTYxNjg=",
      "title": "Provide clear privacy and security guidelines",
      "url": "https://github.com/quicwg/qlog/issues/142",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "future-versions",
        "privacy"
      ],
      "body": "qlog should be specific about which fields are potentially privacy sensitive and the possible actions that can be taken to mitigate these issues (e.g., hashing, exclusion, mapping, ...). \r\n\r\nThe current proposal is to work with multiple sanitization levels, depending on the intended use case. \r\nThe way this is expressed in the drafts depends on the data definition format we end up adopting. \r\n\r\nOne potential source of inspiration is https://www.tracewrangler.com, which anonymizes pcaps. \r\n\r\nOther related considerations are whether to provide options to encrypt qlogs themselves.\r\n\r\nThis is intended to be an overarching summary issue, with sub-issues expected for specific approaches/proposals. ",
      "createdAt": "2021-03-31T08:50:43Z",
      "updatedAt": "2021-08-18T13:32:19Z",
      "closedAt": null,
      "comments": [
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "On the topic of encrypting the logs themselves, I think that shouldn't be specified. How ever the owner of the log wants to secure the file at rest should be up to them.",
          "createdAt": "2021-03-31T14:07:00Z",
          "updatedAt": "2021-03-31T14:07:00Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I think that makes sense. I feel some of the remarks on this point were mainly tied to the serialization format selection. i.e., if we use CBOR, we get COSE (https://tools.ietf.org/html/rfc8152) \"for free\", which in turn might be an additional reason to chose CBOR as basic format, as that gives a standard/default option for encryption for people that don't have a specific opinion on how they'd want to do it otherwise. ",
          "createdAt": "2021-03-31T14:13:30Z",
          "updatedAt": "2021-03-31T14:13:30Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "Ok. Well, see the other issue on my feelings about a complicated format. :) Keep it simple, IMO.",
          "createdAt": "2021-03-31T14:20:40Z",
          "updatedAt": "2021-03-31T14:20:40Z"
        }
      ]
    },
    {
      "number": 143,
      "id": "MDU6SXNzdWU4NDYyMjQwNzA=",
      "title": "Change data definition format",
      "url": "https://github.com/quicwg/qlog/issues/143",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "We currently use a custom DDL inspired by TypeScript to specify events.\r\nThis should probably be changed to a format already defined by the IETF. This would also potentially remove the need to specify a custom JSON mapping.\r\n\r\nCurrently, YANG and especially CDDL seem to be the most attractive options for this purpose. \r\n\r\nExisting discussion was mainly in https://mailarchive.ietf.org/arch/msg/quic/H_inwB1oLh4fr1-i7JyUb-8U5Gg",
      "createdAt": "2021-03-31T08:55:23Z",
      "updatedAt": "2021-08-18T13:34:06Z",
      "closedAt": null,
      "comments": [
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "I have the following comments on format:\r\n\r\n1. If it's not binary (or extremely efficient to generate and process even at extremely large scale) then I can't use it at run time. The best I can do is support a post processor to convert to qlog later. The tools will likely have problem with large files as well.\r\n2. IMO, it **must** be simple to write a custom converter to the format. Please no super complicated protocols just around format. If I have to include an external library just to deal with the file format, then it's likely it won't be supported.",
          "createdAt": "2021-03-31T14:13:39Z",
          "updatedAt": "2021-03-31T14:13:39Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "To clarify, there are two types of formats we need to consider: \r\n1. The data definition format: how we define events and member data types in the drafts (that's what this issue is intended to be about)\r\n2. The serialization format(s): what a qlog file actually looks like in string/binary form (I realized we no longer had an issue to discuss that, so I've made https://github.com/quiclog/internet-drafts/issues/144)\r\n\r\nI think your comments mainly reflect on the 2nd point, though they are of course somewhat tied: for example, CDDL makes it easy to express JSON and CBOR, but potentially more difficult to define other (binary) serialization formats. ",
          "createdAt": "2021-03-31T14:23:39Z",
          "updatedAt": "2021-03-31T14:23:39Z"
        }
      ]
    },
    {
      "number": 144,
      "id": "MDU6SXNzdWU4NDY3NjI1MTU=",
      "title": "Revisit serialization format decision",
      "url": "https://github.com/quicwg/qlog/issues/144",
      "state": "CLOSED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "In draft-02, we decided to keep using JSON as the main serialization format, with NDJSON as a streaming option. We did update the data definition language used in the draft to make it easier to define custom serializations into e.g., binary formats, if others want a more performant option. \r\n\r\nIt might be needed to revisit this decision and to still go for a binary format by default. CBOR has so far been named most as a potential option, as it's an IETF standard (as opposed to e.g., protocol buffers or flatbuffers and similar) and has proved itself for other protocol-related use cases as well. \r\n\r\nThe question remains: do we consciously limit ourselves to a select few serialization formats? and even if we don't, which \"default\" formats do we commit to in the texts? \r\n\r\nSeveral people are of the opinion it's enough to stick with for example JSON as the main format in the qlog specification and to have people write converters from/to JSON for more performant options themselves. This because even with something like CBOR, not all applications will want to employ that directly, and converters would still be needed.",
      "createdAt": "2021-03-31T14:22:01Z",
      "updatedAt": "2021-08-18T13:35:17Z",
      "closedAt": "2021-08-18T13:35:16Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Another simple way of viewing this (and one of the main questions I feel we need to answer ASAP post-adoption), is what the main goal of qlog is:\r\n\r\n1) Define a logging format that makes it easy for **protocol implementations** to log data (efficiently, at scale)\r\n2) Define a logging format that makes it easy to create **reusable tooling** \r\n\r\n(I think it was @nibanks who put it like this, but for the life of me, I can't find the source). \r\n\r\nIf 1), we probably need to go full binary and optimize for write speed/size. 2) is imo what we have now, with a relatively verbose JSON setup. If we want to go for both at the same time (which I'm not sure is possible, might lead to \"worst of both worlds\") we'd probably end up with something like CBOR. \r\n\r\nIn my personal experience, it's the tooling part that's difficult and something that most parties don't want to invest in themselves/don't have the necessary expertise for in the networking/protocol teams. Making tooling easier (e.g., even using things like `jq` or simple python) and more reusable seems like it should stay the main goal. While the current qvis toolsuite doesn't deal well with larger qlog files, that's mainly because it's web-based, not because JSON can't scale to hundreds of MBs or even Gigabytes in a native tool. Of course, that's just my opinion :) ",
          "createdAt": "2021-04-07T15:20:32Z",
          "updatedAt": "2021-04-07T15:20:32Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "I think we can create translation libraries/tools easily enough between formats. The question then becomes what do you want to do?\r\n\r\na) **Optimize for tools** - Standardize around a single format (JSON most likely?) that tools can easily use. QUIC implementations then have the choice to either write directly to that format, or have a custom format, and a custom post processing tool to convert to the tool format.\r\n\r\nb) **Optimize for implementations** - Standardize around a binary format (and helper library(s)?) for QUIC implementations to efficiently write to. Tools can either read from that format or perhaps someone could write a helper library to convert to some more easily consumed format. While I like the idea of trying to optimize for implementations, I wonder if it's just going to open a bigger can of worms. A lot of folks will have strong opinions here, and likely already have some solution they use for other performant logging anyways.\r\n\r\nThe more I think about it, I kind of lean towards a). Implementations can (and will) do what they want. If JSON is optimal enough for them (it seems it is for FB?) then they can use it. If they want something more/different, they can implement a translation layer/tool (what MsQuic partially has). And best of all, it makes the standardization process simpler.\r\n\r\nOne last thought though, is that while web-based solutions are currently the reason the tools are slow, I do expect JSON parsing to be significantly slower than a binary format, especially at GB file sizes. It'd be interesting to see a perf comparison. The best way I could think is to add qlog file format support to WPA, and update MsQuic's qlog translation layer. Then grab a large trace from MsQuic (binary ETW) and convert it to qlog. Then separately open the binary version and the qlog version and measure how long either takes.",
          "createdAt": "2021-04-07T15:42:06Z",
          "updatedAt": "2021-04-07T15:42:06Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "One other option to consider is the use of / overlap with the PCAP-NG format typically used for packet captures. \r\n\r\nThis is apparently being considered for adoption on opsawg and might be flexible enough to include the endpoint-specific data we want to add to the mix. \r\n\r\nI still need time to analyze what PCAP-NG actually does, but initial discussion on this was on the mailing list at: https://mailarchive.ietf.org/arch/msg/qlog/2bSRgRdaRleLhTDFv_C4DYZ3zng/\r\n\r\nOne benefit of this would be that we can easily log raw (encrypted) packets along with endpoint data as in normal .pcaps (though I'm not sure how useful that is). A downside is that the format is (AFAIK) barely supported outside of tools like wireshark (e.g., no easy mature open source parsers available, though I could be completely wrong on that count). ",
          "createdAt": "2021-05-19T11:45:02Z",
          "updatedAt": "2021-05-19T11:45:02Z"
        },
        {
          "author": "mcr",
          "authorAssociation": "NONE",
          "body": "It might not be the encrypted packets you are logging, it might be the DNS requests (whether encrypted or not), or even the ICMP packet too big, or the ICMP port unreachables.",
          "createdAt": "2021-05-21T18:24:24Z",
          "updatedAt": "2021-05-21T18:24:24Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "As in implementer, why would I modify my endpoint to take a packet capture when e.g. tcpdump can already do that?",
          "createdAt": "2021-07-13T15:44:39Z",
          "updatedAt": "2021-07-13T15:44:39Z"
        },
        {
          "author": "mcr",
          "authorAssociation": "NONE",
          "body": "> As in implementer, why would I modify my endpoint to take a packet capture when e.g. tcpdump can already do that?\r\n\r\nBecause tcpdump can't capture (a) the cleartext packets inside the QUIC/TLS, (b) your state transitions.\r\nThe reason you might want it all in pcap-ng format is so that that you can combine an external view of the packets (including DNS requests, ICMPs, and TCP activities) with your internal capture.  \r\nYou'd do a zipper merge on the data so that you can see that your internal state transition followed a failed DNS request, or something like that.\r\n",
          "createdAt": "2021-07-13T16:29:46Z",
          "updatedAt": "2021-07-13T16:29:46Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "In my experience, my QUIC client application fails to resolve a name, I don't even make a UDP socket or QUIC connection object. My client stderr log throws an error message, possibly reporting the error returned by my resolution syscall.\r\n\r\nCombining with wire packet captures seems to have marginal value when those packets don't contain more information than is available to the client.",
          "createdAt": "2021-07-13T16:52:58Z",
          "updatedAt": "2021-07-13T16:52:58Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "Discussed during IETF 111. The feeling in the room was to stick with JSON serialization as the canonical interop format for qlog. Use of JSON does not prevent other serialization formats but we can constrain our scope of work to focus on one in this set of deliverables.",
          "createdAt": "2021-08-02T13:11:21Z",
          "updatedAt": "2021-08-02T13:11:21Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "For clarification, the present specifics of the document's JSON serialization definitions are a starting point for further development should the WG declare consensus on using JSON.\r\n\r\nThe discussion about streaming serialization (whether NDJSON or some other format) is separate, so I've created #172 .",
          "createdAt": "2021-08-02T17:50:46Z",
          "updatedAt": "2021-08-02T17:50:46Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Given the consensus, I am closing this issue. The main related subissues are tracked in #172 and #143 going forward. ",
          "createdAt": "2021-08-18T13:35:16Z",
          "updatedAt": "2021-08-18T13:35:16Z"
        }
      ]
    },
    {
      "number": 146,
      "id": "MDU6SXNzdWU4NDkyNjQ4ODk=",
      "title": "Make protocol_type more well defined",
      "url": "https://github.com/quicwg/qlog/issues/146",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "high-level-schema",
        "current-version",
        "discuss"
      ],
      "body": "Currently, `protocol_type` is a single string which typically has the value \"QUIC_HTTP3\". \r\n\r\nHowever, this doesn't particularly scale to aggregated logs down the line (e.g., in #139 we can have a plethora of different protocols represented), and it isn't clear how to define new strings for new protocol types (e.g., is it TCP_HTTP2 or TCP_TLS_HTTP2 and in that case, why isn't it QUIC_TLS_HTTP3? etc.)\r\n\r\nOne direct solution might be to make the field an array of individual values (i.e., `protocol_type = [\"QUIC\", \"HTTP3\"]`), but that potentially adds additional overhead if the field is logged for each event individually. \r\n\r\nAnother option would be to prefix event names with the protocol (e.g., `transport:packet_sent` becomes `quic:transport:packet_sent`) but that reduces the future potential to re-use events across protocols (not a big deal for QUIC vs TCP probably, but higher level logic events (say, `recovery:metrics_updated`) could suffer). \r\n\r\nThis is somewhat tied to #85, as some events will be implicitly tied to a particular protocol anyway. ",
      "createdAt": "2021-04-02T14:55:11Z",
      "updatedAt": "2021-08-18T13:45:24Z",
      "closedAt": null,
      "comments": [
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "Personally, I think events **should** be tied to protocol, and \"sharing\" them should not be a goal. IMO that's going to make things harder and more confusing to interpret, especially if you end up having both protocols in the same log. For Windows, we regularly use well-defined events and they are always specific to a particular component. Even if things might look similar now, that doesn't mean they would stay that way in the future. Forcing things to be the same would then limit the development of the one that wants to evolve.",
          "createdAt": "2021-04-02T15:08:20Z",
          "updatedAt": "2021-04-02T15:08:20Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "And one more data point for you, we generally follow a pattern for events to be named something along the line of <Component/Protocol><Object/Qualifier><Action>, such as `QuicConnVersionSet` and `QuicStreamCreated`. It allows for events to be globally unique and descriptive enough that you don't need too much follow up to explain what it is doing.",
          "createdAt": "2021-04-02T15:13:31Z",
          "updatedAt": "2021-04-02T15:13:31Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This also has a potential impact on how we define the high-level `name` field vs the separate `category` and `event/type` fields, as tracked in #150 and #153. ",
          "createdAt": "2021-08-18T13:41:30Z",
          "updatedAt": "2021-08-18T13:45:24Z"
        }
      ]
    },
    {
      "number": 147,
      "id": "MDU6SXNzdWU4NTE0MjkyNjE=",
      "title": "How to log handshake cancelations?",
      "url": "https://github.com/quicwg/qlog/issues/147",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "I didn't think of this back when we defined the triggers for `connection_closed`, but this is happening **a lot** in production: When dialing a new peer, libp2p races connections to that peer on all advertised addresses and transports, and uses whichever connection returns first. All the other connection attempts are canceled.\r\n\r\nIt would be nice if there was a trigger \"the user aborted this connection attempt before handshake completion\".",
      "createdAt": "2021-04-06T13:32:43Z",
      "updatedAt": "2021-08-18T13:38:18Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Good point!\r\n\r\nDo you think a generic `aborted` trigger is enough, or would it make sense to go with something more fine-grained like `aborted_racing` (potentially having an `aborted` generic as well?)?\r\n\r\nWould it be useful to have a way to indicate to which other connection (6-tuple?) this one \"lost\" in the race (and by how much etc.)? Would that need a separate event or should that be included in the `connection_closed`? I'd tend towards a separate event for that one myself. ",
          "createdAt": "2021-04-07T07:50:37Z",
          "updatedAt": "2021-04-07T07:50:37Z"
        }
      ]
    },
    {
      "number": 148,
      "id": "MDU6SXNzdWU4NTI2NjAzMzg=",
      "title": "Format text to a certain width and avoid inline comments",
      "url": "https://github.com/quicwg/qlog/issues/148",
      "state": "OPEN",
      "author": "toidiu",
      "authorAssociation": "NONE",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "Inline comments force the reader to scroll sideways and makes it more difficult to read.\r\n\r\nAdditionally while this is possibly fine for html, the rendering in pdf is much worse since scrolling is not supported.\r\n\r\n**html example**: https://quiclog.github.io/internet-drafts/draft-marx-qlog-event-definitions-quic-h3.html#section-a.1\r\n\r\n **pdf example**:\r\n![pdf_rendering](https://user-images.githubusercontent.com/4350690/113912463-00d55d80-9790-11eb-9c05-e5abfea0b81e.png)\r\n",
      "createdAt": "2021-04-07T17:58:36Z",
      "updatedAt": "2021-08-18T13:38:46Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Hello @toidiu,\r\n\r\nThank you for this very valid comment. \r\nWe will take this into account when re-formatting the qlog documents after adoption by the QUIC wg. \r\n\r\nI hope it doesn't cause too much of an inconvenience in the mean time? ",
          "createdAt": "2021-04-08T13:28:31Z",
          "updatedAt": "2021-04-08T13:28:31Z"
        },
        {
          "author": "toidiu",
          "authorAssociation": "NONE",
          "body": "Great thanks for the reply and all your work. I can use the html version of the draft in the meanwhile. ",
          "createdAt": "2021-04-08T16:41:48Z",
          "updatedAt": "2021-04-08T16:41:48Z"
        }
      ]
    },
    {
      "number": 149,
      "id": "MDU6SXNzdWU4NTgyNjM2NjE=",
      "title": "[draft 02] Fix JSON serialization example under the Field name semantics section",
      "url": "https://github.com/quicwg/qlog/issues/149",
      "state": "CLOSED",
      "author": "JorisHerbots",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "**Problem**\r\nThe section about \"Field name semantics\" in draft 02 contains the following example:\r\n```\r\nJSON serialization:\r\n\r\n{\r\n    time: 1553986553572,\r\n\r\n    name: \"transport:packet_sent\",\r\n    event: \"packet_sent\",\r\n    data: { ... }\r\n\r\n    protocol_type:  \"QUIC_HTTP3\",\r\n    group_id: \"127ecc830d98f9d54a42c4f0842aa87e181a\",\r\n\r\n    time_format: \"absolute\",\r\n\r\n    ODCID: \"127ecc830d98f9d54a42c4f0842aa87e181a\", // QUIC specific\r\n}\r\n```\r\nThe QLOG specification lists the use of `category` and `type` fields or their concatenation under the `name` field. The above example, however, seems to hint that there also exists an `event` field. \r\n\r\n**Suggested fix**\r\n ```\r\nJSON serialization:\r\n\r\n{\r\n    time: 1553986553572,\r\n\r\n    name: \"transport:packet_sent\",\r\n    data: { ... }\r\n\r\n    protocol_type:  \"QUIC_HTTP3\",\r\n    group_id: \"127ecc830d98f9d54a42c4f0842aa87e181a\",\r\n\r\n    time_format: \"absolute\",\r\n\r\n    ODCID: \"127ecc830d98f9d54a42c4f0842aa87e181a\", // QUIC specific\r\n}\r\n```\r\nOr\r\n\r\n ```\r\nJSON serialization:\r\n\r\n{\r\n    time: 1553986553572,\r\n\r\n    category: \"transport\",\r\n    type: \"packet_sent\",\r\n    data: { ... }\r\n\r\n    protocol_type:  \"QUIC_HTTP3\",\r\n    group_id: \"127ecc830d98f9d54a42c4f0842aa87e181a\",\r\n\r\n    time_format: \"absolute\",\r\n\r\n    ODCID: \"127ecc830d98f9d54a42c4f0842aa87e181a\", // QUIC specific\r\n}\r\n```",
      "createdAt": "2021-04-14T21:05:37Z",
      "updatedAt": "2021-04-15T09:28:33Z",
      "closedAt": "2021-04-15T09:28:33Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thanks for noticing this. The correct fix is the first (the omission of the `event` field). I will open a PR for that. ",
          "createdAt": "2021-04-15T08:18:26Z",
          "updatedAt": "2021-04-15T08:18:26Z"
        }
      ]
    },
    {
      "number": 150,
      "id": "MDU6SXNzdWU4NTgyNzI5OTA=",
      "title": "[draft 02] \"events\" field minimum requirements",
      "url": "https://github.com/quicwg/qlog/issues/150",
      "state": "CLOSED",
      "author": "JorisHerbots",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [
        "design",
        "high-level-schema",
        "current-version",
        "discuss"
      ],
      "body": "**Issue**\r\nThe specification mentions the following under the \"Field name semantics\" section (ID: field-name-semantics): \r\n\r\n> Each qlog event at minimum requires the \"time\" ({{time-based-fields}}), \"name\" ({{name-field}}) and \"data\" ({{data-field}}) fields.\r\n\r\nAccording to the section \"category and event\" (ID: name-field), `name` is the concatenation of the `category` and `type` fields. This should be reflected in the line above.\r\n\r\n**Suggestion**\r\n> Each qlog event at minimum requires the \"time\" ({{time-based-fields}}), \"name\" (or \"category\" and \"type\") ({{name-field}}) and \"data\" ({{data-field}}) fields.",
      "createdAt": "2021-04-14T21:20:23Z",
      "updatedAt": "2021-08-18T13:46:37Z",
      "closedAt": "2021-08-18T13:46:37Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So this is a bit of a difficult one... As explained in section `name-field`, category+type were used in qlog draft 01 but in 02 it's preferred to use the concatenated version: `As such, the default approach in qlog is to concatenate both field values`\r\n\r\nIt's highly uncertain at this point how/if these fields will continue to exist in this form (see also #146, which means we might go to quic:packet_sent instead of transport:packet_sent in time for example).\r\n\r\nSo for now, I'd like to keep the text as-is (encourage concatenated form). \r\n\r\nNote: qvis -should- still support both category + event for draft02 for easier backwards compat though. If that's not the case, then that should be fixed. ",
          "createdAt": "2021-04-15T08:29:17Z",
          "updatedAt": "2021-04-15T08:29:17Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Duplicate of #153, closing in favor of that. ",
          "createdAt": "2021-08-18T13:46:37Z",
          "updatedAt": "2021-08-18T13:46:37Z"
        }
      ]
    },
    {
      "number": 152,
      "id": "MDU6SXNzdWU4NTg5ODYxNTc=",
      "title": "Add ability to log CPU/threading info",
      "url": "https://github.com/quicwg/qlog/issues/152",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "design",
        "high-level-schema",
        "current-version"
      ],
      "body": "In msquic, events all contain the current CPU ID, Process ID and Thread ID (https://github.com/microsoft/msquic/blob/main/src/plugins/wpa/DataModel/QuicEvent.cs), which allows them to do advanced debugging of threading and CPU allocation issues (https://github.com/microsoft/msquic/blob/main/docs/TSG.md#diagnosing-rss-issues).\r\n\r\nIt would potentially be interesting to have this type of metadata well-defined in qlog as well.\r\n\r\nCC @nibanks",
      "createdAt": "2021-04-15T15:15:55Z",
      "updatedAt": "2021-08-19T07:24:50Z",
      "closedAt": null,
      "comments": [
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "Here's an example scenario where having CPU information per event is key to diagnosing issues: https://github.com/microsoft/msquic/blob/main/docs/TSG.md#diagnosing-rss-issues",
          "createdAt": "2021-04-15T15:33:24Z",
          "updatedAt": "2021-04-15T15:33:24Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "At this point, given that we are currently trying to end up with as few \"standard\" qlog events as possible, I wonder if it would make sense to keep this in.\r\n\r\nIt's always possible to add custom fields to indicate this information if needed for a given implementation. Additionally, I'm wondering if it would make sense to log this for each event in qlog instead of have separate events when a connection moves to a new CPU (as we already do that type of logic for other things, like we don't log spinbit in each packet_header but rather have a separate `spin_bit_updated` event). \r\n\r\nSpecifically: I propose not doing this in qlog proper at this time. ",
          "createdAt": "2021-08-18T13:44:42Z",
          "updatedAt": "2021-08-18T13:44:42Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "If this was supported, it would have to be per-event. When you have multiple threads firing off events in parallel, any/every thread may be generating an event at any time, even for the same connection. For instance:\r\n\r\nThread A: Queues a send on connection X, stream Y.\r\nThread B: Queues a send on connection X, stream Z.\r\nThread C: Processes connection X (sending and receiving data for streams Y & Z).\r\n\r\nOne thing to note, WPA **requires** thread and cpu/processor to be supplied for every event.\r\n\r\nAlso, as far as deciding if this is necessary, per-thread/processor scheduling is personally one of the main reasons I need tools for processing logs, and not just look at the raw text. I would find it very surprising if other server deployments don't also have similar experiences.\r\n\r\nPersonally, I'd prefer to at least define this in the spec, but possibly make it optional. If we want tools to be able to generically consume these fields, they can't be custom.",
          "createdAt": "2021-08-18T13:54:07Z",
          "updatedAt": "2021-08-18T13:54:07Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "The qlog direction to log wire events is fine for me. \r\n\r\nBut it seems @nibanks is really discussing the kind of foundation event meta-data that might get logged, and why it is useful. I tend to agree. \r\n\r\nThere's a benefit to considering this information in qlog, we can provide guidance about the data fields as part of security and privacy analysis. For instance, low-level information is useful for local developer analysis but might be too sensitive to share by default.\r\n\r\nWhat would a common platform-independent schema for CPU/thread look like? Is there anything qlog can borrow from?",
          "createdAt": "2021-08-18T14:07:00Z",
          "updatedAt": "2021-08-18T14:07:00Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "FYI, [here](https://github.com/microsoft/msquic/blob/main/src/plugins/trace/dll/DataModel/QuicEvent.cs#L187) is the base (C#) object for events in the WPA event processing code. Generically, every event has at least an ID, timestamp, processor, thread ID, process ID and event-specific payload.",
          "createdAt": "2021-08-18T14:12:36Z",
          "updatedAt": "2021-08-18T14:12:36Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": " It really does seem like endpoint-local data just like the timestamp. I can see cases where all of those could be useful, so optional fields sounds fine to me.\r\n\r\nIf all the info is needed to make sense, I might be tempted to define it as a single tuple rather than individual fields e.g. `hw_info: {processor_id: uint32, process_id: uint32, thread_id: uint32}`\r\n",
          "createdAt": "2021-08-18T14:29:49Z",
          "updatedAt": "2021-08-18T14:29:49Z"
        },
        {
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "body": "@LPardue that works for me.",
          "createdAt": "2021-08-18T15:56:27Z",
          "updatedAt": "2021-08-18T15:56:27Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I think I can now better grasp the benefits of doing this within the context of qlog, so thanks for the additional discussion.\r\n\r\nWe can bikeshed the exact form this should take. I for example would suggest not putting this as a property of the `data` field (part of the payload) but rather as a top-level field (at the same level as timestamp, name and data itself). \r\n\r\nThis would be something defined in the main schema document, as it's usable across protocols. \r\n\r\nAssigning to @lnicco so he can get his hands dirty with adding something new :) \r\n",
          "createdAt": "2021-08-19T07:24:23Z",
          "updatedAt": "2021-08-19T07:24:23Z"
        }
      ]
    },
    {
      "number": 153,
      "id": "MDU6SXNzdWU4NjM2MDE2OTk=",
      "title": "Revisit category/type/name setup",
      "url": "https://github.com/quicwg/qlog/issues/153",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "high-level-schema",
        "current-version",
        "discuss"
      ],
      "body": "Prior to draft-02, we had separate category and type fields. The idea was that this would be easier to filter on (e.g., show me only events in the `transport` category). I'm still not sure people actually use it this way. \r\n\r\nWith the move to normal JSON in -02, I introduced the `name` field, which concatenates to `category:type`. The motivation for that was mainly reducing JSON overhead by not having to repeat `\"category\"` and `\"type\"` strings for each event. \r\n\r\nNow, we have the discussion around `protocol_type` in #85, indicating it might make more sense to tie events more closely to protocols and not have generic/high-level categories (instead of `transport:packet_sent` and a separate `protocol_type` of QUIC, we would for example have `quic_packet_sent` and `tcp_packet_sent`). \r\n\r\nI guess the main question is if there's value in splitting up events in type + category for high-level filtering, or if that's not necessary in practice. From my experience in qvis, it isn't all that useful, since filtering on category still requires looping over all events (and keeping things in lookup maps is also possible without explicit qlog-level categories).",
      "createdAt": "2021-04-21T08:44:56Z",
      "updatedAt": "2021-08-18T13:45:49Z",
      "closedAt": null,
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "The utility of importance, type, category (and potentialy privacy-level), is for me being able to configure my logging application. In some cases I need full details for debugging and I can control the environment to ensure there are no privacy concerns. That utility doesn't necessarily need to be reflected into the serialized logs. As a qlog logging library maintainer, I quite like the idea of providing people with the means to configure different logging instances. What would help is for the qlog spec to set the expectations of what events appear in a log for any type of configuration. For uncoordinated logs, putting this detail into the log itself would be useful for the same reason - it can help avoid false positives (e.g. not seeing any data_moved events in a log could be an application failing to read/write data into streams, or it could be a concious choice by an endpoint to *not* log those events.).\r\n\r\nHaving gone through a round of trying to shift to qlog-02, one observation I made is that the way I structured the object model gave me unique events. From those, I could always \"reflect\" the importance, category or type in the serializing code. Importance is very interesting here, it's an invariant property of the event that *is not* sent on the wire. Therefore, I would expect that such reflection is possible in deserializing code too. I think that's what you mean by \"keeping things in lookup maps is also possible without explicit qlog-level categories\".\r\n\r\nAnother way to write your question is,  how important is it to define a logging format that can be acted on by general purpose tools? Tools such as jq can't natively know a qlog event's importance, but if the log included the value, writing queries would be easy. A post-processing step, using a qlog-aware tool, could insert an importance fields, that could be used by other tools. That's a transformation that is easily reversible, and qlog-aware tools should handle unknown fields (so it's a non-destructive transformation).\r\n\r\nquic_packet_sent and tcp_packet_sent will always exist in a category of transport, whether qlog defines it or not. \r\n",
          "createdAt": "2021-07-20T18:11:58Z",
          "updatedAt": "2021-07-20T18:11:58Z"
        },
        {
          "author": "jlaine",
          "authorAssociation": "CONTRIBUTOR",
          "body": "My two cents here would: \"just go with `name`\", as it's unusual to have to key off two fields to know how to interpret an event (think for instance of the JS `Event`).\r\n\r\nI could also live with separate category / type, but what I'd really NOT like is to have an ambiguous spec with two different ways of identifying events.",
          "createdAt": "2021-07-23T10:09:38Z",
          "updatedAt": "2021-07-23T10:09:38Z"
        }
      ]
    },
    {
      "number": 154,
      "id": "MDU6SXNzdWU4NjUzOTY0Njg=",
      "title": "the frames_processed fails to capture received and sent frames",
      "url": "https://github.com/quicwg/qlog/issues/154",
      "state": "OPEN",
      "author": "toidiu",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [
        "design",
        "quic-http3-fields",
        "future-versions"
      ],
      "body": "The [`frames_processed`](https://tools.ietf.org/html/draft-marx-qlog-event-definitions-quic-h3-02#section-5.3.14) event fails to capture the sending and receiving of frames since it only specified a single `packet_number` field.\r\n\r\nAccording to the [transport rfc](https://tools.ietf.org/html/draft-ietf-quic-transport-32#section-12.3):\r\n>  Each endpoint maintains a separate packet number for sending and receiving.\r\n\r\nI feel mirroring the packet events would be consistent and result in two events: `frames_sent` and `frames_received` which will be easier to match on.",
      "createdAt": "2021-04-22T19:31:20Z",
      "updatedAt": "2021-08-18T13:47:00Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "So the idea is that send/receive semantics for frames are done in the `packet_sent` and `packet_received` events. These not only log e.g., the packet header, but also the frames and their contents. \r\n\r\nThe `frames_processed` event is an additional one to be used to signify exactly that: when the frames are -processed- (as this does not necessarily happen directly after/before send/receive). This is mostly in the cases where a) the processing code is decoupled heavily from the send/recv code or b) you don't want to log full packets, but are mainly interested in e.g., how stream frames are handled. The `packet_number` is just to have -a- way of correlating this info to the packet carrying the frames for later cross-reference, but not intended to replace the `packet_sent` and `packet_received` events (which log the packet numbers as well of course).\r\n\r\nIf you would only want to log the frames (e.g., have pure `frames_sent` and `frames_received`), you could just use `packet_sent` and `packet_received` and omit packet-level information from these instead. \r\n\r\nFrom your issue, I assume this wasn't clear when reading the draft and that we should clarify it. However, I feel like the setup works as you desire/describe, so I don't think there's a design issue. If you disagree, please let us know.\r\n\r\n(note: it's likely that the `frames_processed` event will be replaced with a number of more specific events like `acks_processed`, see #85)",
          "createdAt": "2021-04-23T07:53:24Z",
          "updatedAt": "2021-04-23T07:54:17Z"
        },
        {
          "author": "toidiu",
          "authorAssociation": "NONE",
          "body": "Thanks for the explanation. The intention of frame_processed makes sense but there is text that added to my confusion. There might still be a good usecase for frame_sent/recv event and I listed the pros/cons for that.\r\n\r\n> Note: in some implementations, it can be difficult to log frames\r\n   directly, even when using packet_sent and packet_received events.\r\n   For these cases, this event also contains the direct packet_number\r\n   field, which can be used to more explicitly link this event to the\r\n   packet_sent/received events.\r\n\r\n**note and packet_number confusion**\r\nThe quote from the draft specifically calls out sending and receiving and how the packet_number can be used to link the event to the packet event.\r\n\r\nIf this event is meant for processing of received events, as you described, then it might be good to call that out explicitly and remove the packet_sent part.\r\n \r\n**difficulty in logging frames in packet event**\r\nThe quote describes our use case pretty well (difficult to log frames directly, even when using packet_sent and packet_received events). So we plan to emit the packet event with sparse info and another event which captures the frame info. Given that I see two options:\r\n\r\n- using packet_sent/recv\r\n  - pros: this will allow us to reuse the event.\r\n  - cons: low granularity of the logs. There is more data in a frame_event vs a packet_event. Customers only wishing to consume packet_events will need to do their own parsing or opt into both events; this can be noisy/cumbersome. \r\n- adding and using new frame_sent/recv\r\n  - pros: this will allow users to easily consume packet_events vs frame_event.\r\n  - cons: more events and possibly duplication.\r\n",
          "createdAt": "2021-04-23T19:07:25Z",
          "updatedAt": "2021-04-23T19:14:34Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thank you for the additional information. I now understand the root of your issue (I think) and agree that there's a semantic mismatch (at minimum in the use of the verb \"processed\" vs parsed/created).\r\n\r\nI also understand the arguments for separate frame_* events, but I'm unsure if it's still possible to make such a change. The packet_* events are at the core of qlog and implemented by all stacks that do qlog (that I know of). All the tooling also utilizes this. Splitting this up by default would mean lots of code churn (one of the reasons we added a separate `frames_processed` in the first place). \r\n\r\nAm I correct in understanding you have a concrete need for this split in your own stack (i.e., it's difficult to emit everything in `packet_sent/received` and you really _need_ separate events?) or this this mainly a theoretical exercise? In the first case, could you provide a few more details on how/why it works that way? Thanks!\r\n",
          "createdAt": "2021-04-26T09:37:30Z",
          "updatedAt": "2021-04-26T09:37:30Z"
        },
        {
          "author": "toidiu",
          "authorAssociation": "NONE",
          "body": "> All the tooling also utilizes this. Splitting this up by default would mean lots of code churn (one of the reasons we added a separate frames_processed in the first place).\r\n\r\nI wanted to make sure we were on the same page. I was suggesting that we keep the `frames` field in the packet_* events and introduce frame_* events. This might introduce duplication but also not break existing tooling.\r\n\r\nWe do have a need for this in our stack. Emitting the packet_* with the `frames` info would force us to have extra allocation; which we need to avoid in a networking library (QUIC). \r\n\r\n---\r\n\r\nIf its not possible to add frame_*:\r\n\r\nThe alternative is that we emit the `packet_*` with just the packet related info and then later on emit another `packet_*` with frames related info. However, I do wonder if qlog tools are flexible enough to expect this behavior and match the 'separated' packet events?\r\n\r\nThis still doesn't address easy filtering of packet vs frame events, so we would likely add a custom field to indicate and filter that easily.\r\n\r\n---\r\n\r\nAside:\r\nI am not familiar with the existing tooling and how easy/difficult they would be to update, but I wonder if there is a way to mark fields as deprecated so that new tools opt into the preferred usage (streamline and remove duplication).\r\n\r\nI also wonder if breaking tools might be acceptable since this is still in draft. But I am new here so defer the decision to you and others; also thats is a much larger conversation.",
          "createdAt": "2021-04-26T19:57:07Z",
          "updatedAt": "2021-04-26T19:59:07Z"
        },
        {
          "author": "toidiu",
          "authorAssociation": "NONE",
          "body": "Hi, wanted to make sure someone saw the above comment. \r\n\r\nWould be good to know which way the draft design will lean so that we can remain compatible.",
          "createdAt": "2021-05-03T18:50:27Z",
          "updatedAt": "2021-05-03T18:50:59Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Hey toidiu,\r\n\r\nThanks for following up. I did see your previous post, and thanks for confirming this is an issue in your stack.\r\n\r\nAt this point, we are preparing for adoption of the qlog drafts in the IETF QUIC working group, where one of the discussions to be had is indeed the amount and fine-grainedness of events. Your input will be useful then. However, at this time, I cannot guarantee new frame_* events will be added, nor that they won't... It's safe to say they won't be added anytime soon though. \r\n\r\nFor now, I'd say the best approach is to log two `packet_*` events then (as those should be easy to merge automatically by tooling). \r\n\r\nAt this point, there isn't all that much (public/open-source) tooling that I'm aware of. The biggest toolsuite is qvis (https://github.com/quiclog/qvis), which is incidentally also maintained by myself. I can say that currently logging separate `packet_*` events for the same packet (one with, one without frames) won't auto-merge the two in qvis (and I don't expect any other tooling to do this atm). Conceptually this is something I could add, but all that would do is choose either the first or the last and pretend that's the only event in there, loosing timing info (though maybe that's enough for what you need atm?). If that's a needed workaround for you at this time, let me know at https://github.com/quiclog/qvis/issues and I'll add that. \r\n\r\nIn general, I don't worry too much about breaking tooling at this point (since we're still in draft), but I'm not at all certain `frame_*` events will ever be added and re-writing tools to deal with them **properly** would be too much work at the moment (As a quick hack, I would support them by merging them with `packet_*` events, just as I would do when not using separate `frame_*` events).\r\n\r\nI hope that answers your questions. If not, feel free to let us know!  \r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2021-05-03T19:34:26Z",
          "updatedAt": "2021-05-03T19:34:26Z"
        },
        {
          "author": "toidiu",
          "authorAssociation": "NONE",
          "body": "> For now, I'd say the best approach is to log two packet_* events then (as those should be easy to merge automatically by tooling). \r\n\r\nThanks @rmarx for the reply on how to proceed. Your reasoning makes sense in light of upcoming adoption and the unknowns. \r\n\r\nPlease feel free to close the issue.\r\n\r\n",
          "createdAt": "2021-05-04T04:48:50Z",
          "updatedAt": "2021-05-04T04:48:50Z"
        }
      ]
    },
    {
      "number": 156,
      "id": "MDU6SXNzdWU4OTI1MTg4NzE=",
      "title": "Discuss versioning",
      "url": "https://github.com/quicwg/qlog/issues/156",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "high-level-schema",
        "current-version",
        "discuss"
      ],
      "body": "Currently, we have only a single version field in `qlog_version`. This is somewhat inflexible, as it for example doesn't allow indicating updated versions of event definitions for individual protocols (say we have main schema version 2, but HTTP/3's events are already at 5, while you can also use 2, 3 and 4 with main schema 2).\r\n\r\nI'm not entirely sure we need to go very fine-grained in this (e.g., indicating for each event which version it belongs to seems overkill), but a more advanced scheme than what we have currently is probably needed.\r\n\r\nOriginal remark from @lpardue:\r\n\r\n> Do we also need independent versioning of the different schema? How does qlog evolve over the years? For example, say the main schema got published as 1.0, and then work commenced on 2.0. Can there be a QUIC qlog event definitions 1.1 (which is updated say to support QUIC v2) and a 2.1 (which is updated to support QUIC v2 and a new main schema format)?\r\n",
      "createdAt": "2021-05-15T19:17:44Z",
      "updatedAt": "2021-08-18T13:48:04Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 157,
      "id": "MDU6SXNzdWU5MTAyMTI3NTE=",
      "title": "PCAPML and metadata integration in general",
      "url": "https://github.com/quicwg/qlog/issues/157",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "high-level-schema",
        "future-versions"
      ],
      "body": "I recently came across this interesting project that tags traffic in pcaps for Machine Learning purposes: https://github.com/nprint/pcapml\r\n\r\nThis general concept of keeping traffic traces and metadata describing that data in the same file is one of the things I had envisioned for qlog at the start as well (i.e., combining traces into a single file, the `configuration` field, the ability to add new fields to events at will, etc.). This goal has diminished somewhat over time, but I'm still a big proponent of it.\r\n\r\nI feel we should take a look at PCAPML to see how they're approaching this and decide if similar setups should be *possible* in qlog (though probably not part of the core spec). ",
      "createdAt": "2021-06-03T07:43:30Z",
      "updatedAt": "2021-08-18T13:48:27Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 158,
      "id": "MDU6SXNzdWU5MjcyMjUzNTA=",
      "title": "What is the media-type?",
      "url": "https://github.com/quicwg/qlog/issues/158",
      "state": "OPEN",
      "author": "kazuho",
      "authorAssociation": "MEMBER",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "design",
        "high-level-schema",
        "current-version"
      ],
      "body": "What is the [media-type](https://www.iana.org/assignments/media-types/media-types.xhtml) of the qlog files?",
      "createdAt": "2021-06-22T13:18:18Z",
      "updatedAt": "2021-08-18T13:48:56Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This is currently not yet defined...\r\n\r\nAt first instinct, I'd say `application/qlog+json`, but I'm not sure how we'd indicate the difference between normal JSON and newline-delimited JSON (if we even decide to keep that). Maybe `application/qlog+ndjson` and then something like `application/qlog+cbor` down the line?\r\n\r\nNot sure how easy/difficult that would be to deal with for qlog tooling / how media-type parsers typically deal with this type of thing. ",
          "createdAt": "2021-06-22T13:28:46Z",
          "updatedAt": "2021-06-22T13:28:46Z"
        },
        {
          "author": "kazuho",
          "authorAssociation": "MEMBER",
          "body": "Thank you for the response.\r\n\r\nFor context, the reason I asked is because h2o has a well-known URI for serving traces, see https://mailarchive.ietf.org/arch/msg/quic/VHyaEIHxYylfg5NAKBxccycqnvc/.\r\n\r\nAt the moment, we use a custom ndjson format, but if we are to use qlog, there has to be a media-type.",
          "createdAt": "2021-08-13T06:42:12Z",
          "updatedAt": "2021-08-13T06:42:12Z"
        }
      ]
    },
    {
      "number": 159,
      "id": "MDU6SXNzdWU5MzM5Mjg3MjA=",
      "title": "Consider renaming HTTP/3 \"frame_type\" to \"type\"",
      "url": "https://github.com/quicwg/qlog/issues/159",
      "state": "CLOSED",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version",
        "discuss"
      ],
      "body": "If I understand the schema correctly, I would produce something like this\r\n\r\n```\r\n[\"42.797\",\"http\",\"frame_created\",{\"stream_id\":\"12345\",\"frame\":{\"frame_type\":\"data\"},\"length\":\"6789\"}]\r\n```\r\n\r\nsince `frame_type` is a property of the `frame` object, it seems redundant. Can we just use `type` instead?",
      "createdAt": "2021-06-30T17:16:43Z",
      "updatedAt": "2021-08-18T14:47:33Z",
      "closedAt": "2021-08-18T14:47:33Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "We used to have just `type` or `id` for all similar fields, then (I think when moving to -02 or slightly before) I changed everything to have a more declarative name to make fields less reliant on context. \r\n\r\nYou could argue this is not needed for `frame_type` because it is indeed encapsulated in a top-level `frame` field, while it **is** still needed for `stream_id` because that's not immediately clear. Still, I personally somewhat prefer consistency here myself.\r\n\r\nWhat would be your main argument for not keeping `frame_type`? ",
          "createdAt": "2021-07-01T09:01:44Z",
          "updatedAt": "2021-07-01T09:01:44Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Ping @LPardue ",
          "createdAt": "2021-08-18T13:49:29Z",
          "updatedAt": "2021-08-18T13:49:29Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "I can live without this change, lets close it",
          "createdAt": "2021-08-18T14:18:52Z",
          "updatedAt": "2021-08-18T14:18:52Z"
        }
      ]
    },
    {
      "number": 160,
      "id": "MDU6SXNzdWU5MzQwNDIwNzk=",
      "title": "GoAway contains a \"stream_id\" field",
      "url": "https://github.com/quicwg/qlog/issues/160",
      "state": "CLOSED",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "https://quicwg.org/qlog/draft-ietf-quic-qlog-h3-events.html#section-a.1.6\r\n\r\nWhen this became usable by clients, the ID changed to also apply to pushes. Suggest the field name \"id\" instead.",
      "createdAt": "2021-06-30T19:20:04Z",
      "updatedAt": "2021-07-01T12:48:29Z",
      "closedAt": "2021-07-01T12:48:29Z",
      "comments": []
    },
    {
      "number": 163,
      "id": "MDU6SXNzdWU5Mzc0OTkyMTA=",
      "title": "Aggregating stream_frame",
      "url": "https://github.com/quicwg/qlog/issues/163",
      "state": "OPEN",
      "author": "incfex",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [
        "quic-http3-fields",
        "future-versions"
      ],
      "body": "I am currently implementing qlog for video streaming using quiche.\r\nDue to the nature of video streaming, there are a lot of back and forth of `STREAM` and `ACK` frames, and they are not very useful to log.\r\nFrom the `server` vantage point, `ACK`s can be aggregated by either `packets_acked` or `frames_processed` event. However, I did not find a way to aggregate `STREAM` frames the server send out. Is there a good way to solve this problem?",
      "createdAt": "2021-07-06T04:06:03Z",
      "updatedAt": "2021-08-18T13:49:44Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Hello @incfex,\r\n\r\nThanks for opening an issue. \r\n\r\nIIUC, you're basically asking for a `frames_created` event, in which you would aggregate ACK and STREAM frames that are sent over multiple packets into a single event. Is that correct? This is indeed something we currently don't have, but that I feel would be logical to add. \r\n\r\nFor the ACK-frame special case, maybe we can add an endpoint discriminator to `packets_acked` so it can be re-used when either sending/receiving (though this kind of depends on how uniformly we end up doing qlog events down the line: it might make more sense to add that to `frames_processed` too and rename it to `frames_info` or something). \r\n\r\nexample (though not very happy with the semantics of \"owner\" here):\r\n```\r\npackets_acked {\r\n  owner?:\"local\"|\"remote\",\r\n\r\n  packet_number_space?:PacketNumberSpace,\r\n  packet_numbers?:Array<uint64>\r\n}\r\n```\r\n\r\nI am however a bit confused by your motivation saying \r\n> there are a lot of back and forth of STREAM and ACK frames, and they are not very useful to log.\r\n\r\naren't you still logging them all in the `frames_processed` (or potential `frames_created`)? or how does your approach make that specifically better than using `packet_sent` and `packet_received`? Do you mean you don't want to log the packet info and just the frame details? or are you logging select ACKs/STREAM frames (but how do you decide which to log then?)? or is there something else going on?",
          "createdAt": "2021-07-09T08:36:47Z",
          "updatedAt": "2021-07-09T08:36:47Z"
        },
        {
          "author": "incfex",
          "authorAssociation": "NONE",
          "body": "Sorry for the confusion, my current situation is: on the SERVER side, it is sending a lot of STREAM frames and receiving similar amount of ACK frames.\r\n> IIUC, you're basically asking for a frames_created event, in which you would aggregate ACK and STREAM frames that are sent over multiple packets into a single event.\r\n\r\n\r\nThis is basically what I am asking for, but only log ACK or STREAM frames, and with a little twist.\r\n\r\nQlog currently requires STREAM frame to have `frame_type` and `stream_id` field. In my case when I am logging every `packet_sent`, each of `packet_sent` only have a single stream frame in it. There are usually 50 consecutive `packet_sent` events like this. Thus, I am purposing a `frames_created` event with `default_frame` field inside. When frames in the array did not specify their `frame_type`, we could assume that they have the same field values with the default.\r\n\r\npurposed `frames_created` example:\r\n```\r\nframes_created {\r\n  default_frame?:QuicFrame,\r\n  frames?:Array<QuicFrame>,\r\n  packet_numbers?:Array<uint64>\r\n}\r\n```\r\n\r\n\r\ncurrent example of logging all the STREAM frames with `packet_sent`(json format): \r\n```\r\n{\r\n  \"events\": [\r\n    {\r\n      \"time\": \"1\",\r\n      \"name\": \"transport:packet_sent\",\r\n      \"frames\": [\r\n        {\r\n          \"fin\": false,\r\n          \"frame_type\": \"stream\",\r\n          \"length\": 1000,\r\n          \"offset\": 2000,\r\n          \"stream_id\": 0\r\n        }\r\n      ],\r\n      \"header\": {\r\n        \"packet_number\": 3,\r\n        \"packet_size\": 1024\r\n      },\r\n      \"packet_type\": \"1RTT\",\r\n      \"transmission_type\": \"not_retransmission\"\r\n    },\r\n    {\r\n      \"time\": \"100\",\r\n      \"name\": \"transport:packet_sent\",\r\n      \"frames\": [\r\n        {\r\n          \"fin\": false,\r\n          \"frame_type\": \"stream\",\r\n          \"length\": 1000,\r\n          \"offset\": 3000,\r\n          \"stream_id\": 0\r\n        }\r\n      ],\r\n      \"header\": {\r\n        \"packet_number\": 4,\r\n        \"packet_size\": 1024\r\n      },\r\n      \"packet_type\": \"1RTT\",\r\n      \"transmission_type\": \"not_retransmission\"\r\n    },\r\n    {\r\n      \"time\": \"200\",\r\n      \"name\": \"transport:packet_sent\",\r\n      \"frames\": [\r\n        {\r\n          \"fin\": false,\r\n          \"frame_type\": \"stream\",\r\n          \"length\": 500,\r\n          \"offset\": 4000,\r\n          \"stream_id\": 0\r\n        }\r\n      ],\r\n      \"header\": {\r\n        \"packet_number\": 5,\r\n        \"packet_size\": 524\r\n      },\r\n      \"packet_type\": \"1RTT\",\r\n      \"transmission_type\": \"not_retransmission\"\r\n    }\r\n  ]\r\n}, \r\n...\r\n```\r\n\r\nExample of logging with the `frames_created` event:\r\n```\r\n{\r\n  \"events\":[\r\n    {\r\n      \"time\":\"1\",\r\n      \"name\":\"transport:packet_sent\",\r\n      \"data\":{\r\n        \"default_frame\":{\r\n          \"frame_type\":\"stream\",\r\n          \"stream_id\":0,\r\n          \"length\": 1000\r\n        },\r\n        \"frames\":[\r\n          {\"offset\": 2000},\r\n          {\"offset\": 3000},\r\n          {\"offset\": 4000, \"length\": 500}],\r\n        \"packet_number\": [3, 4, 5]\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nThis approach could also applies to ACK frames, becomes a dumb version of `packets_acked` event that does not care repeated ACKs.\r\n\r\nWhat do you think of this?\r\n",
          "createdAt": "2021-07-12T07:49:43Z",
          "updatedAt": "2021-07-12T07:49:43Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thanks for the additional information, that's much clearer now. \r\n\r\nWhile I agree with the use case for a `frames_created` event, I'm quite skeptical about the proposed design, primarily the `default_frame` setup. I'm having a hard time imagining many implementers wanting to use it like that in a general-purpose setup.\r\n\r\nFor example, you'd have to check if per-frame values deviate from the default, and you'd have to keep multiple of these events \"alive\"/buffered, 1 for each frame type you might care about (and demux frame data to the correct one). It would also require some quite more advanced logic in tools. I feel that would work in your specialized use case (only STREAM/ACK, many similar frame instances), but IMO that's not what should be **standardized**: this would be better suited for a \"custom\", application-specific qlog event, which is perfectly allowed by the spec as well. \r\n\r\nThis is partly because IIUC, one of the main reasons to do this is to reduce log verbosity. qlog has a long history of trying different ways to combat this (e.g., a convoluted csv-alike setup in draft-01 with columns). For draft-02, we took the decision to care less about (textual) verbosity/repetition, since this can be dealt with using either compression or a binary serialization format (see #30 for some earlier discussion and #144 for the current issue on this). I think moving from pure `packet_sent` to a general `frames_created` (where you still log each frame (in-full), without `default_frame`) already helps a lot in this regard. Going further should imo be application-specific. \r\n\r\nSo what I'd propose is add something like this:\r\n```\r\nframes_created : \r\n{\r\n       frames:Array<QuicFrame>,\r\n\r\n       packet_numbers?:Array<uint64>\r\n}\r\n```\r\n\r\nI think probably @marten-seemann also has some opinions on this. ",
          "createdAt": "2021-07-12T14:52:29Z",
          "updatedAt": "2021-07-12T14:52:29Z"
        },
        {
          "author": "incfex",
          "authorAssociation": "NONE",
          "body": "Thanks for your response!\r\n\r\nI agree that this would advanced logic in tools to achieve `default_frame`. My original intend is to only apply this field to STREAM/ACK frames, since they are the most likely ones to appear consecutivly. Also only maintain/buffer 1 `frames_created` for both frame types. As long as the next frame is different from the `default_frame` maintained, current `frames_created` will be concluded and a new one will be created. This way, we do not have to buffer multiple of these events.\r\n\r\n> I'm having a hard time imagining many implementers wanting to use it like that in a general-purpose setup.\r\n\r\nAbout this, if a website have video playback or file download, it will have bulk consecutive STREAM/ACK frames. Having a video on the website is not that uncommon this days.\r\n\r\nMaybe change the `default_frame` to `common_frame_type`, and only declare the `frame_type:string` inside it would reduce the amount of advance logic, whilst saving space to store the qlog.",
          "createdAt": "2021-07-13T03:11:15Z",
          "updatedAt": "2021-07-13T03:11:15Z"
        },
        {
          "author": "incfex",
          "authorAssociation": "NONE",
          "body": "After applying `frames_created` and `frames_processed` to only consecutive STREAM and ACK frames, I have observed 70~80% space save in the final qlog. These event types prove to be very useful in the situation where large objects are transferred (e.g. streaming, downloading).",
          "createdAt": "2021-08-05T07:14:19Z",
          "updatedAt": "2021-08-05T07:14:19Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Hello @incfex,\r\n\r\nThanks for keeping us updated on this. \r\n\r\nIIUC, you have now created a custom `frames_created` event that makes use of your proposed `default_frame` field, right? And that approach saves you 70 to 80% of qlog size. Would it be possible to upload an example of such a resulting file here so I can better interpret what exactly you're doing?\r\n\r\nDuring the [recent discussion on this at the IETF](https://youtu.be/R7q8cWIAIDQ?t=3267), I proposed **not** adding events like `frames_created` to qlog to keep the qlog spec more straightforward. In order to reduce qlog size, I argued that 1) it doesn't matter -that- much in practice (some large deployments like Facebook use verbose JSON directly) and 2) it can largely be solved using (on-the-fly/streaming) compression (see also #30). \r\n\r\nAs such, it would help me to get some insight into your specific use case and the reasons why keeping qlog size down (if that is indeed the main motivation) is crucial to your setup and why that's difficult to achieve by using compression instead. I'm not arguing having additional size optimizations would be useless, but I am debating if the complexity of adding these events to the qlog **standard** are worth their benefits.\r\n\r\nRelatedly, I wonder how you are using the logged information concretely. No longer having specific timestamps and packet associations for individual ACKs/STREAM frames reduces debuggability in some ways. How are you currently processing the qlogs in practice to e.g., find bugs/inefficiencies or how do you plan to do so? \r\n\r\nThank you in advance for this additional insight!\r\n",
          "createdAt": "2021-08-17T14:56:50Z",
          "updatedAt": "2021-08-17T14:56:50Z"
        },
        {
          "author": "incfex",
          "authorAssociation": "NONE",
          "body": "> IIUC, you have now created a custom frames_created event that makes use of your proposed default_frame field, right? And that approach saves you 70 to 80% of qlog size. Would it be possible to upload an example of such a resulting file here so I can better interpret what exactly you're doing?\r\n\r\nAbsolutely, here is the qlog format we are currently using.\r\n[f576620f4936d820.qlog.zip](https://github.com/quicwg/qlog/files/7004174/f576620f4936d820.qlog.zip)\r\nThis is a fork to the Facebook's mvfst implementation, and still a work in progress. Since we are only logging on the server-side, it is only aggregating outgoing STREAM and incoming ACK frames. You might be noticing repeated \"packetNums\" for ACK, that is for the PADDING frame attached to the ACK frames.\r\n\r\n> During the recent discussion on this at the IETF, I proposed not adding events like frames_created to qlog to keep the qlog spec more straightforward. In order to reduce qlog size, I argued that 1) it doesn't matter -that- much in practice (some large deployments like Facebook use verbose JSON directly) and 2) it can largely be solved using (on-the-fly/streaming) compression (see also #30).\r\n\r\nI have watched that session and learnt a lot from that. I now agrees with that if we are trying to make qlog a logging format, sticking to the wire-format is the way. However, writing qlog is hammering on our disk IO, increasing the IO latency and thus lowered our bandwidth. Also, our QUIC server works in edge computing, the disk space to store and bandwidth to transfer qlog cost a lot, so we cannot use verbose JSON directly. (on-the-fly/streaming) does help, and we are using it now to further reducing the size of our qlog.\r\n\r\n> As such, it would help me to get some insight into your specific use case and the reasons why keeping qlog size down (if that is indeed the main motivation) is crucial to your setup and why that's difficult to achieve by using compression instead. I'm not arguing having additional size optimizations would be useless, but I am debating if the complexity of adding these events to the qlog standard are worth their benefits.\r\n\r\nReasons as explained before:\r\n1. high cost to store and transfer the qlog.\r\n2. writing un-aggregated qlog impacts our disk IO, caused lower network bandwidth.\r\n3. compression is used with aggregated qlog.\r\n\r\nOur current observation is that if you try to implement qlog on the machine that running quic fine right now might cause performance impact. And to mitigate this, you have to increase the budget. \r\n\r\n> Relatedly, I wonder how you are using the logged information concretely. No longer having specific timestamps and packet associations for individual ACKs/STREAM frames reduces debuggability in some ways. How are you currently processing the qlogs in practice to e.g., find bugs/inefficiencies or how do you plan to do so?\r\n\r\nWe are just starting to use qlog, and trying to see what we could use it for. Specific timestamps can be added using time delta just like other events. Currently we have a parser that parse our aggregated qlog back into standard qlog.\r\n\r\nThere might be some place I did not explain clearly, if you have any question, just shoot it. This also helps us a lot.\r\n",
          "createdAt": "2021-08-18T03:39:24Z",
          "updatedAt": "2021-08-18T03:39:24Z"
        }
      ]
    },
    {
      "number": 164,
      "id": "MDU6SXNzdWU5MzgxMDIyNDk=",
      "title": "units of src_port, dst_port, minimum_congestion_window",
      "url": "https://github.com/quicwg/qlog/issues/164",
      "state": "OPEN",
      "author": "junhochoi",
      "authorAssociation": "NONE",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "While I read the some of the event definitions, I have some questions:\r\n\r\nhttps://github.com/quicwg/qlog/blob/main/draft-ietf-quic-qlog-quic-events.md#L312\r\n\r\n```\r\n    src_port?: uint32,\r\n    dst_port?: uint32,\r\n```\r\n`uint16` for udp port numbers (https://datatracker.ietf.org/doc/html/rfc768) looks good enough.\r\n\r\nhttps://github.com/quicwg/qlog/blob/main/draft-ietf-quic-qlog-quic-events.md#L1106\r\n\r\n```\r\n    initial_congestion_window?:uint64, // in bytes\r\n    minimum_congestion_window?:uint32, // in bytes // Note: this could change when max_datagram_size changes\r\n```\r\n\r\nSince both are congestion window values, using `uint64` for both makes sense to me.\r\n\r\n",
      "createdAt": "2021-07-06T17:14:31Z",
      "updatedAt": "2021-08-18T13:50:06Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Hello Junho,\r\n\r\nThanks for opening the issue. \r\n\r\n`uint16` for UDP ports seems sensible.\r\n\r\nNot sure if we need `uint64` at all for congestion windows though... I'd rather think that using `uint32` for the initial cwnd would be better? (or are there systems doing +4GB bursts on new connections somewhere? :P)\r\n",
          "createdAt": "2021-07-09T09:39:17Z",
          "updatedAt": "2021-07-09T09:39:17Z"
        },
        {
          "author": "junhochoi",
          "authorAssociation": "NONE",
          "body": "`congestion_window` is also `uint64`, so I just think that `initial_congestion_window` and `minimal_congestion_window` need to be a same type. In practice it will fit into 32bit (10 x mss and 2 x mss, respectively), but no need to assign a different type for them only because they are small?",
          "createdAt": "2021-07-09T18:12:49Z",
          "updatedAt": "2021-07-09T18:12:49Z"
        }
      ]
    },
    {
      "number": 165,
      "id": "MDU6SXNzdWU5NDE0NDg1ODc=",
      "title": "Some JSON serialization examples are examples of broken JSON",
      "url": "https://github.com/quicwg/qlog/issues/165",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "In the main logging schema, about half of the `JSON serialization` examples don't encapsulate field names in double quotes. So passing these verbatim into a parser will yield errors. ",
      "createdAt": "2021-07-11T13:03:10Z",
      "updatedAt": "2021-08-18T13:50:26Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 166,
      "id": "MDU6SXNzdWU5NDE0NTQ3MjY=",
      "title": "Inconsistencies when talking about the \"trigger\" field",
      "url": "https://github.com/quicwg/qlog/issues/166",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [
        "editorial",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "Across the qlog docs, the text seems inconsistent when it mentions the \"trigger\" field, and whether that is a property of Event of Event:Data. For example\r\n\r\n```\r\nFor each event type, its importance and data definition is laid out, often accompanied by possible values for the optional \"trigger\" field.\r\n```\r\n\r\nIIUC, \"trigger\" is supposed to be only defined for Event:Data that cares to define it. It would help to sweep the docs to ensure consistency in this area.",
      "createdAt": "2021-07-11T13:36:36Z",
      "updatedAt": "2022-02-18T14:20:58Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Current plan is to address this by including triggers directly in the event data definition instead of separately.\r\n\r\nSee https://github.com/quiclog/qlog/tree/master/CDDL/schema#triggers. ",
          "createdAt": "2022-02-18T14:20:58Z",
          "updatedAt": "2022-02-18T14:20:58Z"
        }
      ]
    },
    {
      "number": 167,
      "id": "MDU6SXNzdWU5NDE0NTcwODE=",
      "title": "Qlog events section-3.1.7 diagram is misformatted",
      "url": "https://github.com/quicwg/qlog/issues/167",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "Looks like it is showing the markdown rather than getting rendered as a diagram.",
      "createdAt": "2021-07-11T13:49:33Z",
      "updatedAt": "2021-08-18T13:52:30Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 168,
      "id": "MDU6SXNzdWU5NDIxNDgyNTc=",
      "title": "Allow multiple packet_numbers in frames_processed",
      "url": "https://github.com/quicwg/qlog/issues/168",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "Currently, `frames_processed` only allows indicating a single packet_number.\r\n\r\nHowever, discussion in #163 has shown that you might want to aggregate frames across multiple packets for some use cases, so it makes sense to make this into an `Array<uint64>` instead. ",
      "createdAt": "2021-07-12T14:54:16Z",
      "updatedAt": "2021-08-18T13:53:00Z",
      "closedAt": null,
      "comments": [
        {
          "author": "incfex",
          "authorAssociation": "NONE",
          "body": "About this structure\r\n```\r\nframes_processed : \r\n{\r\n       frames:Array<QuicFrame>,\r\n       packet_numbers?:Array<uint64>\r\n}\r\n```\r\nHow do we log the packet_numbers when we have multiple frames in one packet? My suggestion is we log them one to one.\r\n\r\nExample (suppose fr1 and fr2 are in the same packet):\r\n```\r\n{\r\n       frames:[fr1, fr2, fr3, fr4],\r\n       packet_number:[1, 1, 2, 3]\r\n}\r\n```\r\n\r\nThis way we don't have to do any search when the packets arrive out of order.\r\n",
          "createdAt": "2021-07-14T03:10:19Z",
          "updatedAt": "2021-07-14T03:10:19Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Good point and your suggestion seems sensible :) ",
          "createdAt": "2021-07-14T13:15:27Z",
          "updatedAt": "2021-07-14T13:15:27Z"
        }
      ]
    },
    {
      "number": 169,
      "id": "MDU6SXNzdWU5NTE0MTQ5NzQ=",
      "title": "Bad code block formatting for some events",
      "url": "https://github.com/quicwg/qlog/issues/169",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "Some events, like connection_state_updated and packets_acked don't have properly rendered \"data\" fields because there is no empty line between the \"Data:\" text and the start of the code block indicator \"~~~\".\r\n\r\nThis causes the code to be treated as a normal, contiguous text block",
      "createdAt": "2021-07-23T09:37:12Z",
      "updatedAt": "2021-08-18T13:53:16Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 170,
      "id": "MDU6SXNzdWU5NTE0MjEyMDY=",
      "title": "Discuss how to approach extensions short term",
      "url": "https://github.com/quicwg/qlog/issues/170",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "current-version",
        "discuss"
      ],
      "body": "With several extensions to QUIC and HTTP/3 being developed, we should have some way of defining qlog events for them.\r\n\r\nGiven that most of these extensions are not RFC's in their own right, it doesn't make much sense to add them to the main documents at this time (or ever). \r\n\r\nConcrete examples:\r\n- WebTransport having new stream types that impact the existing H3 `stream_type_set` event\r\n- DATAGRAM and CAPSULE frames that should be defined\r\n- CONNECT-UDP related metadata etc. \r\n\r\nProposal:\r\n- Specify qlog events for these in separate documents **in a separate repository** (potentially a new aggregate one at https://github.com/quiclog? Assuming people won't want to make separate docs themselves).\r\n\r\nLong term, we need a proper way to do this, but for now I think something like this might suffice.\r\n\r\ncc @LPardue  \r\n",
      "createdAt": "2021-07-23T09:44:32Z",
      "updatedAt": "2021-08-18T13:37:51Z",
      "closedAt": null,
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "So I don't think we need to concern the current QUIC WG qlog docs with work being done outside the group.\r\n\r\nI do think we should probably accommodate QUIC DATAGRAMS in the qlog schema (because that draft will be done before qlog). \r\n\r\nH3 DATAGRAMS and Capsules should be out of scope here. We could entertain the idea of defining them as part of the h3 datagram spec itself, but with the open questions about schema format etc that's probably not really feasible.",
          "createdAt": "2021-07-23T10:08:18Z",
          "updatedAt": "2021-07-23T10:08:18Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Related to #124 ",
          "createdAt": "2021-08-18T10:18:57Z",
          "updatedAt": "2021-08-18T10:18:57Z"
        }
      ]
    },
    {
      "number": 171,
      "id": "MDU6SXNzdWU5NTE0MzEwOTQ=",
      "title": "packet_number should not be required for vneg/retry packets",
      "url": "https://github.com/quicwg/qlog/issues/171",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "Currently, the PacketHeader struct makes the `packet_number` field required.\r\n\r\nWe must add a comment that this is only true if `packet_type` is not version negotiation or retry (similar to how we define other optional fields there).\r\n\r\ncc @jlaine ",
      "createdAt": "2021-07-23T09:58:41Z",
      "updatedAt": "2021-08-18T13:53:31Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 172,
      "id": "MDU6SXNzdWU5NTgzNzQ5NjA=",
      "title": "Decide if streaming serialization needs to be defined",
      "url": "https://github.com/quicwg/qlog/issues/172",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "design",
        "high-level-schema",
        "current-version"
      ],
      "body": "The document includes considerations about streaming serialization and specifies a way to do this using NDJSON (new-line delimited JSON).\r\n\r\nThere's two things that the Working Group should consider:\r\n\r\n1) Does streaming serialization need to be defined as part of the qlog main schema?\r\n2) If the answer to 1 is yes, what format should be used.\r\n\r\nDuring IETF 111, it was noted that https://datatracker.ietf.org/doc/html/rfc7464 is an IETF-defined format that achieves similar streaming properties as NDJSON.  There might be a preference for using RFC 7464 pending the outcome of #144.",
      "createdAt": "2021-08-02T17:50:26Z",
      "updatedAt": "2021-10-25T12:07:00Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "As discussed previously, I have now experimented with the \"JSON text sequences\" format described in https://datatracker.ietf.org/doc/html/rfc7464. \r\n\r\nWhile it is a bit annoying to have to add the RecordSeparator (RS, %x1E, U+001E) character before each event, in practice it was easy enough to integrate the new format with tools like [qvis ](https://github.com/quiclog/qvis/commit/9eaf25b67fa7a5128874f1e0dc3f1f623908439a)and use it with existing tools like jq, grep, sed and awk. \r\n\r\nAs such, we propose to indeed replace the NDJSON format in draft-00 with the RFC 7464 format. This has several advantages, among which: \r\n1. having an existing RFC to refer to instead of having to define the format in qlog itself (since NDJSON is not an official standard anywhere)\r\n2. having an existing mime-type `application/json-seq`  (see also #158)\r\n3. supporting \"pretty printed\" JSON (records/events can span multiple lines), while NDJSON does not support \\n characters in an event\r\n\r\nI will create a PR to make this change in the text. Below are some example files and practical guidelines for those who wish to start experimenting with this themselves. cc @marten-seemann \r\n\r\n------------\r\n\r\n[This zip file](https://github.com/quicwg/qlog/files/7374539/json-seq.zip) contains 2 files in both NDJSON, line-based json-seq and pretty-printed json-seq formats. \r\n\r\nThese were generated by taking quic-go NDJSON outputs from https://interop.seemann.io and then adding the RecordSeparator character to them using the following sed monstrosity: \r\n\r\n```\r\n# adapted from https://blog.jpalardy.com/posts/handling-broken-json-with-jq/#an-example\r\n\r\ncat ndjsoninput1.qlog | sed -e 's/^{/'$(printf \"\\x1e\")'{/' -e '$a\\\\n' | jq -c --seq . > textseqoutput1.qlog\r\n\r\n# NOTE: if the last record isn't properly closed with a LineFeed \\n, then jq will SILENTLY drop the final event in the file...\r\n# this is why we add the  -e '$a\\\\n'  command, which selects the final line with $, enters append mode with a, and then adds \\n\r\n# if we have too many \\n's, they are discarded, so this is safe\r\n\r\n# jq -c is used to pretty-print the output. If that's not needed, the jq command can be left out. \r\n```\r\n\r\nI then also changed the \"qlog-format\" field on the first line to \"JSON-SEQ\" (instead of \"NDJSON\"). That should be enough to get the files to load in qvis (\"qlog-version\" is currently still \"draft-02\", we'll probably want to change that for the upcoming ietf-draft-01).\r\n\r\nOf course, implementations that output the new format should just output the \\x1E character directly instead of post-processing the files like this... how to do that depends on the programming language of course.\r\n\r\n\r\nI then also tested the json-seq files with some common tooling, especially `jq`. `jq` has built-in support for text-sequences by passing in the option `--seq`. With the option on, `jq` should also still be able to process normal JSON and NDJSON, so it should be safe to \"leave it on\", no matter which qlog format you're processing.\r\n\r\nFor example:\r\n```\r\ncat textseqoutput1.qlog | jq --seq -c '. | select(.data.header?.packet_type? == \"handshake\")'\r\n``` \r\n\r\nFeel free to test this out yourselves and let me know if you find problems with the new format!\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2021-10-19T15:25:48Z",
          "updatedAt": "2021-10-19T15:25:48Z"
        },
        {
          "author": "kixelated",
          "authorAssociation": "NONE",
          "body": "I've been using NDJSON and I like the simplicity, but the inability to have newlines in the JSON output was a point of contention for me. The ability to add some newlines to make events more readable would be nice.\r\n\r\nThe addition of the `\\x1E` character is gross but solves the problem while using an existing IETF standard.",
          "createdAt": "2021-10-20T21:04:00Z",
          "updatedAt": "2021-10-20T21:04:00Z"
        },
        {
          "author": "kazuho",
          "authorAssociation": "MEMBER",
          "body": "My two cents would go to using NDJSON rather than JSON Text Sequences (RFC 7464), because the former is more widespread, easy to use with existing line-oriented tools, and because I do not think we need the properties being provided by RFC 7464 (e.g., process dataset in the middle, as discussed in [Section 1 of RFC 7464]{https://datatracker.ietf.org/doc/html/rfc7464#section-1}).\r\n\r\nI would not mind too strongly about switching to JSON Text Sequences, as it is possible to convert from that to NDJSON, but my preference goes to using something more widespread - that was the reason we chose JSON instead of some binary format, after all.",
          "createdAt": "2021-10-20T21:58:17Z",
          "updatedAt": "2021-10-20T21:58:17Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "As an individual: I prefer to base the streaming output on an IETF standard. Building something for general purpose tools is useful and valuable today but I would like to set up qlog to be something that integrates well into IETF paradigms in the long term.\r\n\r\nThe transformation to newline-only delimitation is trivial. If its useful, I think we can mention that without referring to NDJSON explicitly.",
          "createdAt": "2021-10-20T22:19:57Z",
          "updatedAt": "2021-10-20T22:19:57Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thanks all for the additional input. We decided to try the JSON Text Sequences for now and see how it goes (doesn't mean we can't later switch to something else if Text Sequences turn out horrible somehow). \r\n\r\nThe new approach is detailed in the new draft-01 of the main schema here: https://datatracker.ietf.org/doc/html/draft-ietf-quic-qlog-main-schema-01.\r\n\r\nFeel free to implement the new format and let us know results, remarks, feedback, etc. Thanks!",
          "createdAt": "2021-10-25T12:07:00Z",
          "updatedAt": "2021-10-25T12:07:00Z"
        }
      ]
    },
    {
      "number": 173,
      "id": "MDU6SXNzdWU5NjI4MTExMzg=",
      "title": "RawInfo doesn't play well with UDP datagram headers",
      "url": "https://github.com/quicwg/qlog/issues/173",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "Currently, we re-use the RawInfo struct to give a simple re-usable way to log raw packet/frame/datagram contents.\r\n\r\nIn the struct, we have two length-fields: the full `length` and `payload_length`, assuming the header length can be calculated from those two. \r\n\r\nHowever, we do not have a way to log e.g., only the payload without the header (we can only log the full value truncated, but not indicate it starts at the payload).\r\n\r\nThis isn't a problem for QUIC/H3 packets/frames, but as @jlaine pointed out, it is a problem for UDP datagrams. In most stacks, you don't get the pure UDP packet header and so can't log it (so you'd always start with the payload).\r\n\r\nThis can be solved in several different ways:\r\n1. disallow usage of RawInfo for datagrams\r\n2. make explicit that datagram-related events start at the payload\r\n3. log a fixed-value/fixed-size dummy UDP datagram (e.g., 8 bytes of zeroes)\r\n4. extend RawInfo to make it more flexible\r\n\r\nI'm currently most in favor of 2, as I don't see many people logging full UDP datagrams instead of logging the QUIC packets. \r\n\r\n",
      "createdAt": "2021-08-06T14:55:06Z",
      "updatedAt": "2021-08-18T13:53:51Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 174,
      "id": "MDU6SXNzdWU5NzM0ODkzNzA=",
      "title": "Editorial update to RFCs/draft-34 + rawInfo + general consistency",
      "url": "https://github.com/quicwg/qlog/issues/174",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "high-level-schema",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "since qlog started early on in the quic/H3 design process, we have some leftovers from early drafts in the docs.\r\n\r\nWe've updated most things over time as they were changed, but some aspects (e.g., most of the quic recovery events mention draft-23/27, `stream_state_updated` mentions draft-23, `packet_sent` triggers refer draft-23/19, etc.)\r\n\r\nWe need to go through each event and match it to terminology used in the final versions of the documents. \r\nFor most things, this would just require removing mentions of old drafts, but in some cases this might require further changes. \r\n\r\nFinally, many events in the quic/H3 docs incorrectly use the pre-draft-02 way of logging raw information (e.g., as bytes fields directly), instead of properly using the new `raw:RawInfo` type. This should be updated.\r\n\r\nSubsumes #46. ",
      "createdAt": "2021-08-18T09:57:41Z",
      "updatedAt": "2021-08-18T14:48:45Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Related to #113 as well.",
          "createdAt": "2021-08-18T10:12:34Z",
          "updatedAt": "2021-08-18T10:12:34Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Related to #129 ",
          "createdAt": "2021-08-18T10:20:57Z",
          "updatedAt": "2021-08-18T10:20:57Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Related to #166 ",
          "createdAt": "2021-08-18T13:51:53Z",
          "updatedAt": "2021-08-18T13:51:53Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "As discussed during the editors' meeting, it makes sense to keep this work until when we do the major pass over the full documents when updating to the new Data Definition format (#143). It makes sense to check these things when going through all event definitions piece-by-piece. ",
          "createdAt": "2021-08-18T14:48:45Z",
          "updatedAt": "2021-08-18T14:48:45Z"
        }
      ]
    },
    {
      "number": 175,
      "id": "MDU6SXNzdWU5ODUxMDI4NDQ=",
      "title": "h3 parameters: s/max_header_list_size/max_field_section_size",
      "url": "https://github.com/quicwg/qlog/issues/175",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "editorial",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "The name of the setting was changed in draft 28",
      "createdAt": "2021-09-01T12:40:41Z",
      "updatedAt": "2022-02-18T14:21:51Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thanks Lucas, good catch!\r\n\r\nI'm trying to track all of these minor changes in #174 and we plan to do them in bulk when going over all the definitions when switching them to CDDL. \r\n\r\nFeel free to report other similar changes, as individual issues with a reference to #174 or as comments on that issue directly. ",
          "createdAt": "2021-09-01T15:01:28Z",
          "updatedAt": "2021-09-01T15:01:28Z"
        }
      ]
    },
    {
      "number": 176,
      "id": "I_kwDOCrLn6M47dVO2",
      "title": "Define means for strong extensibility of TPs",
      "url": "https://github.com/quicwg/qlog/issues/176",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "https://quicwg.org/qlog/draft-ietf-quic-qlog-quic-events.html#name-parameters_set defines some of the core QUIC TPs and then says\r\n\r\n> Additionally, this event can contain any number of unspecified fields. This is to reflect setting of for example unknown (greased) transport parameters or employed (proprietary) extensions.\r\n\r\nThat's fine but is it weak and doesn't help interoperability much. We know this is going to be an area of innovation - new extensions and grease values. The spec would be improved by having a well-defined \"extension bucket\" field that TPs can go in, an array of integers tuples would be fine, for example.\r\n\r\nThis would help something like the qlog crate accomodate different users https://github.com/cloudflare/quiche/blob/master/tools/qlog/src/lib.rs#L1712 and parse input from different loggers.\r\n\r\n",
      "createdAt": "2021-09-15T21:43:26Z",
      "updatedAt": "2021-09-15T21:43:26Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 178,
      "id": "I_kwDOCrLn6M48g4Le",
      "title": "support for DATAGRAMS in data_moved events",
      "url": "https://github.com/quicwg/qlog/issues/178",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "Slightly related to #124\r\n\r\nhttps://quicwg.org/qlog/draft-ietf-quic-qlog-quic-events.html#section-3.3.15 defines the data_moved event. The stream_id field is optional. It isn't clear if the type of data I'm moving is stream data (and I don't have the stream ID) or if its datagram data (and I'll never have the stream ID).\r\n\r\nAn non-exhaustive list of options to address this are:\r\n\r\n1) leave it as is, and let tools assume that omitting the stream ID field implies datagram. (That breaks down for implementations that can't populate the stream ID for whatever reason)\r\n2) add a field to describe the type of data moved\r\n3) Be more clear that `data_moved` is only for stream data.Then possibly:\r\n  a) rename the event to `stream_data_moved`\r\n  b) add a new `datagram_data_moved` event\r\n\r\n",
      "createdAt": "2021-10-04T14:25:25Z",
      "updatedAt": "2021-10-04T14:25:25Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 179,
      "id": "I_kwDOCrLn6M486GE_",
      "title": "Figures contain lines that are too long",
      "url": "https://github.com/quicwg/qlog/issues/179",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [
        "editorial",
        "current-version"
      ],
      "body": "An editorial issue, but one that is good to get solved with a general approach that will avoid nit blocking eventual publication.\r\n\r\nHere's an example of the nits from the main schema draft\r\n\r\n```\r\n  Checking nits according to https://www.ietf.org/id-info/checklist :\r\n  ----------------------------------------------------------------------------\r\n\r\n  ** There are 30 instances of too long lines in the document, the longest\r\n     one being 329 characters in excess of 72.\r\n```\r\n\r\nWe had a similar problem in the Digest draft, some things like hashes or JSON objects are too long. Here's what we did https://httpwg.org/http-extensions/draft-ietf-httpbis-digest-headers.html#appendix-C\r\n\r\n> Some examples include JSON objects in the content. For presentation purposes, objects that fit completely within the line-length limits are presented on a single line using compact notation with no leading space. Objects that would exceed line-length limits are presented across multiple lines (one line per key-value pair) with 2 spaced of leading indentation.",
      "createdAt": "2021-10-10T02:44:06Z",
      "updatedAt": "2021-10-20T14:36:31Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "We plan to tackle this in the move to CDDL. ",
          "createdAt": "2021-10-20T14:35:51Z",
          "updatedAt": "2021-10-20T14:35:51Z"
        }
      ]
    },
    {
      "number": 180,
      "id": "I_kwDOCrLn6M49Pv9z",
      "title": "consider an alternative to the .qlog file extension for streaming serilization",
      "url": "https://github.com/quicwg/qlog/issues/180",
      "state": "CLOSED",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [
        "design",
        "current-version"
      ],
      "body": "The `qlog_format` field is part of the QlogFile and QlogFileNDJSON, so it's a bit circular to decide how to parse the object. When processing large files, it can be a pain to decide,\r\n\r\nOne technique would be to look at the first line of a file to determine the qlog format before attempting to parse it. But that seems like a hack. It also doesn't help if a large qlog is written into a file as a single line.\r\n\r\nKnowing the format up front, such as by unique file extensions, would mean that tools or applications can make more assumptions about how to deal with the file. For instance, I could simply use `split` https://man7.org/linux/man-pages/man1/split.1.html to safely slice up NDJSON files today, without requireing deep knowledge of qlog formats.",
      "createdAt": "2021-10-15T15:08:43Z",
      "updatedAt": "2022-02-18T17:29:51Z",
      "closedAt": "2022-02-18T17:29:51Z",
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This seems like a general issue wider than just qlog, and one that IIUC has traditionally been solved by a combination of looking at extensions AND the first few bytes/line of the file in question (e.g., image format headers). \r\n\r\nWhile we could indicate a specific extension for the different qlog serialization types in the spec, tools probably would still want to just support `.json` as a valid `.qlog` file in any format. In qvis for example, we do [look at the first few characters of a file](https://github.com/quiclog/qvis/blob/14351bc11602d04c04a6ecae038172a28f26cef7/visualizations/src/components/filemanager/data/FileLoader.ts#L204) to guess its format, so we support both options for a `.qlog` before actual parsing. As such, I feel it's one of those cases that we could/should spec, but that it wouldn't have full impact IRL for reusable tooling. \r\n\r\nAn additional aspect is using mime-types when transferring over e.g., HTTP, see #158, where I do also think we should define the media types in the draft. \r\n\r\nSo, I'd propose to indeed recommend (SHOULD, not MUST) .qlog for normal JSON and .sqlog (for \"streaming\" qlog) for json-seq.  What do you think? \r\n\r\n\r\n",
          "createdAt": "2021-10-20T14:45:03Z",
          "updatedAt": "2021-10-20T14:45:03Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "We picked `.sqlog`. This issue can be closed now.\r\n",
          "createdAt": "2022-01-21T18:25:18Z",
          "updatedAt": "2022-01-21T18:25:18Z"
        }
      ]
    },
    {
      "number": 182,
      "id": "I_kwDOCrLn6M49rugR",
      "title": "What are the units of \"relative_time\"?",
      "url": "https://github.com/quicwg/qlog/issues/182",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "The example in https://quicwg.org/qlog/draft-ietf-quic-qlog-main-schema.html#common-fields suggests the field is a string. Elsewhere, timestamps seem to be integers https://quicwg.org/qlog/draft-ietf-quic-qlog-main-schema.html#section-3.4.1 but in Event the `time` is a double https://quicwg.org/qlog/draft-ietf-quic-qlog-main-schema.html#section-3.4",
      "createdAt": "2021-10-25T09:07:31Z",
      "updatedAt": "2021-10-25T09:50:51Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Since we now require all times to be in `ms`, I think the `double` is the only correct one. \r\n\r\nThe string is a leftover from earlier times, when we forced string for something that could be >2^53 (JavaScript number limit), but when moving to CDDL, all of that will be unnecessary and we'll have doubles for this.\r\n\r\n(this obviously doesn't mean all qlog files actually use doubles at this time ;) qvis is a bit too lacks and allows both numbers and strings, so people can get away with either most times) ",
          "createdAt": "2021-10-25T09:50:51Z",
          "updatedAt": "2021-10-25T09:50:51Z"
        }
      ]
    },
    {
      "number": 183,
      "id": "I_kwDOCrLn6M4-VGpW",
      "title": "QUIC relies on ApplicationError, which is defined only for HTTP/3",
      "url": "https://github.com/quicwg/qlog/issues/183",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [
        "lnicco"
      ],
      "labels": [
        "design",
        "editorial",
        "quic-http3-fields"
      ],
      "body": "I recently refactored quiche's qlog implementation to split events into their own modules for general, QUIC and HTTP/3. In follow up work, I realised our implementation of the ConnectionClose frame was stale and I attempted to fix it up here https://github.com/cloudflare/quiche/pull/1079/commits/866292b923ce2fe236fcced0a641607e3be60bec. The definition of that frame at the time of writing is below, and a far as I can tell, `ApplicationError` is only defined in the HTTP/3 spec.\r\n\r\n```\r\nclass ConnectionCloseFrame{\r\n    frame_type:string = \"connection_close\";\r\n\r\n    error_space?:ErrorSpace;\r\n    error_code?:TransportError | ApplicationError | uint32;\r\n    raw_error_code?:uint32;\r\n    reason?:string;\r\n\r\n    trigger_frame_type?:uint64 | string; // For known frame types, the appropriate \"frame_type\" string. For unknown frame types, the hex encoded identifier value\r\n}\r\n```\r\n\r\nIn code review, it was highlighted that including an HTTP/3 enumeration in my QUIC module code is a bit strange (feels like a priority inversion). Also, it doesn't seem to scale to support other applications. I think perhaps what is needed is for there to be an \"externalised\" ApplicationError union type like `type ApplicationError = Http3Error | NewStuff`, or maybe even that doesn't work well for supporting new application protocols...",
      "createdAt": "2021-11-05T11:14:54Z",
      "updatedAt": "2022-02-18T14:18:50Z",
      "closedAt": null,
      "comments": [
        {
          "author": "kazuho",
          "authorAssociation": "MEMBER",
          "body": "Is there a reason to expose the semantics of application protocol in at QUIC level?\r\n\r\nIMO, trying to expose HTTP3Error at QUIC level is no less strange than asking to decode the HTTP headers being transported by the STREAM frames, or the HTTP/3 stream type.\r\n\r\nI would hope that the QUIC-level traces would just show the error codes in numbers, much like they just log the stream IDs / bytes being exchanged.",
          "createdAt": "2021-11-06T04:51:41Z",
          "updatedAt": "2021-11-06T04:51:41Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "That would work too. We could invent new application error event types that sit in H3, and then correlate to QUIC frames bearing the integer value",
          "createdAt": "2021-11-06T11:28:28Z",
          "updatedAt": "2021-11-06T11:28:28Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Good catch, and I feel this is primarily an oversight of mine in forgetting to change this when splitting up QUIC and H3 events...\r\n\r\nI agree it doesn't make sense to have the ApplicationError class in the QUIC events doc and that we should revert to just having `string | uint32` there, with some extra guidance that application-specific qlog docs should make that more explicit (e.g., with the ApplicationError enum that maps to strings in the H3 doc). \r\n\r\nHaving separate error events at the H3 layer is imo perpendicular to this, but certainly also not a bad idea. ",
          "createdAt": "2021-11-09T16:00:45Z",
          "updatedAt": "2021-11-09T16:00:45Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "String | uint32 works for me and means we likely never have to revisit this space ",
          "createdAt": "2021-11-09T16:03:58Z",
          "updatedAt": "2021-11-09T16:03:58Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "With CDDL, we will be able to do better than `string | uint32` as it can define extension points (called sockets/plugs in CDDL) with `$`. \r\n\r\nWill probably look something like:\r\n```\r\n# in QUIC document:\r\n$ApplicationErrorType\r\n\r\n# in HTTP/3 document:\r\n$ApplicationErrorType \\= H3ApplicationError\r\n\r\n# in future WebTransport document\r\n$ApplicationErrorType \\= WTApplicationError\r\n\r\n```",
          "createdAt": "2022-02-18T14:18:50Z",
          "updatedAt": "2022-02-18T14:18:50Z"
        }
      ]
    },
    {
      "number": 184,
      "id": "I_kwDOCrLn6M4-YHxH",
      "title": "The `Summary` type is too poorly defined",
      "url": "https://github.com/quicwg/qlog/issues/184",
      "state": "OPEN",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "editorial"
      ],
      "body": "QlogFile and QlogFileSeq contain `summary?: Summary`. However, https://quicwg.org/qlog/draft-ietf-quic-qlog-main-schema.html#section-3.1 states \r\n\r\n> As the summary field is highly deployment-specific, this document does not specify any default fields or their semantics.\r\n\r\nIt's not a problem to leave the Summary type open as you suggest. But it's not clear how I would represent this in an implementation. Is it an array of `(String, Any)` tuples, or something else?",
      "createdAt": "2021-11-06T13:34:24Z",
      "updatedAt": "2021-11-09T16:14:37Z",
      "closedAt": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "The original idea was to have this as a generic JSON Object (so not quite an array of (string, any) but rather a key-value object, which is kind of the same thing conceptually), as suggested by the example.  \r\n\r\nSo in TypeScript, it might be better defined as `summary?: Object` or if we want to keep the Summary type, we'd get something like:\r\n\r\n```\r\ninterface Summary {\r\n  [key: string]: any;\r\n}\r\n```\r\n(according to https://remarkablemark.org/blog/2021/08/19/typescript-type-plain-old-javascript-object/)\r\n\r\nNot sure what that'll look like in CDDL, but will make sure to keep it into account when we do that work. ",
          "createdAt": "2021-11-09T16:08:18Z",
          "updatedAt": "2021-11-09T16:08:18Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "Sgtm will review it once we get there",
          "createdAt": "2021-11-09T16:14:37Z",
          "updatedAt": "2021-11-09T16:14:37Z"
        }
      ]
    },
    {
      "number": 185,
      "id": "I_kwDOCrLn6M5DMQMn",
      "title": "key_retired should be key_discarded",
      "url": "https://github.com/quicwg/qlog/issues/185",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "marten-seemann"
      ],
      "labels": [
        "editorial",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "Apparently, what was once (colloquially) known as key \"retire\" is now called key \"discard\" in [RFC 9001](https://www.rfc-editor.org/rfc/rfc9001.html#name-discarding-unused-keys). \r\n\r\nAs such, we should update the event definition's name (and probably add some more information in the qlog spec as well, since it's a bit barebones atm). \r\nI'm also not sure anymore what the difference is in the triggers with \"tls\" vs \"local/remote update\"...\r\n\r\ncc @kosekmi\r\n\r\n",
      "createdAt": "2022-02-08T13:51:06Z",
      "updatedAt": "2022-02-08T13:51:48Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 186,
      "id": "I_kwDOCrLn6M5DekYc",
      "title": "Add a way to indicate sent-but-unacked data",
      "url": "https://github.com/quicwg/qlog/issues/186",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "design",
        "quic-http3-fields",
        "current-version"
      ],
      "body": "Once data for a stream is sent in a packet, it has to remain in some form of retransmission buffer (either a separate buffer or as ranges in the main stream buffer or ...) until the data is ACKed as received, only then can it be discarded completely. \r\n\r\nAt this time, there is no way to track how much sent-but-unacked data is outstanding for a given stream. \r\n\r\nThe most organic way to do this seems to be to add a new target to the `data_moved` event. We currently have `\"user\",\"application\",\"transport\",\"network\"`, where we might regard \"network\" as being \"sent but unacked\", but then we still lack a \"discarded\" state. \r\n\r\nBikeshedding is possible on the name: \"discarded\", \"resolved\", \"acknowledged\", ... as conceptually we could even replace the \"user\" target with this one as well, and saying that indicates the data has left the \"network protocol stack\" (either on the sender or receiver side), terming it as \"handled\"/\"resolved\" would make sense there.\r\n\r\ncc @LPardue ",
      "createdAt": "2022-02-11T08:39:33Z",
      "updatedAt": "2022-02-11T08:54:11Z",
      "closedAt": null,
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "There's two transitions here:\r\n\r\nSend side: transport -> $foo\r\nReceive side: application -> $bar\r\n\r\n$bar I think is sufficiently expressed by \"user\" in my opinion. \r\n\r\nFor $foo, it's a bit tricky because the current values are all entities, while you've proposed non-entity terms here. Some additional suggestions would be \"null\", \"free\", or \"terminal\" (as in terminal state, not a bash terminal). \r\n\r\nThe nice thing about modelling a discarding transition is that it can also be used for stream resets. Helps to understand the point in time a transport implementation actually frees any buffers, independent of the RESET_STREAM frame.",
          "createdAt": "2022-02-11T08:54:11Z",
          "updatedAt": "2022-02-11T08:54:11Z"
        }
      ]
    },
    {
      "number": 187,
      "id": "I_kwDOCrLn6M5DyXiK",
      "title": "Remove Summary and Configuration",
      "url": "https://github.com/quicwg/qlog/issues/187",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "design",
        "high-level-schema",
        "discuss"
      ],
      "body": "We currently have the `summary` (in QlogFile) and `configuration` (in Trace) fields.\r\n\r\nThese fields made sense when qlog was viewed as a file format that would primarily be used to aggregate multiple traces into a single file, which would then be transferable between different tools (e.g., in research settings). \r\n\r\nHowever, with most implementations shifting to streaming logging (1 trace per file) and no tools emerging that rely on interoperability via the `summary` and `configuration` fields, I feel it makes sense to just remove them from the spec. This is further motivated by the fact that Summary is defined as just a generic JSON object and Configuration only has 2 recommended fields, 1 of which is `original_uris`, which again only makes sense if we see this as a grouping format. \r\n\r\nSee also #184, cc @LPardue ",
      "createdAt": "2022-02-14T13:07:01Z",
      "updatedAt": "2022-02-14T13:36:20Z",
      "closedAt": null,
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "+1 to simplicity. \r\n\r\nIt seems like it's going to be straightforward for anyone to add such fields in future if they really need them. Being judicious with we things we include in the base spec will make it more straightforward for people to focus on the valuable items.",
          "createdAt": "2022-02-14T13:36:20Z",
          "updatedAt": "2022-02-14T13:36:20Z"
        }
      ]
    },
    {
      "number": 188,
      "id": "I_kwDOCrLn6M5DyiNs",
      "title": "Force line length to 72",
      "url": "https://github.com/quicwg/qlog/issues/188",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "editorial",
        "future-versions"
      ],
      "body": "According to the official IETF draft guidelines, line length should not be longer than 72 ASCII characters (https://www.ietf.org/how/ids/guidelines/#format, and https://www.ietf.org/how/ids/guidelines/).\r\n\r\nFor some reason, I had previously understood this to be 82 characters, and so the current texts are 10 characters too wide...\r\n\r\nSince this will be somewhat of a tedious process (which can be done largely automatically but with manual checks) which will impact allmost all parts of the documents, I propose we do this in a single burst somewhere down the line. \r\n\r\ncc @LPardue ",
      "createdAt": "2022-02-14T13:38:36Z",
      "updatedAt": "2022-02-14T18:52:54Z",
      "closedAt": null,
      "comments": [
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "Chatted a bit with rmarx offline. The errors that xml2rfc moans about are about artwork, not body text etc.\r\n\r\nOver the 3 PRs I created, there might look like a lot of churn but it is all constrained to the artwork pieces. In my opinion, it's better to fix these now (or nullify the json validation errors) so that we don't start ignoring things that exist or get newly introduced.",
          "createdAt": "2022-02-14T18:52:54Z",
          "updatedAt": "2022-02-14T18:52:54Z"
        }
      ]
    },
    {
      "number": 192,
      "id": "I_kwDOCrLn6M5EPB8i",
      "title": "Rework $ProtocolEventBody",
      "url": "https://github.com/quicwg/qlog/issues/192",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [
        "rmarx"
      ],
      "labels": [
        "design",
        "high-level-schema",
        "discuss"
      ],
      "body": "The new CDDL approach uses a CDDL extension point to be more strict about which values are allowed in the `Event:data` field. \r\n\r\nCurrently, it's defined as:\r\n\r\n```\r\n; The ProtocolEventBody is any key-value map (e.g., JSON object)\r\n; only the optional trigger field is defined in this document\r\n$ProtocolEventBody /= {\r\n    ? trigger: text\r\n    * text => any\r\n}\r\n; event documents are intended to extend this socket by using:\r\n; NewProtocolSpecificEvents = EventType1 / EventType2 / ... / EventTypeN\r\n; $ProtocolEventBody /= NewProtocolSpecificEvents\r\n```\r\n\r\nHowever, this effectively still allows just about any JSON object as ProtocolEventBody, as we're just extending the $ProtocolEventBody.\r\n\r\nIf we want to be (slightly) more strict, we could do something like this:\r\n```\r\n; main doc\r\nProtocolEventBodyPrototype = {\r\n    ? trigger: text\r\n    * text => any\r\n}\r\n\r\nProtocolEventBody = ProtocolEventBodyPrototype / $ProtocolEventBodies\r\n\r\n; event docs\r\nNewProtocolSpecificEvents = EventType1 / EventType2 / ... / EventTypeN\r\n$ProtocolEventBodies /= NewProtocolSpecificEvents\r\n```\r\n\r\nAlternatively, we can just NOT allow the general form (the `ProtocolEventBodyPrototype`) and just include that as an example and require event bodies to provide at least 1 defined event. ",
      "createdAt": "2022-02-19T17:03:09Z",
      "updatedAt": "2022-02-19T17:03:22Z",
      "closedAt": null,
      "comments": []
    }
  ],
  "pulls": [
    {
      "number": 12,
      "id": "MDExOlB1bGxSZXF1ZXN0MzAwMDI4NTY1",
      "title": "Fixed typo in \"version_negotiation\" enum member",
      "url": "https://github.com/quicwg/qlog/pull/12",
      "state": "MERGED",
      "author": "jlaine",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2019-07-22T20:34:38Z",
      "updatedAt": "2019-07-22T21:12:06Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "52267e9675f5fd06f5d507a1792aa601ea0bdb81",
      "headRepository": "jlaine/internet-drafts",
      "headRefName": "negotiation-typo",
      "headRefOid": "22e20c5e072d32d98f4e432effec3e2b49d6c869",
      "closedAt": "2019-07-22T21:12:06Z",
      "mergedAt": "2019-07-22T21:12:06Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "9bc53886d90472c68000652c2a1c83a9a6c338a5"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 18,
      "id": "MDExOlB1bGxSZXF1ZXN0MzEwMzM1NzE2",
      "title": "Rename \"type\" property to \"packet_type\" in packet events",
      "url": "https://github.com/quicwg/qlog/pull/18",
      "state": "MERGED",
      "author": "jlaine",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2019-08-23T10:53:01Z",
      "updatedAt": "2019-08-23T12:30:44Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "3b12117f096ab7fa7927516a39a2fd17b392d8d6",
      "headRepository": "jlaine/internet-drafts",
      "headRefName": "packet_type",
      "headRefOid": "f629b74ec44e95158b4594873c338435d07fc108",
      "closedAt": "2019-08-23T12:30:44Z",
      "mergedAt": "2019-08-23T12:30:44Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "886a41e3afc7634500ed382350508a1fe5c224b7"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 38,
      "id": "MDExOlB1bGxSZXF1ZXN0MzY0NDMzMDYy",
      "title": "add the HANDSHAKE_DONE frame",
      "url": "https://github.com/quicwg/qlog/pull/38",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #37.",
      "createdAt": "2020-01-18T14:47:55Z",
      "updatedAt": "2020-01-18T15:31:42Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "e5c946c65db20624d4f06d5c9102d6154fc8c847",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "handshake-done",
      "headRefOid": "189dd7bbf606d0b8400d91260e704c9c328b6aa3",
      "closedAt": "2020-01-18T15:31:42Z",
      "mergedAt": "2020-01-18T15:31:42Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "b50635531bbbbcd059d9670b0b97f55069defb4f"
      },
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Done.",
          "createdAt": "2020-01-18T15:29:31Z",
          "updatedAt": "2020-01-18T15:29:31Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0OTQ3OTg4",
          "commit": {
            "abbreviatedOid": "5ec9531"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "CHANGES_REQUESTED",
          "body": "Could you also add HandshakeDoneFrame to the QuicFrame type in appendix A.4 (https://tools.ietf.org/html/draft-marx-qlog-event-definitions-quic-h3-01#appendix-A.4)? ",
          "createdAt": "2020-01-18T15:18:51Z",
          "updatedAt": "2020-01-18T15:18:51Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0OTQ4NTEy",
          "commit": {
            "abbreviatedOid": "189dd7b"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2020-01-18T15:31:31Z",
          "updatedAt": "2020-01-18T15:31:31Z",
          "comments": []
        }
      ]
    },
    {
      "number": 41,
      "id": "MDExOlB1bGxSZXF1ZXN0MzY0NDk4MTI4",
      "title": "move packet_size to events, move packet_type to PacketHeader",
      "url": "https://github.com/quicwg/qlog/pull/41",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #40.",
      "createdAt": "2020-01-19T05:31:38Z",
      "updatedAt": "2020-09-07T20:14:49Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b50635531bbbbcd059d9670b0b97f55069defb4f",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "udp-vs-quic-header",
      "headRefOid": "ce9b1690e05a31048d39ec171721febb1922d618",
      "closedAt": "2020-09-07T20:14:49Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This was a slightly bigger change than initially anticipated and made in https://github.com/quiclog/internet-drafts/commit/0cb1f02e3c8a60962bc39b387c5db9ba12210556. ",
          "createdAt": "2020-09-07T20:14:49Z",
          "updatedAt": "2020-09-07T20:14:49Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 61,
      "id": "MDExOlB1bGxSZXF1ZXN0Mzg1MjMwMjI3",
      "title": "rename header_decrypt_error to header_parse_error",
      "url": "https://github.com/quicwg/qlog/pull/61",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #60.",
      "createdAt": "2020-03-08T05:53:58Z",
      "updatedAt": "2020-09-08T12:30:47Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b50635531bbbbcd059d9670b0b97f55069defb4f",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "header-decrypt-error",
      "headRefOid": "359513a3bb236747fcbd71ee1f506e12199293ad",
      "closedAt": "2020-09-08T12:30:47Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Made change manually in draft02 branch in https://github.com/quiclog/internet-drafts/commit/a578e935e4cae5d3415bb46358a7b668bf4a4356",
          "createdAt": "2020-09-08T12:30:47Z",
          "updatedAt": "2020-09-08T12:30:47Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 63,
      "id": "MDExOlB1bGxSZXF1ZXN0Mzg3NjMyNDIw",
      "title": "rename idle_timeout to max_idle_timeout",
      "url": "https://github.com/quicwg/qlog/pull/63",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "See https://github.com/quicwg/base-drafts/pull/3099.",
      "createdAt": "2020-03-13T07:30:34Z",
      "updatedAt": "2020-03-13T08:13:43Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b50635531bbbbcd059d9670b0b97f55069defb4f",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "max-idle-timeout",
      "headRefOid": "a007af093fb3f7f77c82d415a6f366f2dc9b2098",
      "closedAt": "2020-03-13T08:13:43Z",
      "mergedAt": "2020-03-13T08:13:43Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "89d2a71667fbdf7888c9139583c84bc0a9690e0f"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 67,
      "id": "MDExOlB1bGxSZXF1ZXN0MzkxODExNzMz",
      "title": "rename max_packet_size to max_udp_payload_size",
      "url": "https://github.com/quicwg/qlog/pull/67",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "See https://github.com/quicwg/base-drafts/pull/3473.",
      "createdAt": "2020-03-21T04:03:25Z",
      "updatedAt": "2020-03-21T12:32:22Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "89d2a71667fbdf7888c9139583c84bc0a9690e0f",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "max-udp-payload-size",
      "headRefOid": "8c8e39e1dafd3ced236d384d20539a7a2dec25d2",
      "closedAt": "2020-03-21T12:32:21Z",
      "mergedAt": "2020-03-21T12:32:21Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "eeebaa4826d2596f552dedac95b4d01998d6e735"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 68,
      "id": "MDExOlB1bGxSZXF1ZXN0MzkzODIxMTU2",
      "title": "Add stateless reset support",
      "url": "https://github.com/quicwg/qlog/pull/68",
      "state": "MERGED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Partially fixes #64.\r\n\r\nMain change is adding `stateless_reset` as a PacketType.\r\n\r\nThe `stateless_reset_token` is added as a field to packet_sent and packet_received.\r\nAny of the \"unpredictable bits\" can be logged as `raw_encrypted`\r\n\r\nAdded a trigger to `connection_state_update` to indicate if a connection goes into draining/closing because a valid stateless_reset was received.\r\n\r\nBackwards compatibility break: renamed `reset_token` to `stateless_reset_token` on the NewConnectionID frame definition (for consistency). \r\n\r\nBeen thinking about a way to signal an \"invalid\" stateless reset, but figured there is no way to distinguish it from an otherwise garbage datagram, so decided it was impossible. Not 100% sure about the \"looping case\" where you continually lower the packet size. Maybe that's solved by adding a generic \"packet_size\" trigger value to `packet_dropped` though?",
      "createdAt": "2020-03-25T20:50:37Z",
      "updatedAt": "2020-03-28T10:24:21Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "eeebaa4826d2596f552dedac95b4d01998d6e735",
      "headRepository": "quicwg/qlog",
      "headRefName": "stateless_reset",
      "headRefOid": "6ff25a4b44ee3a5f146381c737a5de3c64e14c78",
      "closedAt": "2020-03-28T10:24:21Z",
      "mergedAt": "2020-03-28T10:24:20Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "edf676c342bf73c168a27a4af6b6f45af58518ba"
      },
      "comments": [
        {
          "author": "kazu-yamamoto",
          "authorAssociation": "NONE",
          "body": "LGTM!",
          "createdAt": "2020-03-27T02:54:01Z",
          "updatedAt": "2020-03-27T02:54:01Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyMDE3NjE5",
          "commit": {
            "abbreviatedOid": "6ff25a4"
          },
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2020-03-26T13:40:51Z",
          "updatedAt": "2020-03-26T13:40:51Z",
          "comments": []
        }
      ]
    },
    {
      "number": 70,
      "id": "MDExOlB1bGxSZXF1ZXN0Mzk1MDU5NTUz",
      "title": "update transport errors",
      "url": "https://github.com/quicwg/qlog/pull/70",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2020-03-28T07:26:37Z",
      "updatedAt": "2020-03-28T11:00:33Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "eeebaa4826d2596f552dedac95b4d01998d6e735",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "update-transport-errors",
      "headRefOid": "26a19a8f72339cac08eb277f45285fdd244981eb",
      "closedAt": "2020-03-28T11:00:33Z",
      "mergedAt": "2020-03-28T11:00:33Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "2a4dfd91598685b31daade04cf99db4bdffd2109"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 71,
      "id": "MDExOlB1bGxSZXF1ZXN0Mzk1MDY0ODQy",
      "title": "add a packet number space field to loss_timer_set and loss_timer_expired",
      "url": "https://github.com/quicwg/qlog/pull/71",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #69.",
      "createdAt": "2020-03-28T08:27:33Z",
      "updatedAt": "2020-03-28T10:29:32Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "eeebaa4826d2596f552dedac95b4d01998d6e735",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "loss-timer-events-pn-space",
      "headRefOid": "da1743e05116cf2f0f0390ea24c54bf66b2df0c0",
      "closedAt": "2020-03-28T10:29:31Z",
      "mergedAt": "2020-03-28T10:29:31Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "d4a976e57f271d237d1818e5e56c62b6b60fd38b"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 73,
      "id": "MDExOlB1bGxSZXF1ZXN0Mzk1MDc5MjQ3",
      "title": "Merge loss_timer events",
      "url": "https://github.com/quicwg/qlog/pull/73",
      "state": "MERGED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #69.\r\n\r\nNot 100% sure this is enough for all the latest draft-27(+) changes though, added a TODO in the draft for that purpose. \r\n\r\nAlso added a packet_number_space field to metrics_updated to be flexible for implementations that don't want to implement all types of events. It's not a great fit at that location, but it seemed the most synergistic without having a completely new event type.\r\n\r\nPTAL @marten-seemann ",
      "createdAt": "2020-03-28T10:55:36Z",
      "updatedAt": "2020-03-29T11:23:59Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "d4a976e57f271d237d1818e5e56c62b6b60fd38b",
      "headRepository": "quicwg/qlog",
      "headRefName": "loss_timer",
      "headRefOid": "11720e0eb6c63f44526e7546c705aa419a7bf6ef",
      "closedAt": "2020-03-29T11:23:59Z",
      "mergedAt": "2020-03-29T11:23:59Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "a68c214abaa655138ad5935bf3a1021091bfc5a5"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgzMzg4MzI3",
          "commit": {
            "abbreviatedOid": "1833887"
          },
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2020-03-29T08:59:00Z",
          "updatedAt": "2020-03-29T09:01:06Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "There's no single point in time where the packet number space changes for loss recovery purposes. On the contrary, both client and server will have packets from different packet number spaces in flight during every QUIC handshake.\r\n\r\nTherefore I'd suggest to remove this field.",
              "createdAt": "2020-03-29T08:59:00Z",
              "updatedAt": "2020-03-29T11:10:15Z"
            },
            {
              "originalPosition": 64,
              "body": "Why do we need to export a trigger, if this is the only possible reason for canceling the timer anyway?",
              "createdAt": "2020-03-29T09:00:48Z",
              "updatedAt": "2020-03-29T11:10:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgzMzk5MDAx",
          "commit": {
            "abbreviatedOid": "11720e0"
          },
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2020-03-29T11:13:37Z",
          "updatedAt": "2020-03-29T11:13:37Z",
          "comments": []
        }
      ]
    },
    {
      "number": 77,
      "id": "MDExOlB1bGxSZXF1ZXN0NDAxNzczNjIw",
      "title": "add more packet_dropped triggers",
      "url": "https://github.com/quicwg/qlog/pull/77",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2020-04-10T06:13:27Z",
      "updatedAt": "2020-04-12T12:10:18Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "a68c214abaa655138ad5935bf3a1021091bfc5a5",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "more-drop-triggers",
      "headRefOid": "af1614c49eace48bf29b911790a9db0095b458ca",
      "closedAt": "2020-04-12T12:10:18Z",
      "mergedAt": "2020-04-12T12:10:18Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "9af27705fd0eed8f38465ebf34afeedc9e93d857"
      },
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Per discussion on slack, `unexpected_version_negotiation` and `unexpected_retry` can be merged into `unexpected_packet`, given that we have a `packet_type` field for the disambiguation. ",
          "createdAt": "2020-04-12T11:41:05Z",
          "updatedAt": "2020-04-12T11:41:05Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "@rmarx Done. Updated the PR.",
          "createdAt": "2020-04-12T11:56:16Z",
          "updatedAt": "2020-04-12T11:56:16Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 81,
      "id": "MDExOlB1bGxSZXF1ZXN0NDAzMDgyODg0",
      "title": "add a supported_versions array to packet_sent and packet_received",
      "url": "https://github.com/quicwg/qlog/pull/81",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Partial fix for #75.",
      "createdAt": "2020-04-14T09:51:56Z",
      "updatedAt": "2020-04-14T14:40:18Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "9af27705fd0eed8f38465ebf34afeedc9e93d857",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "log-supported-versions",
      "headRefOid": "d02e59eeb7ca2df7787b9818b584629d01608cd9",
      "closedAt": "2020-04-14T14:40:17Z",
      "mergedAt": "2020-04-14T14:40:17Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "b0880b8a5ff7a9e856e321ff12465fd4be15cf5f"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 82,
      "id": "MDExOlB1bGxSZXF1ZXN0NDAzMTEzNzAw",
      "title": "add a version_negotiation trigger for the closed connection_state_updated event",
      "url": "https://github.com/quicwg/qlog/pull/82",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2020-04-14T10:57:24Z",
      "updatedAt": "2020-04-14T14:39:52Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "9af27705fd0eed8f38465ebf34afeedc9e93d857",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "version-mismatch",
      "headRefOid": "573c8386c29bed76851f66c40158eb4165fb35a3",
      "closedAt": "2020-04-14T14:39:52Z",
      "mergedAt": "2020-04-14T14:39:52Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "05c45b5d9e2195535a610c28f9c4a27d88444c5d"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 83,
      "id": "MDExOlB1bGxSZXF1ZXN0NDAzNTMwMzQ5",
      "title": "add a timeout trigger for the closed connection_state_updated event",
      "url": "https://github.com/quicwg/qlog/pull/83",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2020-04-15T04:12:58Z",
      "updatedAt": "2020-11-03T11:42:33Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b0880b8a5ff7a9e856e321ff12465fd4be15cf5f",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "connection-state-timeout",
      "headRefOid": "08e4ca6944c39f416b951adba3dd03d30af326a7",
      "closedAt": "2020-11-03T11:42:33Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm unsure about this PR. In my implementation, I have an idle timeout as well as a handshake timeout (the handshake timeout way shorter than the idle timeout).\r\nWould it make sense to add a value for both? Or a separate field for trigger details?",
          "createdAt": "2020-04-15T07:43:32Z",
          "updatedAt": "2020-04-15T07:43:32Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "In draft-02, I added a trigger value for both generic timeout and handshake_timeout based on quic-go's implementation. ",
          "createdAt": "2020-11-03T11:42:33Z",
          "updatedAt": "2020-11-03T11:42:33Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 84,
      "id": "MDExOlB1bGxSZXF1ZXN0NDAzNjUzMDA0",
      "title": "add a packet_size field to the packet_buffered event",
      "url": "https://github.com/quicwg/qlog/pull/84",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #76.",
      "createdAt": "2020-04-15T09:44:14Z",
      "updatedAt": "2020-07-22T07:48:09Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b0880b8a5ff7a9e856e321ff12465fd4be15cf5f",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "packet-buffered-packet-size",
      "headRefOid": "e17dbba7a86e0c28814ed03b1d9833b2c0c2750a",
      "closedAt": "2020-07-22T07:48:08Z",
      "mergedAt": "2020-07-22T07:48:08Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "fc2eec4b31c9484f8891323017acdc20bae816b3"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 87,
      "id": "MDExOlB1bGxSZXF1ZXN0NDIyMzcxOTQz",
      "title": "Authenticate connection IDs",
      "url": "https://github.com/quicwg/qlog/pull/87",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Adds the transport parameters added in https://github.com/quicwg/base-drafts/pull/3499.",
      "createdAt": "2020-05-24T06:41:19Z",
      "updatedAt": "2020-07-22T07:48:29Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b0880b8a5ff7a9e856e321ff12465fd4be15cf5f",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "authenticate-connection-ids",
      "headRefOid": "3f2ea8e74fb7a36fb692f4d96951de1656f13102",
      "closedAt": "2020-07-22T07:48:29Z",
      "mergedAt": "2020-07-22T07:48:28Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "09f447a17f183f02f8e0ada7cd0b834c3fd3963a"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 92,
      "id": "MDExOlB1bGxSZXF1ZXN0NDIzNTYwODU1",
      "title": "add a packet_dropped trigger for duplicate packets",
      "url": "https://github.com/quicwg/qlog/pull/92",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "See https://quicwg.org/base-drafts/draft-ietf-quic-transport.html#name-packet-numbers.",
      "createdAt": "2020-05-27T02:03:51Z",
      "updatedAt": "2020-07-22T07:46:53Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "d6433e1e93343aae970163d13549ad8361535330",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "packet-drop-duplicate",
      "headRefOid": "4278731985a41594c118fa093912a44e9d4e4ed4",
      "closedAt": "2020-07-22T07:46:53Z",
      "mergedAt": "2020-07-22T07:46:53Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "c93c66d7dafdba32aa415e720a84643ab4835f86"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 93,
      "id": "MDExOlB1bGxSZXF1ZXN0NDMzMDA5OTUz",
      "title": "rename server_busy to connection_refused",
      "url": "https://github.com/quicwg/qlog/pull/93",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2020-06-11T11:19:22Z",
      "updatedAt": "2020-06-11T15:06:15Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b0880b8a5ff7a9e856e321ff12465fd4be15cf5f",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "connection-refused",
      "headRefOid": "8d9475002611699c8381081fa90b95e51ea22f72",
      "closedAt": "2020-06-11T15:06:15Z",
      "mergedAt": "2020-06-11T15:06:15Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "b8a2fd89f64b95e026a68dfcfb879d6c695e1514"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 98,
      "id": "MDExOlB1bGxSZXF1ZXN0NDQ2MDkxNDgx",
      "title": "max_ack_delay is a constant, and logged in the transport parameters_set",
      "url": "https://github.com/quicwg/qlog/pull/98",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2020-07-08T08:47:07Z",
      "updatedAt": "2020-07-08T09:30:40Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b8a2fd89f64b95e026a68dfcfb879d6c695e1514",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "remove-max-ack-delay-from-metrics-update",
      "headRefOid": "408d46cd7076062970ad2898cba4079091629cff",
      "closedAt": "2020-07-08T09:30:40Z",
      "mergedAt": "2020-07-08T09:30:40Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "11edf486b69a96720646b436789d33d4621a02e2"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 99,
      "id": "MDExOlB1bGxSZXF1ZXN0NDQ2MDkyNjE0",
      "title": "remove in_recovery from metrics_update",
      "url": "https://github.com/quicwg/qlog/pull/99",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #96.",
      "createdAt": "2020-07-08T08:49:13Z",
      "updatedAt": "2020-07-08T09:29:59Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b8a2fd89f64b95e026a68dfcfb879d6c695e1514",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "remove-in-recovery-from-metrics-update",
      "headRefOid": "a348778bab9d89e583a49e4262d3ab5be20c896d",
      "closedAt": "2020-07-08T09:29:59Z",
      "mergedAt": "2020-07-08T09:29:59Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "2b49fb613be515fdfde9eff5e1f66c455499fd35"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 103,
      "id": "MDExOlB1bGxSZXF1ZXN0NDQ2MTAzNDQ2",
      "title": "remove the UnknownFrame QUIC frame type",
      "url": "https://github.com/quicwg/qlog/pull/103",
      "state": "CLOSED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Other than H3 frames, QUIC frames are not TLV encoded. It's therefore not possible to parse a frame type that your implementation doesn't understand. In fact, it's a protocol violation to even send such a frame.",
      "createdAt": "2020-07-08T09:08:43Z",
      "updatedAt": "2020-07-08T09:38:57Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "b8a2fd89f64b95e026a68dfcfb879d6c695e1514",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "remove-unknown-frame",
      "headRefOid": "76957f1589918be259181e40d9a9b6b810ceb9b2",
      "closedAt": "2020-07-08T09:38:56Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I'm not sure I follow you on this one.\r\n\r\nHere, the use case is for the receiver. They see an incoming frame with an unknown type, which, according to the spec, leads to a connection close:\r\n\r\n> An endpoint MUST treat the receipt of a frame of unknown type as a\r\n   connection error of type FRAME_ENCODING_ERROR.\r\n\r\nThis definition is to allow the endpoint to log more detailed info (or at least the raw value for manual dissection during debugging) about the unexpected frame before closing the connection. ",
          "createdAt": "2020-07-08T09:34:51Z",
          "updatedAt": "2020-07-08T09:34:51Z"
        },
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "That makes sense. Must have missed that, sorry.",
          "createdAt": "2020-07-08T09:38:56Z",
          "updatedAt": "2020-07-08T09:38:56Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 108,
      "id": "MDExOlB1bGxSZXF1ZXN0NDQ5NDM2MjM3",
      "title": "add an \"invalid_initial\" trigger to the packet_dropped event",
      "url": "https://github.com/quicwg/qlog/pull/108",
      "state": "MERGED",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "There are two conditions an Initial packet has to fulfill:\r\n1. It's DCID must be >= 8 bytes long.\r\n2. The size of the datagram must be >= 1200.\r\n\r\nNone of the other triggers for the `packet_dropped` event seem appropriate for this.",
      "createdAt": "2020-07-15T12:02:04Z",
      "updatedAt": "2020-07-22T07:45:42Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "fae11164cbfc22ff5aa6a763eae746e2e15abd00",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "add-invalid-initial-drop-trigger",
      "headRefOid": "0a8175658bf0aa7ef8d9ebd4754deb1a52c49844",
      "closedAt": "2020-07-22T07:45:42Z",
      "mergedAt": "2020-07-22T07:45:42Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "d6433e1e93343aae970163d13549ad8361535330"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 123,
      "id": "MDExOlB1bGxSZXF1ZXN0NTE2NTY1NjM5",
      "title": "token-related fixes",
      "url": "https://github.com/quicwg/qlog/pull/123",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #122.\r\n\r\nThis PR contains 2 fixes:\r\n\r\n- stateless reset tokens are not tokens\r\n- `PacketHeader` already contains a `Token`, so we don't need another field on the `packet_sent` and `packet_received` event",
      "createdAt": "2020-11-06T07:36:26Z",
      "updatedAt": "2020-11-09T11:23:59Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "draft02",
      "baseRefOid": "197532463830d19b3e5b854f692951fc9a30ce9a",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "token-fixes",
      "headRefOid": "24a5388171711b68cae7430aa63e9e98c679e842",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI2MTU3MzQ2",
          "commit": {
            "abbreviatedOid": "24a5388"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2020-11-09T11:23:50Z",
          "updatedAt": "2020-11-09T11:23:59Z",
          "comments": [
            {
              "originalPosition": 41,
              "body": "So this is a bit of a difficult one imo. \r\nI'd put retry_token outside, since it's encapsulated in its own packet type, and so it can be considered to be part of the \"payload\" rather than the header. \r\nThis is different from the initial token, which is clearly part of the header.\r\n\r\nIf we do put the retry token in the PacketHeader struct, imo it would make sense to do the same for the stateless_reset_token as well, since from the same logic, you could say that that is part of the Stateless Reset Packet header as well, rater than its payload. \r\n\r\nI think it's probably cleaner to have all three in the PacketHeader then, with token?:Token covering both initial and retry as you proposed here. \r\n",
              "createdAt": "2020-11-09T11:23:51Z",
              "updatedAt": "2020-11-09T11:23:59Z"
            }
          ]
        }
      ]
    },
    {
      "number": 125,
      "id": "MDExOlB1bGxSZXF1ZXN0NTMxNDA0NzMy",
      "title": "Field name consistency with QUIC draft 32",
      "url": "https://github.com/quicwg/qlog/pull/125",
      "state": "MERGED",
      "author": "toru",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Currently there's a mix of `limit` and `maximum` in the QLog spec, such that:\r\n\r\n```\r\nclass DataBlockedFrame{\r\n  frame_type:string = \"data_blocked\";\r\n\r\n  limit:uint64;\r\n}\r\n\r\n...\r\n\r\n class MaxDataFrame{\r\n   frame_type:string = \"max_data\";\r\n\r\n   maximum:string;\r\n }\r\n```\r\n\r\nI was kindly informed in the QLog chatroom that this was inherited from `h3-27`. Fast forward to `h3-32` these fields have been unified to `maximum`. Therefore let's update the spec for consistency (with QUIC and within QLog itself).",
      "createdAt": "2020-12-03T02:06:08Z",
      "updatedAt": "2020-12-03T09:05:29Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "draft02",
      "baseRefOid": "197532463830d19b3e5b854f692951fc9a30ce9a",
      "headRepository": "toru/internet-drafts",
      "headRefName": "limit-to-maximum",
      "headRefOid": "9a655f213f4e5cf8dff12d83116cbdaaac028c4b",
      "closedAt": "2020-12-03T09:05:22Z",
      "mergedAt": "2020-12-03T09:05:22Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "153756069ad5d56a720bf730d673f2c74cf1c2cb"
      },
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Yeah, this is clearly an oversight.\r\nEspecially for this type of event/frame, the goal is to be fully consistent with the terminology in the QUIC texts. I just missed they re-named it there. \r\n\r\nThanks for the PR!",
          "createdAt": "2020-12-03T09:05:29Z",
          "updatedAt": "2020-12-03T09:05:29Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 138,
      "id": "MDExOlB1bGxSZXF1ZXN0NTkyNjg5Mzk3",
      "title": "introduce a VersionNegotiationError",
      "url": "https://github.com/quicwg/qlog/pull/138",
      "state": "OPEN",
      "author": "marten-seemann",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "When a client receives a Version Negotiation packet indicating that there's no commonly supported version, it aborts the connection attempt. Currently, qlog doesn't allow to log this.",
      "createdAt": "2021-03-15T02:43:58Z",
      "updatedAt": "2021-06-02T12:12:27Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "d4b62cd84b73338c8be1b749f7686cccd2754967",
      "headRepository": "marten-seemann/internet-drafts",
      "headRefName": "version-negotiation-error",
      "headRefOid": "d532844064683e5a3c229d64ff1df541d99bfd2a",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "body": "Thinking about it, I'm not so sure about it any more. For stateless reset, we already use the `trigger` field. Maybe we should do the same for VN? Then we could close this PR.",
          "createdAt": "2021-03-15T05:28:52Z",
          "updatedAt": "2021-03-15T05:28:52Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I think my intention here was that:\r\n- client logs `connection_closed` with trigger of value `version_mismatch` (which is already in -02, though potentially not perfectly named). Did you maybe miss that trigger? \r\n- to know which versions were offered and supported by both sides, you'd use the `version_information` event and `supported_versions` fields of `packet_sent/received` (see discussion in https://github.com/quiclog/internet-drafts/issues/75)\r\n\r\nI agree this is slightly more tedious than having all of that together in a single event, but IIUC your last reply here, that isn't very critical. \r\n",
          "createdAt": "2021-03-18T14:55:25Z",
          "updatedAt": "2021-03-18T14:55:25Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 145,
      "id": "MDExOlB1bGxSZXF1ZXN0NjA2MDQ1Nzc0",
      "title": "Add myself as editor",
      "url": "https://github.com/quicwg/qlog/pull/145",
      "state": "CLOSED",
      "author": "lnicco",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-03-31T17:22:06Z",
      "updatedAt": "2021-05-01T13:26:41Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "d4b62cd84b73338c8be1b749f7686cccd2754967",
      "headRepository": "lnicco/internet-drafts",
      "headRefName": "luca_author",
      "headRefOid": "1cfa1f014ae74189b8a4b7fb7f14b3944e95f021",
      "closedAt": "2021-05-01T13:26:41Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Forgot to merge this before starting a separate branch for the pre-adoption changes, so made the changes manually in #155 :) ",
          "createdAt": "2021-05-01T13:26:41Z",
          "updatedAt": "2021-05-01T13:26:41Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 151,
      "id": "MDExOlB1bGxSZXF1ZXN0NjE1ODQ3ODA1",
      "title": "Remove event field (only name is preferred in draft-02)",
      "url": "https://github.com/quicwg/qlog/pull/151",
      "state": "MERGED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #149 ",
      "createdAt": "2021-04-15T08:37:38Z",
      "updatedAt": "2021-04-15T09:28:33Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "d4b62cd84b73338c8be1b749f7686cccd2754967",
      "headRepository": "quicwg/qlog",
      "headRefName": "remove-extra-events",
      "headRefOid": "1862d3f97ca9298a380931ac74d4c895416f8a8f",
      "closedAt": "2021-04-15T09:28:33Z",
      "mergedAt": "2021-04-15T09:28:33Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "d820822898dc3cd9030d32f491d7c3b1cb964cac"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjM2NDUxNTg1",
          "commit": {
            "abbreviatedOid": "1862d3f"
          },
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-04-15T09:06:25Z",
          "updatedAt": "2021-04-15T09:06:25Z",
          "comments": []
        }
      ]
    },
    {
      "number": 155,
      "id": "MDExOlB1bGxSZXF1ZXN0NjI4NDMxNzY4",
      "title": "Prepare for adoption",
      "url": "https://github.com/quicwg/qlog/pull/155",
      "state": "MERGED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "This PR tracks the changes necessary to prepare for adoption by the QUIC wg as defined in #137.\r\n\r\nIt currently contains all the text changes, still requiring a few other things after they are approved (remove old document files, switch master branch to main, submit updated docs as individual drafts for the adoption call.",
      "createdAt": "2021-05-01T13:19:29Z",
      "updatedAt": "2021-05-17T18:56:09Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "master",
      "baseRefOid": "d820822898dc3cd9030d32f491d7c3b1cb964cac",
      "headRepository": "quicwg/qlog",
      "headRefName": "pre-adoption",
      "headRefOid": "8953dda487e4492c2d47e9778f22452283e7ea71",
      "closedAt": "2021-05-15T19:31:24Z",
      "mergedAt": "2021-05-15T19:31:24Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "514b0d461f607dfac00097a461969d3d3fc74ddb"
      },
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "For those of you who don't use a local checkout of this to view the resulting HTML after the changes, I've attached them separately:\r\n\r\n[pre-adoption-html-v1.zip](https://github.com/quiclog/internet-drafts/files/6409599/pre-adoption-html-v1.zip)\r\n",
          "createdAt": "2021-05-01T13:23:01Z",
          "updatedAt": "2021-05-01T13:23:01Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Two other points raised by Lucas:\r\n- Add more information about \"previous versions\" (e.g., two main versions in production, -01 and -02, those pre-date these adopted documents)\r\n- Define a new version codepoint for the adopted drafts (now it's still draft-03-wip, but we also can't just do draft-00 or we'll overlap soon. Maybe qlog-0x?)",
          "createdAt": "2021-05-03T12:37:59Z",
          "updatedAt": "2021-05-03T12:37:59Z"
        },
        {
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "body": "Do we  also need independent versioning of the different schema? How does qlog evolve over the years? For example, say the main schema got published as 1.0, and then work commenced on 2.0. Can there be a QUIC qlog event definitions 1.1 (which is updated say to support QUIC v2) and a 2.1 (which is updated to support QUIC v2 and a new main schema format)? \r\n\r\nThere's a lot of possible bikeshedding here. For now, maybe you just want to keep your linear versioning scheme (qlog 01, 02, and next 03) and make it clear that it is decoupled from any document draft id version.\r\n",
          "createdAt": "2021-05-05T23:45:34Z",
          "updatedAt": "2021-05-05T23:45:34Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thanks all for the reviews! \r\n\r\n@lnicco I fully agree that the current text isn't really fit for a proper I-D and especially eventual RFC. I'm hoping we can make things much stricter and clearer following wg consensus on some main points. I'm also hoping the new editors will help re-write some things when that happens ;) \r\n\r\n\r\nI have just fixed the remarks (hopefully), merged the PR and tried to submit the new drafts to the datatracker. \r\nI ran into some problems due to not being familiar with the process there though, doing something different for all 3 documents...\r\n\r\n- main-schema-03 should be published as normal (was somehow auto-posted to the QUIC list...)\r\n- quic-events-00 somehow ended up as having to go through a manual review process (editors got an email about that)\r\n- h3-events-00 has to be approved by the QUIC wg chairs first (no clue why/how that triggered, but @LPardue got an email for that, so...)\r\n\r\nSo you'll probably see some weird emails and the 2 event-definition documents are somewhat delayed behind main-schema, but hopefully things will be sorted soon!\r\n\r\n",
          "createdAt": "2021-05-15T20:17:16Z",
          "updatedAt": "2021-05-15T20:17:16Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "After guidance from the QUIC wg chairs, I have now cancelled submission of:\r\n- draft-marx-qlog-quic-events-00\r\n- draft-marx-qlog-h3-events-00\r\n\r\nAnd instead re-submitted as:\r\n- draft-marx-quic-qlog-quic-events-00\r\n- draft-marx-quic-qlog-h3-events-00\r\n\r\nto make it clearer these are adoption candidates. These are both still pending approval from the QUIC wg chairs, so not quite published yet. \r\n\r\n",
          "createdAt": "2021-05-17T09:07:41Z",
          "updatedAt": "2021-05-17T09:07:41Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "The soap continued... apparently this all triggered a bug in datatracker when trying to replace documents that are in pre-adoption with a wg (it's not quite a compiler bug, but I'll take it for now ;)). \r\n\r\nThe chosen solution is to submit the new drafts again, without indicating they replace the old joint h3+quic events draft. The idea is that the backlinking will be corrected post-adoption.\r\n\r\nFor clarity, these are the most recent drafts that the adoption call will be issued for:\r\n- https://datatracker.ietf.org/doc/draft-marx-quic-qlog-h3-events/\r\n- https://datatracker.ietf.org/doc/draft-marx-quic-qlog-quic-events/\r\n- https://datatracker.ietf.org/doc/draft-marx-qlog-main-schema/\r\n",
          "createdAt": "2021-05-17T18:56:09Z",
          "updatedAt": "2021-05-17T18:56:09Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwMjg4NzQ4",
          "commit": {
            "abbreviatedOid": "8fb4412"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T12:03:26Z",
          "updatedAt": "2021-05-03T12:03:26Z",
          "comments": [
            {
              "originalPosition": 129,
              "body": "You could still point people to this repo in order to collect any adoption call feedback. Then, any and all issues can be brought across to the QUIC WG org when the repo is transferred. And we can update the URL to that new one when the adopted `-00` gets published.",
              "createdAt": "2021-05-03T12:03:26Z",
              "updatedAt": "2021-05-03T12:03:42Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwMjkyOTUx",
          "commit": {
            "abbreviatedOid": "8fb4412"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T12:10:31Z",
          "updatedAt": "2021-05-03T12:10:31Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "Is the intent to delete this file?",
              "createdAt": "2021-05-03T12:10:31Z",
              "updatedAt": "2021-05-03T12:10:31Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwMzE5NzM0",
          "commit": {
            "abbreviatedOid": "8fb4412"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T12:50:34Z",
          "updatedAt": "2021-05-03T12:50:34Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "Indeed, this one is removed and replaced by the two new ones.",
              "createdAt": "2021-05-03T12:50:34Z",
              "updatedAt": "2021-05-03T12:50:34Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUyODUyNjc5",
          "commit": {
            "abbreviatedOid": "8fb4412"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-05T23:36:44Z",
          "updatedAt": "2021-05-05T23:36:45Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "so uhh, why isn't it `git rm`'d ? :D",
              "createdAt": "2021-05-05T23:36:44Z",
              "updatedAt": "2021-05-05T23:36:45Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU1MDgwNDM3",
          "commit": {
            "abbreviatedOid": "8fb4412"
          },
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM, but as @LPardue pointed out, don't we need to delete the old documents?",
          "createdAt": "2021-05-09T13:46:54Z",
          "updatedAt": "2021-05-09T13:46:54Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU1ODU1MjE0",
          "commit": {
            "abbreviatedOid": "8fb4412"
          },
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Looks good to me. Thanks Robin for doing this.\r\n\r\nI have a couple minor comments and a generic comment about considering making the document more strict in the future. \r\nRight now it reads like a \"hands on experience\" document, which is a great start but I think the end goal could be to make some of the text more strict to provide more precise guidelines to QLOG (and QLOG tools) implementors. \r\n\r\nBut that's a separate discussion. \r\nShip it!",
          "createdAt": "2021-05-10T16:44:54Z",
          "updatedAt": "2021-05-10T20:19:40Z",
          "comments": [
            {
              "originalPosition": 145,
              "body": "why is HTTPS2 and HTTP3 ? \r\nIf Secure is implicit with QUIC but not with TCP, maybe this should be `[\"TCP\", \"TLS\", \"HTTP2\"]` ? ",
              "createdAt": "2021-05-10T16:44:55Z",
              "updatedAt": "2021-05-10T20:19:40Z"
            },
            {
              "originalPosition": 206,
              "body": "I think this is fine for now, but it could be more prescriptive in the future. \r\nAllowing total freedom in the events definition can make the development of generic tools harder. ",
              "createdAt": "2021-05-10T17:24:57Z",
              "updatedAt": "2021-05-10T20:19:40Z"
            },
            {
              "originalPosition": 198,
              "body": "is this a SHOULD ? not sure",
              "createdAt": "2021-05-10T20:13:59Z",
              "updatedAt": "2021-05-10T20:19:40Z"
            }
          ]
        }
      ]
    },
    {
      "number": 161,
      "id": "MDExOlB1bGxSZXF1ZXN0NjgxNjU3NDgx",
      "title": "Rename stream_id to id for the GOAWAY frame",
      "url": "https://github.com/quicwg/qlog/pull/161",
      "state": "MERGED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #160. Oversight when keeping up with the latest H3 drafts.",
      "createdAt": "2021-07-01T09:15:05Z",
      "updatedAt": "2021-07-01T12:48:40Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "d7af14438aeefd3d24a8d76d41352515ff0ed3ff",
      "headRepository": "quicwg/qlog",
      "headRefName": "goaway-id",
      "headRefOid": "698cc5790d1d1bd9ce11b3cd6d49d528e0821067",
      "closedAt": "2021-07-01T12:48:29Z",
      "mergedAt": "2021-07-01T12:48:29Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "56b907899f5e20a58dfa651d6922377d3108effd"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk3MTYyMjQ4",
          "commit": {
            "abbreviatedOid": "698cc57"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-01T12:06:15Z",
          "updatedAt": "2021-07-01T12:06:15Z",
          "comments": []
        }
      ]
    },
    {
      "number": 162,
      "id": "MDExOlB1bGxSZXF1ZXN0NjgxODI5MTI2",
      "title": "circles are so 2020",
      "url": "https://github.com/quicwg/qlog/pull/162",
      "state": "MERGED",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-07-01T12:52:36Z",
      "updatedAt": "2021-08-18T09:42:39Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "56b907899f5e20a58dfa651d6922377d3108effd",
      "headRepository": "quicwg/qlog",
      "headRefName": "closing-the-loop-on-the-circle",
      "headRefOid": "5e8c4ed7fb8c7d4780c9958b3c08b7b40786f476",
      "closedAt": "2021-08-18T09:42:39Z",
      "mergedAt": "2021-08-18T09:42:39Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "5796bb5a608d2459fa03fa5782d7c2ad71cc9ab0"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 177,
      "id": "PR_kwDOCrLn6M4r8_iN",
      "title": "Fix 0RTT and 1RTT definitions in PacketType",
      "url": "https://github.com/quicwg/qlog/pull/177",
      "state": "MERGED",
      "author": "lnicco",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes #128\n",
      "createdAt": "2021-09-20T09:41:50Z",
      "updatedAt": "2021-10-06T09:53:58Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "27690bdf78b94592ffe21e70c8ade862b2e64036",
      "headRepository": "quicwg/qlog",
      "headRefName": "fix_packet_type",
      "headRefOid": "f1eb852fd7628daccaa38ed74a6b62c1799f2e14",
      "closedAt": "2021-10-06T09:53:51Z",
      "mergedAt": "2021-10-06T09:53:51Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "a64268dc17a7beebbf8df7567da8a5cf2ac360d3"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOCrLn6M4tNVcS",
          "commit": {
            "abbreviatedOid": "f1eb852"
          },
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-20T10:28:30Z",
          "updatedAt": "2021-09-20T10:28:37Z",
          "comments": [
            {
              "originalPosition": 6,
              "body": "nit: one could argue that RTT should be lowercase for consistency with the other types.",
              "createdAt": "2021-09-20T10:28:31Z",
              "updatedAt": "2021-09-20T10:28:37Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4tNWV0",
          "commit": {
            "abbreviatedOid": "f1eb852"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-20T10:33:19Z",
          "updatedAt": "2021-09-20T10:33:19Z",
          "comments": [
            {
              "originalPosition": 6,
              "body": "Somewhat disagree. RTT is an acronym and the others are not. The RFCs also use the uppercased version of this. Finally, for backwards-compat with existing qlog implementations, 0RTT and 1RTT is easiest. ",
              "createdAt": "2021-09-20T10:33:19Z",
              "updatedAt": "2021-09-20T10:33:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4tb-Lh",
          "commit": {
            "abbreviatedOid": "f1eb852"
          },
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-23T17:25:32Z",
          "updatedAt": "2021-09-23T17:25:32Z",
          "comments": [
            {
              "originalPosition": 6,
              "body": "@rmarx sounds good. \r\nAre there any other concerns, or can this be merged?",
              "createdAt": "2021-09-23T17:25:32Z",
              "updatedAt": "2021-09-23T17:25:32Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4uCpOS",
          "commit": {
            "abbreviatedOid": "f1eb852"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-06T09:53:57Z",
          "updatedAt": "2021-10-06T09:53:58Z",
          "comments": [
            {
              "originalPosition": 6,
              "body": "This is fine I think. \r\n\r\nFor other, larger changes, we'd ideally also add an entry in the changelist on the bottom. But this is such a small thing that it's not needed. ",
              "createdAt": "2021-10-06T09:53:57Z",
              "updatedAt": "2021-10-06T09:53:58Z"
            }
          ]
        }
      ]
    },
    {
      "number": 181,
      "id": "PR_kwDOCrLn6M4tcxPk",
      "title": "Move from NDJSON to JSON Text Sequences",
      "url": "https://github.com/quicwg/qlog/pull/181",
      "state": "MERGED",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Additionally also specified Media Types and file extensions for the various formats\r\n\r\nPertains to #180, #172 and #158.",
      "createdAt": "2021-10-20T16:23:17Z",
      "updatedAt": "2021-10-25T11:42:35Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "b56e74ab9c2e3a09edfc37985d840d2587bcd8cd",
      "headRepository": "quicwg/qlog",
      "headRefName": "text-sequences",
      "headRefOid": "46a5b051afc2837bcb091e93e1f9000bcd0ec170",
      "closedAt": "2021-10-25T11:42:35Z",
      "mergedAt": "2021-10-25T11:42:35Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "0a0d7a78c492ff0fa0b3845b467731fd5cbc711c"
      },
      "comments": [
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Hello all,\r\n\r\nI've tried to resolve all the excellent comments as well as possible. \r\n\r\nIf you have time, please try to review the new changes, and then I will mint a new draft-01 tomorrow!",
          "createdAt": "2021-10-24T10:42:55Z",
          "updatedAt": "2021-10-24T10:42:55Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOCrLn6M4u0vwh",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "marten-seemann",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-21T11:46:42Z",
          "updatedAt": "2021-10-21T11:52:35Z",
          "comments": [
            {
              "originalPosition": 122,
              "body": "```suggestion\r\nqlog event is interpreted as an individual JSON Text Sequence record, and can\r\n```",
              "createdAt": "2021-10-21T11:46:42Z",
              "updatedAt": "2021-10-21T11:52:35Z"
            },
            {
              "originalPosition": 166,
              "body": "Is there any way we can make it more obvious that `RS` are not the ASCII characters `R` and `S`?",
              "createdAt": "2021-10-21T11:47:49Z",
              "updatedAt": "2021-10-21T11:52:35Z"
            },
            {
              "originalPosition": 367,
              "body": "Is this correct? Wouldn't the media type be `application/gzip` or something like that?",
              "createdAt": "2021-10-21T11:52:10Z",
              "updatedAt": "2021-10-21T11:52:35Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u06Z8",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-21T12:29:26Z",
          "updatedAt": "2021-10-21T12:29:27Z",
          "comments": [
            {
              "originalPosition": 8,
              "body": "It would be good to provide a reference for JSON and/or JSON Text Sequences here.",
              "createdAt": "2021-10-21T12:29:27Z",
              "updatedAt": "2021-10-21T12:29:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u0--v",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-21T12:45:26Z",
          "updatedAt": "2021-10-21T13:21:30Z",
          "comments": [
            {
              "originalPosition": 32,
              "body": "We should think strongly about version management moving forward. It appears here that you are reverting back to linking the version of qlog to the version of I-D revision. That has some serious downsides:\r\n\r\n1. I-Ds are cheap. We should be releasing them at a pace it make sense for the contents of an I-D, including non-functional editorial changes.\r\n1. Conversely, having the draft version tied to meaningful changes encourages not releasing new drafts. Or means that people need to alias multiple draft versions as the same logical thing.\r\n1. We have 3 documents. Needing to synchronize those draft versions adds coordination overhead\r\n\r\nAt this point, I would recommend versioning that is decoupled from the I-D versions. That way, you can simply change the \"qlog_version\" whenever you like and people have a clearer idea of the intention. You might also want to start at version `00` then.\r\n",
              "createdAt": "2021-10-21T12:45:27Z",
              "updatedAt": "2021-10-21T13:21:30Z"
            },
            {
              "originalPosition": 65,
              "body": "if this is a normative recommendation, the reference should be too. This applies to other instances and other refs.\r\n\r\n```suggestion\r\nand the Media Type (if any) SHOULD be \"application/qlog+json\" {{!RFC6839}}.\r\n```",
              "createdAt": "2021-10-21T12:47:16Z",
              "updatedAt": "2021-10-21T13:21:30Z"
            },
            {
              "originalPosition": 166,
              "body": "What I would do here is update the above comment to say something like \r\n\r\n```\r\n// list of qlog events, serialized in accordance with RFC 7464.\r\n// For display purposes, record separators are rendered as <RS>\r\n```\r\n\r\nand then use <RS> (which is what RFC 7464 does)",
              "createdAt": "2021-10-21T12:58:29Z",
              "updatedAt": "2021-10-21T13:21:30Z"
            },
            {
              "originalPosition": 201,
              "body": "I think it would help to move these notes above the example. The use of newlines in the body was a little surprise!",
              "createdAt": "2021-10-21T13:02:01Z",
              "updatedAt": "2021-10-21T13:21:30Z"
            },
            {
              "originalPosition": 327,
              "body": "I opened https://github.com/NTAP/isb-ietf-config/issues/10",
              "createdAt": "2021-10-21T13:11:17Z",
              "updatedAt": "2021-10-21T13:21:30Z"
            },
            {
              "originalPosition": 364,
              "body": "what is cbor-seq? Maybe just a typo?",
              "createdAt": "2021-10-21T13:21:08Z",
              "updatedAt": "2021-10-21T13:21:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u4EQ6",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-22T05:50:25Z",
          "updatedAt": "2021-10-22T05:50:26Z",
          "comments": [
            {
              "originalPosition": 148,
              "body": "I have a question that is most likely something you'll tell me to spin off as a new issue (and maybe relates to the planned schema chages CDDL), but I'l mention it here since you're touching things. Not taking action in this PR is ok but I think it might need answering long term.\r\n\r\nBased on the definition of `class QLogFile` and `class QlogFileSeq`, the only difference seems to be that `traces: Array<Trace>` vs `trace: Trace`.\r\n\r\n Now if I read the prose, it suggests that the JSON-SEQ version of `Trace` is actually different because it doesn't contain events.\r\n\r\nThere's inconsistency of approach here. On one hand, because there is a difference in cardinality of traces, you are defining two different `file` types. On the other hand, there is a different in cardinality of events but you don't define two different trace types. It would seem better to me to have a consistent approach - either a single `file` type that can accommodate the different requirements of traces, **or** multiple trace types for JSON and JSON-SEQ respectively.",
              "createdAt": "2021-10-22T05:50:25Z",
              "updatedAt": "2021-10-22T05:50:41Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u6Bqm",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-22T15:00:29Z",
          "updatedAt": "2021-10-22T15:00:30Z",
          "comments": [
            {
              "originalPosition": 166,
              "body": "Agreed that this is needed and I like Lucas' suggestion",
              "createdAt": "2021-10-22T15:00:30Z",
              "updatedAt": "2021-10-22T15:00:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u6DMl",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-22T15:05:53Z",
          "updatedAt": "2021-10-22T15:05:53Z",
          "comments": [
            {
              "originalPosition": 32,
              "body": "That's a good point... I just keep bikeshedding version names in my mind...\r\n\r\n- `ietf-00` is a bit weird, as older drafts were also at the IETF...\r\n- `00` is also a bit weird, since we'd probably like that for the final versions\r\n- `WIP-00` is ok, but I like to keep WIP versions for editor's copies (e.g., people already implementing and testing editor's copies before a new draft is minted. We had this previously between draft-01 and -02). Though maybe if we are more aggressive about releasing drafts this isn't needed anymore. \r\n- `0.1` (or similar semantic versioning) seems good enough, but then maybe it's nicer to start from 0.3 (keeping `draft-01` and `draft-02` as aliases for `0.1` and `0.2`? ",
              "createdAt": "2021-10-22T15:05:53Z",
              "updatedAt": "2021-10-22T15:05:53Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u6EUy",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-22T15:09:56Z",
          "updatedAt": "2021-10-22T15:09:56Z",
          "comments": [
            {
              "originalPosition": 364,
              "body": "This strangely actually exists, see https://www.iana.org/assignments/media-type-structured-suffix/media-type-structured-suffix.xhtml and https://www.rfc-editor.org/rfc/rfc8742.html\r\n\r\nWasn't sure how to refer to that registry though... maybe also just link to the RFC?",
              "createdAt": "2021-10-22T15:09:56Z",
              "updatedAt": "2021-10-22T15:09:56Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u6E4s",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-22T15:11:58Z",
          "updatedAt": "2021-10-22T15:11:58Z",
          "comments": [
            {
              "originalPosition": 148,
              "body": "I understand what you're saying and feel this should be fixed in this PR, not a separate issue. \r\n\r\nI think defining a new Trace class is probably the best way forward here. The exact way of defining that will change with CDDL, but for now making this more explicit is probably best. ",
              "createdAt": "2021-10-22T15:11:58Z",
              "updatedAt": "2021-10-22T15:11:58Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u6GMv",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-22T15:16:35Z",
          "updatedAt": "2021-10-22T15:16:35Z",
          "comments": [
            {
              "originalPosition": 32,
              "body": "yes, picking the answer here is tricky.\r\n\r\nI agree we should keep WIP for the changes-in-flight between one version and the next.\r\n\r\nSemantic versioning could be ok, since we won't be stablising things until \"1.0\" which would coincide with an RFC. However, I wonder how that might break any current qlog tools because its a departure from the kind of format already used. If there's not trouble there then I can get behind a \"0.3\".\r\n",
              "createdAt": "2021-10-22T15:16:35Z",
              "updatedAt": "2021-10-22T15:16:35Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u6LKf",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-22T15:35:25Z",
          "updatedAt": "2021-10-22T15:35:25Z",
          "comments": [
            {
              "originalPosition": 364,
              "body": "interesting! And it's cool that RFC 8742 mentions how JSON-SEQ and CBOR-SEQ relate to each other. \r\n\r\nI think the most straightforward way for now is to leave the table simple but highlight the releationship between these two in the {{binary}} section.",
              "createdAt": "2021-10-22T15:35:25Z",
              "updatedAt": "2021-10-22T15:35:25Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u7-Ag",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-24T06:18:19Z",
          "updatedAt": "2021-10-24T06:18:19Z",
          "comments": [
            {
              "originalPosition": 120,
              "body": "`\"records\"` (with quotes) feels a bit colloquial. \r\nI'd say use either `records` (no quotes), or just `objects` ? ",
              "createdAt": "2021-10-24T06:18:19Z",
              "updatedAt": "2021-10-24T06:18:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u7-HX",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-24T06:23:49Z",
          "updatedAt": "2021-10-24T06:23:50Z",
          "comments": [
            {
              "originalPosition": 239,
              "body": "NIT: \r\nif `\".(s)qlog.A.B\"` is meant to be a regex should it be \".(s)?qlog.A.B\" ?\r\nBut that would impact readability perhaps. Not feeling strongly about this, just pointing it out",
              "createdAt": "2021-10-24T06:23:50Z",
              "updatedAt": "2021-10-24T06:23:50Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u8DQ8",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-24T10:23:47Z",
          "updatedAt": "2021-10-24T10:23:47Z",
          "comments": [
            {
              "originalPosition": 239,
              "body": "It's not meant to be a regex, as I assume a letter encased in ( ) would mean optional to the reader, much like in normal prose. ",
              "createdAt": "2021-10-24T10:23:47Z",
              "updatedAt": "2021-10-24T10:23:47Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u8DZk",
          "commit": {
            "abbreviatedOid": "8cb5956"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-24T10:29:55Z",
          "updatedAt": "2021-10-24T10:29:55Z",
          "comments": [
            {
              "originalPosition": 32,
              "body": "I feel like the format change shouldn't matter for tooling, as they should have been handling the version as an opaque string. At least for qvis, this would mean just aliasing 0.3 to our existing draft-02 parser (with some extra checks for JSON-SEQ). \r\n\r\nAs supporters of 0.3 need to make changes for JSON-SEQ anyway, I think this shouldn't be a problem and a good way forward in general, so I've made the change. ",
              "createdAt": "2021-10-24T10:29:55Z",
              "updatedAt": "2021-10-24T10:29:55Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M4u8KnH",
          "commit": {
            "abbreviatedOid": "f4ba514"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "APPROVED",
          "body": "Design changes LGTM.\r\n\r\nThere are some broader editorial improvements that could be made but they can be done later on (when we're not up agaisnt the publish cutoff date).",
          "createdAt": "2021-10-24T15:16:00Z",
          "updatedAt": "2021-10-24T15:16:00Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOCrLn6M4u8Liu",
          "commit": {
            "abbreviatedOid": "f4ba514"
          },
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-10-24T15:56:55Z",
          "updatedAt": "2021-10-24T15:56:55Z",
          "comments": []
        }
      ]
    },
    {
      "number": 189,
      "id": "PR_kwDOCrLn6M4yzX0_",
      "title": "Fix main schema build errors and wrapping",
      "url": "https://github.com/quicwg/qlog/pull/189",
      "state": "MERGED",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "- main: temporarily remove {: .language-json} tags until diagrams are changed\r\n- main: wrap lines to appease xml2rfc\r\n\r\nHelps address part of #188.\r\n\r\nIn this spec, you have a fundamental problem that the json in examples is malformed and kramdown complains. So let's just disable that for now. \r\n\r\nThe rest of the changes are tedious but also not too onerous. The main issue you have is that there's lots of comments here and there that break length limits. So I've just picked a line length that will appease xml2rfc. \r\n\r\nIn some cases, you have comments inside JSON, which won't work. In one case I deleted some because the qlog properties might get deleted anyway.\r\n\r\nThe changes you have in mind might have obviated the errors anyway. But if not, these changes will set a strong foundation to know how to shut xml2rfc up.",
      "createdAt": "2022-02-14T17:30:05Z",
      "updatedAt": "2022-02-18T11:17:39Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "0a0d7a78c492ff0fa0b3845b467731fd5cbc711c",
      "headRepository": "quicwg/qlog",
      "headRefName": "lucas/fix-main-schema",
      "headRefOid": "335cdbc19b1195a62e75e6c3682b9ce884ea5cb6",
      "closedAt": "2022-02-18T11:17:39Z",
      "mergedAt": "2022-02-18T11:17:39Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "fac519ace6ed637d406170db1aab36768a3b730e"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOCrLn6M40kdTh",
          "commit": {
            "abbreviatedOid": "335cdbc"
          },
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-02-14T17:34:18Z",
          "updatedAt": "2022-02-14T17:34:19Z",
          "comments": [
            {
              "originalPosition": 289,
              "body": "Why these changes?",
              "createdAt": "2022-02-14T17:34:18Z",
              "updatedAt": "2022-02-14T17:34:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M40kiYK",
          "commit": {
            "abbreviatedOid": "335cdbc"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-02-14T17:52:41Z",
          "updatedAt": "2022-02-14T17:52:41Z",
          "comments": [
            {
              "originalPosition": 289,
              "body": "in this specific case, the newlines matter. While the format does support them, it might confuse readers. So I changed the events to ones that had a slightly shorter name but still seemed to be semantically valid.",
              "createdAt": "2022-02-14T17:52:41Z",
              "updatedAt": "2022-02-14T17:52:41Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M40kjRY",
          "commit": {
            "abbreviatedOid": "335cdbc"
          },
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-02-14T17:55:55Z",
          "updatedAt": "2022-02-14T17:55:56Z",
          "comments": [
            {
              "originalPosition": 289,
              "body": "Ok.",
              "createdAt": "2022-02-14T17:55:55Z",
              "updatedAt": "2022-02-14T17:55:56Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M40kjSY",
          "commit": {
            "abbreviatedOid": "335cdbc"
          },
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-02-14T17:55:58Z",
          "updatedAt": "2022-02-14T17:55:58Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOCrLn6M404Mog",
          "commit": {
            "abbreviatedOid": "335cdbc"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-02-18T11:16:56Z",
          "updatedAt": "2022-02-18T11:16:56Z",
          "comments": []
        }
      ]
    },
    {
      "number": 190,
      "id": "PR_kwDOCrLn6M4yzYaa",
      "title": "Fix H3 and QPACK wrapping",
      "url": "https://github.com/quicwg/qlog/pull/190",
      "state": "MERGED",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "Fixes part of #188. The changes are tedious but also not too onerous. The main issue you have is that there's lots of comments here and there that break length limits. So I've just picked a line length that will appease xml2rfc.\r\n\r\nThe changes you have in mind might have obviated the errors anyway. But if not, these changes will set a strong foundation to know how to shut xml2rfc up.",
      "createdAt": "2022-02-14T17:32:31Z",
      "updatedAt": "2022-02-18T11:20:22Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "0a0d7a78c492ff0fa0b3845b467731fd5cbc711c",
      "headRepository": "quicwg/qlog",
      "headRefName": "lucas/fix-h3-line-width",
      "headRefOid": "a527786789d2349b0f308f26dc0cb24a94b144f1",
      "closedAt": "2022-02-18T11:20:22Z",
      "mergedAt": "2022-02-18T11:20:22Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "8dd481ad98f85bc5db16fc8d01bdf20b312f39e1"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOCrLn6M40kePg",
          "commit": {
            "abbreviatedOid": "a527786"
          },
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-02-14T17:37:37Z",
          "updatedAt": "2022-02-14T17:37:37Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOCrLn6M40kyym",
          "commit": {
            "abbreviatedOid": "a527786"
          },
          "author": "LPardue",
          "authorAssociation": "MEMBER",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-02-14T18:56:05Z",
          "updatedAt": "2022-02-14T18:56:05Z",
          "comments": [
            {
              "originalPosition": 3,
              "body": "yes, xml2rfc even moans about the title length :laughing: ",
              "createdAt": "2022-02-14T18:56:05Z",
              "updatedAt": "2022-02-14T18:56:05Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M404NaP",
          "commit": {
            "abbreviatedOid": "a527786"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-02-18T11:20:14Z",
          "updatedAt": "2022-02-18T11:20:14Z",
          "comments": []
        }
      ]
    },
    {
      "number": 191,
      "id": "PR_kwDOCrLn6M4yzg_L",
      "title": "Fix QUIC events wrapping and errors",
      "url": "https://github.com/quicwg/qlog/pull/191",
      "state": "MERGED",
      "author": "LPardue",
      "authorAssociation": "MEMBER",
      "assignees": [],
      "labels": [],
      "body": "- quic: fix artwork line length\r\n- quic: stick commas between refs to unfool xml2rfc\r\n\r\nFixes part of https://github.com/quicwg/qlog/issues/188. The changes are tedious but also not too onerous. The main issue you have is that there's lots of comments here and there that break length limits. So I've just picked a line length that will appease xml2rfc.\r\n\r\nThe changes you have in mind might have obviated the errors anyway. But if not, these changes will set a strong foundation to know how to shut xml2rfc up.",
      "createdAt": "2022-02-14T18:11:09Z",
      "updatedAt": "2022-02-18T11:23:19Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "0a0d7a78c492ff0fa0b3845b467731fd5cbc711c",
      "headRepository": "quicwg/qlog",
      "headRefName": "lucas/fix-quic-events",
      "headRefOid": "fd68ca3d9f5f60beaaf9c62f48d9538afc10c640",
      "closedAt": "2022-02-18T11:23:19Z",
      "mergedAt": "2022-02-18T11:23:19Z",
      "mergedBy": "rmarx",
      "mergeCommit": {
        "oid": "9b28c154492e6dac2491dfded48d2def56ed3179"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOCrLn6M40kqpr",
          "commit": {
            "abbreviatedOid": "fd68ca3"
          },
          "author": "nibanks",
          "authorAssociation": "MEMBER",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-02-14T18:23:19Z",
          "updatedAt": "2022-02-14T18:23:19Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOCrLn6M404OEU",
          "commit": {
            "abbreviatedOid": "fd68ca3"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-02-18T11:23:10Z",
          "updatedAt": "2022-02-18T11:23:10Z",
          "comments": []
        }
      ]
    },
    {
      "number": 193,
      "id": "PR_kwDOCrLn6M4zLk9j",
      "title": "Move to CDDL - main schema",
      "url": "https://github.com/quicwg/qlog/pull/193",
      "state": "OPEN",
      "author": "rmarx",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "This PR bundles the TypeScript-to-CDDL changes for draft 0.4 for the main schema document (see other PRs for the QUIC and H3/QPACK documents). \r\n\r\nList of intended changes:\r\n\r\n- [x] Replace TypeScript with CDDL descriptions\r\n- [x] Split up CDDL definitions and JSON examples\r\n- [ ] Properly explain the $ProtocolEventBody extension point + include trigger in the example \r\n- [ ] Properly discuss how event docs should define triggers in the CDDL \r\n- [ ] Replace TypeScript explanation in `Notational Conventions` and `qlog to JSON mapping` with CDDL and I-JSON references, basic explanations and considerations\r\n- [ ] Explain the need for custom uint64 and hexstring CDDL types\r\n",
      "createdAt": "2022-02-19T19:09:46Z",
      "updatedAt": "2022-02-25T08:19:38Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "9b28c154492e6dac2491dfded48d2def56ed3179",
      "headRepository": "quicwg/qlog",
      "headRefName": "cddl-main-04",
      "headRefOid": "05f015f5517e95b2b95aa779bf081615fa9130dd",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOCrLn6M41PUK3",
          "commit": {
            "abbreviatedOid": "05f015f"
          },
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-02-25T02:26:00Z",
          "updatedAt": "2022-02-25T02:26:00Z",
          "comments": [
            {
              "originalPosition": 53,
              "body": "in #194 I have used `~~~~ cddl` to open the block instead of this line. \r\nIt seems to generate the same HTML, it's a bit less verbose and it also is easier to parse with some simple awk so I have found it to be quite handy of a syntax compared to what you are using here.\r\n\r\nIt would be nice to keep things consistent. ",
              "createdAt": "2022-02-25T02:26:00Z",
              "updatedAt": "2022-02-25T02:26:00Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOCrLn6M41P_fe",
          "commit": {
            "abbreviatedOid": "05f015f"
          },
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-02-25T08:19:38Z",
          "updatedAt": "2022-02-25T08:19:38Z",
          "comments": [
            {
              "originalPosition": 53,
              "body": "I agree your approach is probably the better option (and potentially makes it easier to extract CDDL from the markdown docs), so I'll change my side. Thanks!",
              "createdAt": "2022-02-25T08:19:38Z",
              "updatedAt": "2022-02-25T08:19:38Z"
            }
          ]
        }
      ]
    },
    {
      "number": 194,
      "id": "PR_kwDOCrLn6M4zMoiq",
      "title": "Move to CDDL - HTTP3, QPACK",
      "url": "https://github.com/quicwg/qlog/pull/194",
      "state": "OPEN",
      "author": "lnicco",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-02-21T00:34:43Z",
      "updatedAt": "2022-02-25T02:23:11Z",
      "baseRepository": "quicwg/qlog",
      "baseRefName": "main",
      "baseRefOid": "9b28c154492e6dac2491dfded48d2def56ed3179",
      "headRepository": "quicwg/qlog",
      "headRefName": "cddl_http3",
      "headRefOid": "ddb29ce8fcebf472a18bec8cf1b4e816593685be",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "body": "I have checked the CDDL syntax with this command \r\n```\r\ncat draft-ietf-quic-qlog-h3-events.md | awk 'BEGIN{flag=0} /~~~ cddl-definition/{flag=1; printf \"\\n\"; next} /~~~/{flag=0; next} flag' | cddl - generate | jq .\r\n``` \r\n\r\nmost definitions are unused though at this time \r\ncommand output\r\n```\r\n*** Unused rule HTTP3ParametersRestore\r\n*** Unused rule HTTP3StreamType\r\n*** Unused rule HTTP3StreamTypeSet\r\n*** Unused rule HTTP3FrameCreated\r\n*** Unused rule HTTP3FrameParsed\r\n*** Unused rule HTTP3PushResolved\r\n*** Unused rule QPACKStateUpdate\r\n*** Unused rule QPACKStreamStateUpdate\r\n*** Unused rule QPACKStreamState\r\n*** Unused rule QPACKDynamicTableUpdate\r\n*** Unused rule QPACKDynamicTableUpdateType\r\n*** Unused rule QPACKDynamicTableEntry\r\n*** Unused rule QPACKHeadersEncoded\r\n*** Unused rule QPACKHeadersDecoded\r\n*** Unused rule QPACKInstructionCreated\r\n*** Unused rule QPACKInstructionParsed\r\n*** Unused rule HTTP3Frame\r\n*** Unused rule HTTP3DataFrame\r\n*** Unused rule HTTP3HeadersFrame\r\n*** Unused rule HTTPHeader\r\n*** Unused rule HTTP3CancelPushFrame\r\n*** Unused rule HTTP3SettingsFrame\r\n*** Unused rule HTTP3Settings\r\n*** Unused rule HTTP3PushPromiseFrame\r\n*** Unused rule HTTP3GoawayFrame\r\n*** Unused rule HTTP3MaxPushIdFrame\r\n*** Unused rule HTTP3ReservedFrame\r\n*** Unused rule HTTP3ApplicationError\r\n*** Unused rule QPACKInstruction\r\n*** Unused rule SetDynamicTableCapacityInstruction\r\n*** Unused rule InsertWithNameReferenceInstruction\r\n*** Unused rule InsertWithoutNameReferenceInstruction\r\n*** Unused rule DuplicateInstruction\r\n*** Unused rule SectionAcknowledgementInstruction\r\n*** Unused rule StreamCancellationInstruction\r\n*** Unused rule InsertCountIncrementInstruction\r\n*** Unused rule QPACKHeaderBlockRepresentation\r\n*** Unused rule IndexedHeaderField\r\n*** Unused rule LiteralHeaderFieldWithName\r\n*** Unused rule LiteralHeaderFieldWithoutName\r\n*** Unused rule QPACKHeaderBlockPrefix\r\n*** Unused rule QPACKTableType\r\n{\r\n  \"bather\": 1044930698034052400,\r\n  \"upaithric\": 15980487929328420000,\r\n  \"uxorially\": 14932785096873822000,\r\n  \"verminer\": 3648320349101929000\r\n}\r\n```\r\n",
          "createdAt": "2022-02-21T00:37:27Z",
          "updatedAt": "2022-02-21T00:37:27Z"
        },
        {
          "author": "rmarx",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Hey @lnicco,\r\n\r\n Thanks for the work and the cool one-liner to extract CDDL from the draft.\r\n\r\nSome initial feedback:\r\n1. I've found that the CDDL tool doesn't really properly validate the \"unused rules\" so you need to make sure they are referenced somewhere. For the main schema I've forced this with kind of an ugly hack by adding the rules manually to a debugging definition ([see here](https://github.com/quiclog/qlog/blob/master/CDDL/schema/qlog-0.4.cddl#L175)). It's probably best to have that here as well (can even be in the draft for now imo).\r\n2. using the `~~~ cddl-definition` ends up with slightly different generated HTML than the main schema where I use the `{: .language-cddl}`. Your version generates `class=\"lang-cddl-definition sourcecode\"` while mine does `class=\"lang-cddl sourcecode\"`. I don't really care which method we use, as long as it creates consistent output. \r\n3. We're not totally consistent about how we use string \"enums\". E.g., you've added a separate `QPACKDynamicTableUpdateType`, but HTTP3PushResolved has an inline `decision: \"claimed\" / \"abandoned\"`. I'd prefer having separate types for these things (have done this in the main schema as well).\r\n4. You've prefixed the HTTP/3 type names with `HTTP3` instead of `HTTP`. My idea was that tools can eventually generate the qlog event name from the type names (i.e., `TransportPacketSent` can be transformed to `transport:packet_sent`). In this case, the category name is `http` and not `http3`, so your events should be called `HTTPMyEventName` not `HTTP3MyEventName`. At least for now... maybe we should discuss renaming the category to `http3` instead... (now I assumed it would be implied by the `protocol_type` field) cc @LPardue and see #146.\r\n5. I think now in CDDL you can indeed have a single definition for FrameParsed and FrameCreated and have both alias to that.   \r\n6. Please also run the `make` command (at least for the final PR commit). This didn't have glaring errors, but a few trailing whitespaces (fixed with `make fix-lint`). ",
          "createdAt": "2022-02-21T08:12:02Z",
          "updatedAt": "2022-02-21T08:12:02Z"
        },
        {
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks @rmarx! Very valuable feedback and advice. \r\nI'll try to fix the generated HTML and use `{: .language-cddl}`. \r\nFor the time being I admit that I cut corners to get a quick continuous CDDL validation :)  \r\n\r\nAs far as using the HTTP3 prefix instead of HTTP I thought that it was valuable to distinguish between HTTP/3 and HTTP/2 especially around Frames (e.g. HTTP/2 Frames have flags?) but I'll revert to using HTTP and we can discuss further for future versions. \r\n\r\nI'll have a second iteration ready soon.",
          "createdAt": "2022-02-21T21:51:46Z",
          "updatedAt": "2022-02-21T22:08:30Z"
        },
        {
          "author": "lnicco",
          "authorAssociation": "COLLABORATOR",
          "body": "@rmarx I addressed almost all the comments. I can use some guidance on how to address having shared types for Parameters and Frames. \r\n\r\nI also created a PR for the full CDDL file in case you want to link it all together \r\n \r\nhttps://github.com/quiclog/qlog/pull/7",
          "createdAt": "2022-02-25T02:23:10Z",
          "updatedAt": "2022-02-25T02:23:10Z"
        }
      ],
      "reviews": []
    }
  ]
}